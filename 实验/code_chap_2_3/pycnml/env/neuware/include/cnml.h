/*************************************************************************
 * Copyright (C) [2018] by Cambricon, Inc.
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *************************************************************************/

/************************************************************************
 *
 *  @file cnml.h
 *
 *
 *  @brief cnml APIs provide programmable interfaces for users to develop
 *  their-owned programs, which includes device managment, context
 *  management, memory managment of both sides (devices and hosts), etc.
 *
 **************************************************************************/

#ifndef CNML_H_
#define CNML_H_

#define CNML_MAJOR_VERSION 7
#define CNML_MINOR_VERSION 3
#define CNML_PATCH_VERSION 0

#define CNML_VERSION (CNML_MAJOR_VERSION * 10000 + CNML_MINOR_VERSION * 100 + CNML_PATCH_VERSION)

#include "cnrt.h"  // NOLINT
#if defined(__cplusplus)
extern "C" {
#endif

#if defined(WIN32) || defined(WINDOWS)
#include <time.h>

#ifdef USE_CNML_DLL
#ifdef CNML_DLL_EXPORTS
#define CNML_DLL_API __declspec(dllexport)
#else /*CNML_DLL_EXPORTS*/
#define CNML_DLL_API __declspec(dllimport)
#endif /*CNML_DLL_EXPORTS*/
#else
#define CNML_DLL_API
#endif /*USE_CNML_DLL*/

#else
#define CNML_DLL_API
#endif

//! @brief An enum.
/*! CNML external core version. Enumeration cnmlCoreVersion_t has 6 enumerated values, each of which
 *  represent a type of hardware. This enumeration variable is passed in at compile time to
 *  determine which version of hardware instructions are generated by compilation. */
typedef enum {
  CNML_1H8 = 1,
  /*!< 1H8 hardware. */
  CNML_1H16 = 2,
  /*!< 1H16 hardware. */
  CNML_C10 = 3,
  /*!< MLU100 hardware, deprecated, use CNML_MLU100 instead. */
  CNML_1H8MINI = 4,
  /*!< 1H8MINI hardware. */
  CNML_MLU100 = 3,
  /*!< MLU100 hardware, instead name of CNML_C10.*/
  CNML_MLU270 = 5,
  /*!< MLU270 hardware. */
  CNML_MLU220 = 6,
  /*!< MLU220 hardware. */
} cnmlCoreVersion_t;

//! @brief An enum.
/*! Enumeration Variables of data layout in CNML. Enumeration cnmlDataOrder_t has 25 enumerated
 *  values, each of which represent a kind of data layout. There are 24 4-D data layout types and 1
 *  3D data layout type. This enumerated variable can be passed in when Tensor is created. */
typedef enum {
  CNML_NCHW = 0,
  /*!< Data layout order: NCHW. */
  CNML_NCWH = 1,
  /*!< Data layout order: NCWH. */
  CNML_NHCW = 2,
  /*!< Data layout order: NHCW. */
  CNML_NHWC = 3,
  /*!< Data layout order: NHWC. */
  CNML_NWHC = 4,
  /*!< Data layout order: NWHC. */
  CNML_NWCH = 5,
  /*!< Data layout order: NWCH. */
  CNML_CNHW = 6,
  /*!< Data layout order: CNHW. */
  CNML_CNWH = 7,
  /*!< Data layout order: CNWH. */
  CNML_CHNW = 8,
  /*!< Data layout order: CHNW. */
  CNML_CHWN = 9,
  /*!< Data layout order: CHWN. */
  CNML_CWHN = 10,
  /*!< Data layout order: CWHN. */
  CNML_CWNH = 11,
  /*!< Data layout order: CWNH. */
  CNML_HCNW = 12,
  /*!< Data layout order: HCNW. */
  CNML_HCWN = 13,
  /*!< Data layout order: HCWN. */
  CNML_HNCW = 14,
  /*!< Data layout order: HNCW. */
  CNML_HNWC = 15,
  /*!< Data layout order: HNWC. */
  CNML_HWNC = 16,
  /*!< Data layout order: HWNC. */
  CNML_HWCN = 17,
  /*!< Data layout order: HWCN. */
  CNML_WCHN = 18,
  /*!< Data layout order: WCHN. */
  CNML_WCNH = 19,
  /*!< Data layout order: WCNH. */
  CNML_WHCN = 20,
  /*!< Data layout order: WHCN. */
  CNML_WHNC = 21,
  /*!< Data layout order: WHNC. */
  CNML_WNHC = 22,
  /*!< Data layout order: WNHC. */
  CNML_WNCH = 23,
  /*!< Data layout order: WNCH. */
  CNML_TNC = 24,
  /*!< Data layout order: TNC. */
  CNML_ARRAY = 25,
  /*!< Data layout order: Array. */
  CNML_NDHWC = 26,
  /*!< Data layout order: NDHWC. */
  CNML_NCDHW = 27,
  /*!< Data layout order: NCDHW. */
  CNML_DHWCN = 28,
  /*!< Data layout order: DHWCN. */
  CNML_HW = 29,
  /*!< Data layout order: HW. */
  CNML_CHW = 30,
  /*!< Data layout order: CHW. */
  CNML_NTC = 31,
  /*!< Data layout order: NTC. */
  CNML_NC = 32,
  /*!< Data layout order: NC. */
} cnmlDataOrder_t;

//! @brief An enum.
/*! Enumeration Variables of datatype in CNML. Enumeration cnmlDataType_t has 14 enumerated values,
 *  each of which represent a kind of datatype. This enumerated variable can be passed in when
 *  Tensor is created. */
typedef enum {
  CNML_DATA_INVALID = 0,
  /*!< Invalid  datatype. */
  CNML_DATA_FLOAT16 = 1,
  /*!< FLOAT16 datatype. */
  CNML_DATA_FLOAT32 = 2,
  /*!< FLOAT32 datatype. */
  CNML_DATA_DOUBLE = 3,
  /*!< DOUBLE datatype. */
  CNML_DATA_FIX8 = 4,
  /*!< FIX8 datatype. */
  CNML_DATA_INT8 = 4,
  /*!< INT8 datatype. */
  CNML_DATA_INT16 = 6,
  /*!< INT16 datatype. */
  CNML_DATA_INT32 = 7,
  /*!< INT32 datatype. */
  CNML_DATA_UINT8 = 8,
  /*!< UINT8 datatype. */
  CNML_DATA_UINT16 = 9,
  /*!< UINT16 datatype. */
  CNML_DATA_UINT32 = 10,
  /*!< UINT32 datatype. */
  CNML_DATA_QUANT8 = 11,
  /*!< QUANT8 datatype. */
  CNML_DATA_BINARY = 12,
  /*!< BINARY datatype. */
  CNML_DATA_BOOL = 13,
  /*!< BOOL datatype. */
  CNML_DATA_INT4 = 14,
} cnmlDataType_t;

//! @brief An enum.
typedef enum {
  CNML_STATUS_NODEVICE = -1,
  /*!< No device error. */
  CNML_STATUS_SUCCESS = 0,
  /*!< Success. */
  CNML_STATUS_DOMAINERR = 1,
  /*!< Domain error. */
  CNML_STATUS_INVALIDARG = 2,
  /*!< Invalid parameter error. */
  CNML_STATUS_LENGTHERR = 3,
  /*!< Length error. */
  CNML_STATUS_OUTOFRANGE = 4,
  /*!< Out of range error. */
  CNML_STATUS_RANGEERR = 5,
  /*!< Out of bounds error. */
  CNML_STATUS_OVERFLOWERR = 6,
  /*!< Overflow error. */
  CNML_STATUS_UNDERFLOWERR = 7,
  /*!< Underflow error. */
  CNML_STATUS_INVALIDPARAM = 8,
  /*!< Invalid param error. */
  CNML_STATUS_BADALLOC = 9,
  /*!< Memory alloc error. */
  CNML_STATUS_BADTYPEID = 10,
  /*!< TYPE ID error. */
  CNML_STATUS_BADCAST = 11,
  /*!< Type conversion error. */
  CNML_STATUS_UNSUPPORT = 12
  /*!< Unsupport. */
} cnmlStatus_t;

/*!
 * @struct cnmlScatterRefOpParam
 * @brief A struct.
 *
 * The cnmlScatterRefOpParam is a structure describing the parameters for selecting scatter_add,
 * scatter_sub, scatter_mul, scatter_div, scatter_max, scatter_min and scatter_update.
 * The scatter_div is not supported for now.
 *
 * The cnmlCreateScatterRefOpParam() and cnmlDestroyScatterRefOpParam are used to create and
 * destroy an instance of cnmlScatterRefOpParam_t, respectively.
 */
struct cnmlScatterRefOpParam;

/*! ``cnmlScatterRefOpParam_t`` is a pointer to ``cnmlScatterRefOpParam``, which is a
 * struct for selecting scatter_add, scatter_sub, scatter_mul, scatter_div, scatter_max,
 * scatter_min and scatter_update.
 */
typedef struct cnmlScatterRefOpParam *cnmlScatterRefOpParam_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreateScatterRefOpParam`` to select
 * the scatter type, which is to be used by ``cnmlCreateScatterRefOp``. */
typedef enum {
  CNML_SCATTER_ADD = 0,
  CNML_SCATTER_SUB = 1,
  CNML_SCATTER_MAX = 2,
  CNML_SCATTER_MIN = 3,
  CNML_SCATTER_MUL = 4,
  CNML_SCATTER_DIV = 5,
  CNML_SCATTER_UPDATE = 6,
} cnmlScatterType_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreatePoolOpParam`` to select
    the pooling value-selecting method to be used by ``cnmlCreatePoolOp``. */
typedef enum {
  CNML_POOL_AVG = 0,
  /*!< The average value inside the pooling window is used. */
  CNML_POOL_MAX = 1,
  /*!< The maximum value inside the pooling window is used. */
  CNML_POOL_MAXINDEX = 2,
  CNML_POOL_SUM = 3,
  /*!< The sum of values inside the pooling window is used. */
  /*!< The average and maximum value inside the pooling window are used. */
  CNML_POOL_BLEND = 4,
  // L2,
  // None
} cnmlPoolMode_t;

//! @brief An enum.
/*! Specific mode of unpool operator in CNML. Enumeration cnmlUnpoolMode_t has 7 enumerated values,
 *  each of which represent a kind of unpool mode. User can pass in it according to their actual
 *  needs when they create the unpool operator. */
typedef enum {
  CNML_UNPOOL = 0,
  /*!< The unpool mode.*/
  CNML_ROWWISE_UNPOOL = 1,
  /*!< The rowwise unpool mode.*/
  CNML_MAXPOOLBP = 2,
  /*!< The maxpoolbp mode.*/
  CNML_AVGPOOLBP = 3,
  /*!< The avgpoolbp mode.*/
  CNML_MIDUNPOOL = 4,
  /*!< The midunpool mode.*/
  CNML_DIV = 5,
  /*!< The div mode.*/
  CNML_REP = 6,
  /*!< The rep mode.*/
  CNML_DILATION_UNPOOL = 7
  /*!< The dilation unpool mode.*/
} cnmlUnpoolMode_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreatePoolBackwardParam`` to select
 *  poolbackward strategy method to be used by ``cnmlCreatePoolBackwardOp``, which may
 *  cause different output size. */
typedef enum {
  CNML_UNPOOL_KSAME = 0,
  /*!< The window can be out of bounds. */
  CNML_UNPOOL_KVALID = 1,
  /*!< The window must be within the bounds. */
} cnmlUnPoolStrategyMode_t;

//! @brief An enum.
/*! In which dimension of reduce_or operator is calculated in CNML. Enumeration cnmlReduce_orDim_t
 *  has 4
 *  enumerated values, indicating the dimension in which reduce_or operator is calculated. User can
 *  pass in it according to their actual needs when they create the reduce_or operator. At present,
 *  only N dimension and C dimension is supported.*/
typedef enum {
  CNML_REDUCE_OR_DIM_C = 3,
  /*!< Compute reduce_or in dimension C. */
  CNML_REDUCE_OR_DIM_W = 1,
  /*!< Compute reduce_or in dimension W. */
  CNML_REDUCE_OR_DIM_H = 2,
  /*!< Compute reduce_or in dimension H. */
  CNML_REDUCE_OR_DIM_N = 4
  /*!< Compute reduce_or in dimension N. */
} cnmlReduce_orDim_t;

//! @brief An enum.
/*! In which dimension of reduce_and operator is calculated in CNML. Enumeration cnmlReduce_orDim_t
 *  has 4
 *  enumerated values, indicating the dimension in which reduce_and operator is calculated. User can
 *  pass in it according to their actual needs when they create the reduce_and operator. At present
 *  only N dimension and C dimension is supported.*/
typedef enum {
  CNML_REDUCE_AND_DIM_C = 3,
  /*!< Compute reduce_and in dimension C. */
  CNML_REDUCE_AND_DIM_W = 1,
  /*!< Compute reduce_and in dimension W. */
  CNML_REDUCE_AND_DIM_H = 2,
  /*!< Compute reduce_and in dimension H. */
  CNML_REDUCE_AND_DIM_N = 4
  /*!< Compute reduce_and in dimension N. */
} cnmlReduce_andDim_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreatePoolOpParam`` to select
 *  pooling strategy method to be used by ``cnmlCreatePoolOp``, which may
 *  cause different output size. */
typedef enum {
  CNML_POOL_KFULL = 0,
  /*!< The pooing window can be out of bounds. */
  CNML_POOL_KVALID = 1,
  /*!< The pooling window must be within the bounds. */
} cnmlPoolStrategyMode_t;

//! @brief An enum.
/*! Which activation function is used by active operator in CNML. Enumeration cnmlActiveFunction_t
 *  has 4 enumerated values, indicating different activation functions in active operator. User can
 *  pass in it according to their actual needs when they create the active operator. */
typedef enum {
  CNML_ACTIVE_NONE = 0,
  /*!< Do not use activation function. */
  CNML_ACTIVE_SIGMOID = 1,
  /*!< Use sigmoid activation function. */
  CNML_ACTIVE_RELU = 2,
  /*!< Use relu activation function. */
  CNML_ACTIVE_TANH = 3,
  /*!< Use tanh activation function. */
  CNML_ACTIVE_RELU1 = 4,
  /*!< Use relu1 activation function. */
  CNML_ACTIVE_RELU6 = 5,
  /*!< Use relu6 activation function. */
  CNML_ACTIVE_HARD_SIGMOID = 6,
  /*!< Use hard sigmoid activation function. */
} cnmlActiveFunction_t;

typedef enum {
  CNML_TRIGON_TAN = 0,
  CNML_TRIGON_ASIN = 1,
  CNML_TRIGON_ACOS = 2,
  CNML_TRIGON_ATAN = 3,
  CNML_TRIGON_SINH = 4,
  CNML_TRIGON_COSH = 5,
  CNML_TRIGON_ASINH = 6,
  CNML_TRIGON_ACOSH = 7,
  CNML_TRIGON_ATANH = 8,
} cnmlTrigonFunction_t;

//! @brief An enum.
/*! In which mode of conv operator is calculated in CNML. Enumeration cnmlConvMode_t
 *  has 3 enumerated values, indicating the mode in which Ndconv operator is calculated.
 *  User can pass in it according to their actual needs when they create the Ndconv operator. */
typedef enum {
  CNML_CONV = 0,
  /*!< The common conv operation.*/
  CNML_CONV_GROUP = 1,
  /*!< The conv group operation. */
  CNML_CONV_DEPTHWISE = 2,
  /*!< The conv depthwise operation. */
} cnmlConvMode_t;

//! @brief An enum.
/*! Dimension of CNML.Enumeration cnmlDimension_t has 4 enumerated values, each of which represent a
 *  dimension. This enumerated variable can be used for function variable passing in. */
typedef enum {
  CNML_DIM_N = 0,
  /*!< Dimension N. */
  CNML_DIM_C = 1,
  /*!< Dimension C. */
  CNML_DIM_H = 2,
  /*!< Dimension H. */
  CNML_DIM_W = 3,
  /*!< Dimension W. */
  CNML_DIM_HW = 4,
  /*!< Dimension HW. */
  CNML_DIM_T = 5,
  /*!< Dimension T. */
} cnmlDimension_t;

typedef enum {
  NONE = 0,
  MEAN = 1,
  SUM = 2,
} cnmlReductionmode_t;

//! @brief An enum.
/*! Tensor type of CNML.Enumeration cnmlTensorType_t has 3 enumerated values, each of which
 *  represent a kind of tensor type. Users pass in different types of tensor in the interface for
 *  creating tensor to create different types of tensor. */
typedef enum {
  CNML_TENSOR = 0,
  /*!< Tensor type. */
  CNML_FILTER = 1,
  /*!< Filter type. */
  CNML_CONST = 2,
  /*!< Const type. */
  CNML_VARIABLE = 3,
  /*!< variable type. */
} cnmlTensorType_t;

//! @brief An enum.
/*! Data conversion of cast operator in CNML.Enumeration cnmlCastType_t has 9 enumerated values,
 *  each of which represent a kind of data conversion mode. User can pass in it according to their
 *  actual needs when they create the cast operator. */
typedef enum {
  CNML_CAST_FLOAT32_TO_UINT8 = 0,
  /*!< Convert float32 to uint8. */
  CNML_CAST_UINT8_TO_FLOAT32 = 1,
  /*!< Convert uint8 to float32. */
  CNML_CAST_INT8_TO_FLOAT16 = 3,
  /*!< Convert int8 to float16. */
  CNML_CAST_FIX8_TO_FLOAT16 = 3,
  /*!< Convert int8 to float16. */
  CNML_CAST_FLOAT16_TO_FLOAT32 = 4,
  /*!< Convert float16 to float32. */
  CNML_CAST_FLOAT16_TO_FIX8 = 5,
  /*!< Convert float16 to int8. */
  CNML_CAST_FLOAT16_TO_INT8 = 5,
  /*!< Convert float16 to int8. */
  CNML_CAST_FLOAT32_TO_FLOAT16 = 6,
  /*!< Convert float32 to float16. */
  CNML_CAST_INT16_TO_FLOAT16 = 7,
  /*!< Convert int16 to float16. */
  CNML_CAST_FLOAT16_TO_INT16 = 8,
  /*!< Convert float16 to int16. */
  CNML_CAST_FLOAT16_TO_INT16_ROUND_ZERO = 9,
  // MLU270 append
  /*!< Convert float16 to uint8. */
  CNML_CAST_FLOAT16_TO_UINT8 = 10,
  /*!< Convert uint8 to float16. */
  CNML_CAST_UINT8_TO_FLOAT16 = 11,
  /*!< Convert int8 to float32. */
  CNML_CAST_INT8_TO_FLOAT32 = 12,
  /*!< Convert float32 to int8. */
  CNML_CAST_FLOAT32_TO_INT8 = 13,
  /*!< Convert int16 to float32. */
  CNML_CAST_INT16_TO_FLOAT32 = 14,
  /*!< Convert float32 to int16. */
  CNML_CAST_FLOAT32_TO_INT16 = 15,
  /*!< Convert float16/32 to int16/32. */
  CNML_CAST_FLOAT16_TO_INT16_ROUND_EVEN = 16,
  CNML_CAST_FLOAT16_TO_FLOAT16_ROUND_EVEN = 17
} cnmlCastType_t;

//! @brief An enum.
/*! Types of yuv in yuv to rgb operator in CNML.Enumeration cnmlYuvType_t has 2 enumerated values,
 *  each of which represent a type of yuv in yuv to rgb operator. User can pass in it according to
 *  their actual needs when they create the yuv to rgb operator. */
typedef enum {
  CNML_YUV420SP_NV12 = 0,
  /*!< YUV420SP_NV12 type, correspond to YCbCr. */
  CNML_YUV420SP_NV21 = 1,
  /*!< YUV420SP_NV21 type, correspond to YCrCb. */
} cnmlYuvType_t;

//! @brief An enum.
/*! The order of output channels in yuv to rgb operator in CNML.Enumeration cnmlRgbType_t has 3
 *  enumerated values, each of which represent a kind of the order of output channels in yuv to rgb
 *  operator. User can pass in it according to their actual needs when they create the yuv to rgb
 *  operator. */
typedef enum {
  CNML_RGB0 = 0,
  /*!< The order of output channels is RGB0. */
  CNML_BGR0 = 1,
  /*!< The order of output channels is BGR0. */
  CNML_ARGB = 2,
  /*!< The order of output channels is ARGB. */
} cnmlRgbType_t;

//! @brief An enum.
/*! Mode of LRN operator in CNML.Enumeration cnmlLrnType_t has 3 enumerated values, each of which
 *  represent a kind of computing mode in LRN operator. User can pass in it according to their
 *  actual needs when they create the LRN operator. */
typedef enum {
  CNML_LRN_V1,
  /*!< LRN operator v1 mode. Specific meaning is Yi = Xi / [(alpha * sum(Xj^2) / m + k) ^ beta], m =
     min(local_size, 2*ci-1) */
  CNML_LRN_V2,
  /*!< LRN operator v2 mode. Specific meaning is Yi = Xi / [(alpha * sum(Xj^2) + k) ^ beta] */
  CNML_LRN_V3
  /*!< LRN operator v3 mode. Specific meaning is Yi = Xi / [(alpha * sum(Xj^2) / local_size + k) ^
     beta], j = i - local_size / 2 ~~ i + local_size / 2, (i and j are in C dimention) */
} cnmlLrnType_t;

//! @brief An enum.
/*! Type of RNN operator input in CNML.Enumeration cnmlRNNInputMode_t has 3 enumerated values, each
 *  of which represent a type of RNN operator input. User can pass in it according to their actual
 *  needs when they create the RNN operator. */
typedef enum {
  CNML_RNN_LINEAR_INPUT = 0,
  /*!< LINEAR type input. */
  CNML_RNN_SKIP_INPUT = 1,
  /*!< SKIP type input. */
} cnmlRNNInputMode_t;

typedef enum {
  CNML_GRU_MODE_V1 = 0,
  /*!< design formulas of GRU_MODE_V1:
       1. rt = (w1*x + b1 + w2*h-1 + b2)
       2. zt = (w3*x + b3 + w4*h-1 + b4)
       3. ~ht = tanh(rt * (w5*x + b5) + w6*ht-1 + b6 )
       4. ht = (1 - zt) * ht-1 + zt * ~ht   */
  CNML_GRU_MODE_V2 = 1,
  /*!< design formulas of GRU_MODE_V2:
       1. rt = (w1*x + b1 + w2*h-1 + b2)
       2. zt = (w3*x + b3 + w4*h-1 + b4)
       3. ~ht = tanh(rt * (w6*ht-1 + b6) + w5*x + b5 )
       4. ht = (1 - zt) * ~ht + zt * ht-1   */
} cnmlGRUMode_t;

typedef enum {
  CNML_RNN_UNUSED = -1,
  CNML_RNN_NC = 0,
  CNML_RNN_TNC = 1,
  CNML_RNN_NTC = 2,
  CNML_RNN_TN = 3,
  CNML_RNN_NT = 4,
} cnmlRnnDataMode_t;

typedef enum { CNML_TOPK_OP_MODE_MAX = 0, CNML_TOPK_OP_MODE_MIN = 1 } cnmlTopkOpMode_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreateNdDyadicOp`` to select
 * the dyadic operate type. */
typedef enum {
  CNML_DYADIC_ADD = 0,
  /*!< The dyadic type for the add operation. */
  CNML_DYADIC_SUB = 1,
  /*!< The dyadic type for the sub operation. */
  CNML_DYADIC_MULT = 2,
  /*!< The dyadic type for the mult operation. */
} cnmlDyadicType_t;

//////////////////////// common /////////////////////////

/*!
 *  @brief A function.
 *
 *  This function is used to initialize hardware platform and LOG system.
 *
 *  @param[in] flag
 *    Input. The input is integer variable. flag, the future reserved variable, is temporarily
 *  invalid.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlInit(int flag);
/*!
 *  @brief A function.
 *
 *  This function is used to initialize hardware platform and LOG system.
 *
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlExit();
/*!
 *  @brief A function.
 *
 *  This function is used to get the CNML version.This function is used to get the CNML version.
 *
 *  @param[out] ver
 *    Output. return version number
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are not met:
 *    - ver is a non-null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlGetVersion(unsigned int *ver);

// cnml tensor
/*!
 *  @struct cnmlTensor
 *  @brief A struct.
 *
 *  The cnmlTensor_t is a structure describing tensor in MLU. cnmlCreateTensor() is used to create a
 * 4D
 *  instance of cnmlTensor_t. cnmlCreateTensor_V2() is used to create a ND instance of cnmlTensor_t.
 *  cnmlDestroyTensor() is used to destroy an instance of cnmlTensor_t. */
struct cnmlTensor;
/*! ``cnmlTensor_t`` is a pointer to ``cnmlTensor`` which is a
    structure holding the description of a tensor in MLU. */
typedef struct cnmlTensor *cnmlTensor_t;

// for NDTensor
/*!
 *  @brief A function.
 *
 *  This function initializes a multidimensional (1-N-dimensional) Tensor at the MLU end according
 *  to the user-specified Tensor type.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t
 *  @param[in] tensor_type
 *    Input. A variable indicating the Tensor type
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Tensor_typeis not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTensor_V2(cnmlTensor_t *tensor, cnmlTensorType_t tensor_type);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the pointer of tensor on device is freed.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor address at the MLU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Pointer is null.
 *    - The pointer content pointed to by tensor has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyTensor(cnmlTensor_t *tensor);

/*!
 *  @brief A function.
 *
 *  According to the data type given by the user, the function sets the type of data when saved in
 *  MLU.According to the data type given by the user, the function sets the type of data when saved
 *  in MLU.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t.
 *  @param[in] data_type
 *    Input. A variable indicating the Tensor data type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Data_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlSetTensorDataType(cnmlTensor_t tensor, cnmlDataType_t data_type);

/*!
 *  @brief A function.
 *
 *  This function gets the data type of the input Tensor.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t
 *  @retval cnmlDataType_t data type
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Data_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlGetTensorDataType(cnmlTensor_t tensor, cnmlDataType_t *dtype);

/*!
 *  @brief A function.
 *
 *  This function sets the shape of the Tensor at the MLU end according to the user-specified shape
 *  (the number of dimensions, and the specific value of each dimension).
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t.
 *  @param[in] dim_num
 *    Input. An integer variable indicating the number of dimensions.
 *  @param[in] dim_values
 *    Input. An integer array storing specific value for each dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - The length of dim_num and dim_values arrays is not consistent.The length of dim_num and
 *  dim_values arrays is not consistent.
 */
CNML_DLL_API cnmlStatus_t cnmlSetTensorShape(cnmlTensor_t tensor, int dim_nums, int dim_values[]);

/*!
 *  @brief A function.
 *
 *  This function sets the shape of the Tensor at the MLU end according to the user-specified shape
 *  (the number of dimensions, and the specific value of each dimension).
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t.
 *  @param[in] dim_num
 *    Input. An integer variable indicating the number of dimensions.
 *  @param[in] dim_values
 *    Input. An integer array storing specific value for each dimension.
 *  @param[in] dim_strides
 *    Input. An integer array storing specific value for each dimension's stride.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - The length of dim_num and dim_values arrays is not consistent.The length of dim_num and
 *  dim_values arrays is not consistent.
 */
CNML_DLL_API cnmlStatus_t cnmlSetTensorShape_V2(cnmlTensor_t tensor,
                                                int dim_nums,
                                                int dim_values[],
                                                int dim_strides[]);

/*!
 *  @brief A function.
 *
 *  This function gets the shape of the input Tensor.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t.
 *  @param[in] shape
 *    Input. A pointer pointing to an integer a pointer pointing to an integer.
 *  @retval Null
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Data_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlGetTensorShape(cnmlTensor_t tensor, int *shape);

/*!
 *  @brief A function.
 *
 *  This function gets the size of the space occupied by the input Tensor.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t
 *  @retval size_t type
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Data_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlGetTensorSize_V2(cnmlTensor_t tensor, size_t *size);

/*!
 *  @brief A function.
 *
 *  This function gets the length of input Tensor.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t
 *  @retval int type
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Data_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlGetTensorLen(cnmlTensor_t tensor, int *len);

/*!
 *  @brief A function.
 *
 *  Given a tensor, a file name, and an optimization level, the function copies the data from the
 *  specified Tensor device into the cnmldata / file in the current running directory.
 *
 *  This function has no return value, and if the inout tensor is a null pointer or the file name is
 *  illegal, it returns directly by throwing error.
 *
 *  opt_level input will not return if it is an illegal value, but a default value will be taken.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] filename
 *    Input. File name, which is used to save data in the device for this tensor.
 *  @param[in] opt_level
 *    Input. Optimization level. An integer of 0 or 1, 0 means no optimization, 1 means
 *    computation optimization, some tensors may not be copied from the device after computation
 *    optimization.
 */
CNML_DLL_API cnmlStatus_t cnmlDumpTensorFromDevice(cnmlTensor_t tensor,
                                                   const char *filename,
                                                   int opt_level);

/*!
 *  @brief A function.
 *
 *  This function is used to set the position value of the tensor at MLU end when it is used for
 *  precision quantization.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] position
 *    Input. An integer variable that indicates the value of the position parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedPosition(cnmlTensor_t tensor, int position);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the position value of the tensor at MLU end when it is used for
 *  precision quantization.
 *
 *  @param[out] position
 *    Output. A pointer pointing to an integer variable that saves the value of the position
 *  parameter.
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlGetQuantizedPosition(cnmlTensor_t tensor, int *position);

/*!
 *  @brief A function.
 *
 *  This function is used to set the value of scale required by the tensor at MLU end for precision
 *  quantization.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] scale
 *    Input. A floating-point variable that indicates the value of the scale parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedScale(cnmlTensor_t tensor, float scale);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the value of scale set by the tensor at MLU end for precision
 *  quantization.
 *
 *  @param[out] scale
 *    Output. A pointer pointing to a floating-point variable that saves the value of the scale
 *  parameter.
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlGetQuantizedScale(cnmlTensor_t tensor, float *scale);

/*!
 *  @brief A function.
 *
 *  This function is used to set the position parameters of the data quantized by channel for the
 *  tensor at the MLU end.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] positions
 *    Input. An integer array that saves the value of the position parameter used for each channel
 *  quantization. If channel scale or channel alpha is given, default value is 0.
 *  @param[in] positions_size
 *    Input. An integer variable indicating the number of channels, and the value should be
 *  consistent with Tensor's value in the N dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor, positions are null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedPositionByChannel(cnmlTensor_t tensor,
                                                            int *positions,
                                                            int positions_size);

/*!
 *  @brief A function.
 *
 *  This function is used to set the scale parameters of the data quantized by channel for the
 *  tensor at MLU end.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] scales
 *    Input. A floating-point array that saves the value of the scale parameter used for each
 *  channel quantization. If channel position is given, default scale is 1.0.
 *  @param[in] scales_size
 *    Input. An integer variable indicating the number of channels, and the value should be
 *  consistent with Tensor's value in the N dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor, scales are null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedScaleByChannel(cnmlTensor_t tensor,
                                                         float *scales,
                                                         int scales_size);

/*!
 *  @brief A function.
 *
 *  This function is used to set the alpha parameters of the data quantized by
 *  channel for the tensor at MLU end.
 *
 *  **Formula**
 *
 *    alpha = 1 / scale
 *    float_num = fix_num * 2^(position) * alpha = fix_num * 2^(position) / scale
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] alphas
 *    Input. A floating-point array that saves the value of the alpha parameter used for each
 *  channel quantization. If channel position is given, default alpha is 1.0.
 *  @param[in] alphas_size
 *    Input. An integer variable indicating the number of channels, and the value should be
 *  consistent with Tensor's value in the N dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor, scales are null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedAlphaByChannel(cnmlTensor_t tensor,
                                                         float *alphas,
                                                         int alphas_size);

/*!
 *  @brief A function.
 *
 *  This function is used to set the scale and offset parameters required for Quant8 precision
 *  quantization of the tensor at MLU end.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] scale
 *    Input. A floating-point variable that indicates the value of the scale parameter.
 *  @param[in] offset
 *    Input. A floating-point variable that indicates the value of the offset parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuant8Param(cnmlTensor_t tensor, float scale, float offset);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the scale and offset parameters required for Quant8 precision
 *  quantization of the tensor at MLU end.
 *
 *  @param[out] scale
 *    Output. A pointer pointing to a floating-point variable that saves the value of the scale
 *  parameter.
 *  @param[out] float
 *    Output. A pointer to a floating-point variable that saves the value of the offset parameter.
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlGetQuant8Param(cnmlTensor_t tensor, float *scale, float *offset);

/*!
 *  @brief A function.
 *
 *  This function is used to output the address information of the tensor at mlu end in memory.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at the MLU end.
 *  @param[in] type
 *    Input. An enumeration variable that indicates tensor type.
 */
CNML_DLL_API cnmlStatus_t cnmlPrintTensor(cnmlTensor_t tensor, cnmlTensorType_t tensor_type);

/*!
 *  @brief A function.
 *
 *  This function is used to copy data of tensor at CPU end to file.
 *
 *  @param[in] filename
 *    Input. A string pointer that specifies the file name.
 *  @param[in] output
 *    Input. A void* pointer pointing to the address allocated by the CPU to save data.
 *  @param[in] app
 *    Input. A Boolean variable that specifies whether is written to a file in an additive manner.
 */
CNML_DLL_API cnmlStatus_t cnmlDumpTensor2File_V2(const char *filename,
                                                 cnmlTensor_t tensor,
                                                 void *output,
                                                 bool app);

// cnml bind data
/*!
 *  @brief A function.
 *
 *  This function is used to bind the data information of the tensors at MLU and CPU end.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at MLU end, and the interface currently supports only
 *  CNML_FILTER and CNML_CONST-type Tensor.
 *  @param[in] cpu_data_ptr
 *    Input. A pointer of void type pointing to the binding data address of the Tensor at CPU end.
 *  @param[in] free_aftercompile
 *    Input. A bool variable, the cpu_tensor_ptr will be freed automatically if the value is true,
             otherwise it should be freed by user manually.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointers of tensor, cpu_data_ptr are null.
 *    - Tensor type is not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlBindConstData_V2(cnmlTensor_t tensor,
                                               void *cpu_tensor_ptr,
                                               bool free_aftercompile);

/*!
 *  @brief A function.
 *
 *  This function is used to get the const data from the binded tensor at MLU.
 *  This funciton should be used after cnmlCreateTensor API and cnmlBindConstData API.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at MLU end, and the interface currently supports only
 *  CNML_CONST-type Tensor.
 *  @param[in] cpu_ptr
 *    Input. A pointer of void type pointing to the binding data address of the Tensor at CPU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointers of tensor, cpu_data_ptr are null.
 *    - Tensor type is not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlGetConstData(cnmlTensor_t tensor, void **cpu_ptr);

/*!
 *  @brief A function.
 *
 *  This function is used to destroy the specified tenor on the mlu.
 *
 *  @param[in] tensor
 *    Input.  a pointer pointing to the address to be destroyed
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyTensor(cnmlTensor_t *tensor);
////////////////////////// operation /////////////////////////
/* base operation start */
/*!
 *  @struct cnmlBaseOp
 *  @brief A struct.
 *
 *  The cnmlBaseOp is a structure describing base operation. Each base operation calls its
 * corresponding
 *  function to create an instance of cnmlBaseOp_t. For example, add operation calls
 *  cnmlCreateAddOp() to create a specific instance of cnmlBaseOp_t. cnmlDestroyBaseOp() is used to
 *  destroy an instance of cnmlBaseOp_t. */
struct cnmlBaseOp;
/*! ``cnmlBaseOp_t`` is a pointer to ``cnmlBaseOp`` which is a
    structure holding the description of base operation. */
typedef struct cnmlBaseOp *cnmlBaseOp_t;

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the space occupancy of the specified operator.
 *
 *  @param[out] totalmem
 *    Output. The size of the total space occupied by the operator.
 *  @param[out] sharemem
 *    Output. The size of the shared memory occupied by the operator.
 *  @param[out] privatemem
 *    Output. The size of the privated memory occupied by the operator.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlGetMaxMemUsed(cnmlBaseOp_t op,
                                            int64_t *totalmem,
                                            int64_t *sharemem,
                                            int64_t *privatemem);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the space occupancy of the specified operator.
 *
 *  @param[out] iocount
 *    Output. The IO number of the compiled operator.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlGetIOCount(cnmlBaseOp_t op, int64_t *iocount);

/*!
 *  @brief A function.
 *
 *  Check whether the base operator can run.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base oeprator.
 *  @param[in] version
 *    Input. Platform version.(MLU270)
 *  @retval CNML_STATUS_UNSUPPORT
 *    This function is not complete.
 */
CNML_DLL_API cnmlStatus_t cnmlCheckBaseOpRunnable(cnmlBaseOp_t op, cnmlCoreVersion_t version);

/*!
 *  @brief A function.
 *
 *  Compile base operators.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base oeprator.
 *  @param[in] version
 *    Input. Platform version.
 *  @param[in] core_num
 *    Input. Number of cores participating in the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCompileBaseOp(cnmlBaseOp_t op,
                                            cnmlCoreVersion_t version,
                                            int core_limit);

/*!
 *  @brief A function.
 *
 *  Compile base operators.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base oeprator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCompileBaseOp_V2(cnmlBaseOp_t op);

/*!
 *  @brief A function.
 *
 *  This function sets that the number of operation core is used at compile time according to the
 *  fusion operation pointer given by the user and calls it after the user creates the fusion
 *  operation pointer.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base operation.
 *  @param[in] core_num
 *    Input. An int value, greater than or equal to 1, defaults to the number of core with maximum
 *  computation power at current platform, and each platform's core restrictions are different.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Platform version error.
 */
CNML_DLL_API cnmlStatus_t cnmlSetBaseOpCorenum(cnmlBaseOp_t op, int core_num);

/*!
 *  @brief A function.
 *
 *  The function sets the platform version at compile time according to the fusion operation pointer
 *  given by the user, and calls it after the user creates the fusion operation pointer.
 *
 *  @param[in] op
 *    Input. A pointer pointing to the base operation.
 *  @param[in] version
 *    Input. Platform version.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Platform version error.
 */
CNML_DLL_API cnmlStatus_t cnmlSetBaseOpCoreVersion(cnmlBaseOp_t op, cnmlCoreVersion_t version);

/*!
 *  @brief A function.
 *
 *  Destroy base operator and free spce.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyBaseOp(cnmlBaseOp_t *op);

/*!
 *  @brief A function.
 *
 *  Set the layout for the operation.
 *  When running a network with many base op one by one, this interface should be called after
 *  cnmlCreateXXOp and before the first cnmlCompileBaseOp or cnmlCompileFusionOp of the entire
 *  computational diagram.
 *  @param[in] op
 *    Input. Pointer to a base operation
 *  @param[in] layout
 *    Input. Pointer to a cnmlDataOrder_t
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends and returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSetOperationComputingLayout(cnmlBaseOp_t op, cnmlDataOrder_t layout);

/*!
 *  @brief A function.
 *
 *  Set the layout for the operation input.
 *  When running a network with many base op one by one, this interface should be called after
 *  cnmlCreateXXXOp and before the first cnmlCompileBaseOp or cnmlCompileFusionOp of the entire
 *  computational diagram.
 *  @param[in] op
 *    Input. Pointer to a base operation
 *  @param[in] tensor
 *    Input. Pointer to a cnmlTensor_t
 *  @param[in] layout
 *    Input. Pointer to a cnmlDataOrder_t
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends and returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSetTensorComputingLayoutInOperation(cnmlBaseOp_t op,
                                                                  cnmlTensor_t tensor,
                                                                  cnmlDataOrder_t layout);

/*!
 *  @brief A function.
 *
 *  Set fix8 mode for the computation diagram under the current thread context. When running a
 *  network with many base op one by one, this interface should be called before the first
 *  cnmlCompileBaseOp or cnmlCompileFusionOp of the entire computational diagram.
 *
 *  @param[in] fix8_mode
 *    Input. Open fix8 mode when the input is true; otherwise it will not open.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends and returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSetQuantizedThreadContext(bool fix8_mode);

/*!
 *  @brief A function.
 *
 *  Get the size of stack space required by the operatop.
 *
 *  @param[out] size
 *    Output. The size of stack space required by base operator.
 *  @param[in] op
 *    Input. A pointer pointing to base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends and returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlGetBaseOpRequiredStackSize(cnmlBaseOp_t op, int64_t *size);

/*!
 *  @struct cnmlQuantizedParam
 *  @brief A struct.
 *
 *  The cnmlQuantizedParam is a structure describing the param parameter of computing datatype
 *  on device, using to specify the data type when Tensor participates in the computation on
 *  the chip by calling cnmlSetOperationComputingDataType(). cnmlCreateQuantizedParam() is used to
 *  create an instance of
 *  cnmlQuantizedParam_t.
 *  cnmlDestroyQuantizedParam() is used to destroy an instance of cnmlQuantizedParam_t. */

struct cnmlQuantizedParam;
/*!
 * ``cnmlQuantizedParam_t`` is a pointer to the structure ``cnmlQuantizedParam`` that describes
 * quantization parameters.
 */
typedef struct cnmlQuantizedParam *cnmlQuantizedParam_t;

/*!
 *  @brief A function.
 *
 *  This function is used to create quant parameter of the tensor at MLU end when it is quantized
 *  to int precision.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the cnmlQuantizedParam.
 *  @param[in] pos
 *    Input. A int variable indicating the position value.
 *  @param[in] scale
 *    Input. A floating-point variable indicating the scale value.
 *  @param[in] offset
 *    Input. A floating-point variable indicating the offset value.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of cnmlQuantizedParam is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateQuantizedParam(cnmlQuantizedParam_t *param,
                                                   int pos,
                                                   float scale,
                                                   float offset);

/*!
 *  @brief A function.
 *
 *  This function is used to destroy an instance of cnmlQuantizedParam_t.
 *
 *  @param[in] param
 *    Input. A pointer instance pointing to the cnmlQuantizedParam.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer instance of cnmlQuantizedParam is null.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyQuantizedParam(cnmlQuantizedParam_t *param);

/*!
 *  @brief A function.
 *
 *  Set Operation to specify the data type when Tensor participates in the computation on the chip.
 *
 *  A new interface is provided to set the data types and quantization parameters on the operator
 *  chip to OP separately. Tensor is opinput, output or weight tensor, off-chip data type is
 *  Tensor's own data type, and on-chip data type is input data type.
 *
 *  @param[in] op
 *    Input. A pointer pointing to base oeprator.
 *  @param[in] tensor
 *    Input. Tensor data.
 *  @param[in] data_type
 *    Input. Data type
 *  @param[in] quant_param
 *    Input. Decimal position.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSetOperationComputingDataType(cnmlBaseOp_t op,
                                                            cnmlTensor_t tensor,
                                                            cnmlDataType_t data_type,
                                                            cnmlQuantizedParam_t quant_param);

/* base operation end */

/* fuse op start */
/*!
 *  @struct cnmlFusionOp
 *  @brief A struct.
 *
 *  The cnmlFusionOp is a structure describing fusion operation. cnmlDestroyFusionOp() is used to
 * create
 *  an instance of cnmlFusionOp_t. cnmlDestroyFusionOp() is used to destroy an instance of
 *  cnmlFusionOp_t. */
struct cnmlFusionOp;
/*! ``cnmlFusionOp_t`` is a pointer to ``cnmlFusionOp`` which is a
    structure holding the description of fusion operation. */
typedef struct cnmlFusionOp *cnmlFusionOp_t;

CNML_DLL_API cnmlStatus_t cnmlSetFusionOperationComputingLayout(cnmlFusionOp_t op,
                                                                cnmlDataOrder_t layout);
/*!
 *  @brief A function.
 *
 *  This function is used to obtain the maximum memory used by the fusion operation.
 *
 *  @param[out] totalmem
 *    Output. Total memory.
 *  @param[out] sharemem
 *    Output. Sharing memory.
 *  @param[out] privatemem
 *    Output. Private memory
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlGetFusionMaxMemUsed(cnmlFusionOp_t op,
                                                  int64_t *totalmem,
                                                  int64_t *sharemem,
                                                  int64_t *privatemem);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the number of operators for fusion.
 *
 *  @param[out] iocount
 *    Output. The number of operators for fusion.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlGetFusionIOCount(cnmlFusionOp_t op, int64_t *iocount);

/*!
 *  @brief A function.
 *
 *  This function sets whether to turn on Batchsize changable function according to the fusion
 *  operation pointer given by the user and calls it after the user creates the fusion operation
 *  pointer.
 *
 *  This function is not yet enabled.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operation.
 *  @param[in] changable
 *    Input. A bool value, defaults to false. When it is true, batchsize is changeable.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpBatchsizeChangable(cnmlFusionOp_t op, bool changable);

/*!
 *  @brief A function.
 *
 *  This function sets whether to turn on the number of operation core changable function according
 *  to the fusion operation pointer given by the user and calls it after the user creates the fusion
 *  operation pointer.
 *
 *  This function is not yet enabled.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operation.
 *  @param[in] changable
 *    Input. A bool value defaults to false. When it is true, the number of operation core is
 *  changeable at compile time.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpCorenumChangable(cnmlFusionOp_t op, bool changable);

/*!
 *  @brief A function.
 *
 *  This function sets that the number of operation core is used at compile time according to the
 *  fusion operation pointer given by the user and calls it after the user creates the fusion
 *  operation pointer.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operation.
 *  @param[in] core_num
 *    Input. An int value, greater than or equal to 1, defaults to the number of core with maximum
 *  computation power at current platform, and each platform's core restrictions are different.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Platform version error.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpCorenum(cnmlFusionOp_t op, int core_num);

/*!
 *  @brief A function.
 *
 *  The function sets the platform version at compile time according to the fusion operation pointer
 *  given by the user, and calls it after the user creates the fusion operation pointer.
 *
 *  @param[in] op
 *    Input. A pointer pointing to the fusion operation.
 *  @param[in] version
 *    Input. Platform version.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Platform version error.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpCoreVersion(cnmlFusionOp_t op, cnmlCoreVersion_t version);

/*!
 *  @brief A function.
 *
 *  The function sets whether to turn on the platform version changeable function according to the
 *  user's given fusion operation pointer, and calls it after the user creates the fusion operation
 *  pointer.
 *
 *  This function is not yet enabled.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operation.
 *  @param[in] changable
 *    Input. When it is true, the version is changeable at compile time.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpCoreVersionChangable(cnmlFusionOp_t op, bool changable);

/*!
 *  @brief A function.
 *
 *  This function is used in setting network running mode.It's used to solving conflict of different
 * base op
 *  When run network with fusion many base op to fusion_op, please set fusion_mode true
 *  When run network with many base op one by one, please set fusion_mode false
 *  This func should be called before CompileOp,and should set once in one thread.
 *  When change running mode in one thread, this func should be call to change running mode
 *
 *  @param[in] fusion_mode
 *    Input. A bool variable.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionThreadContext(bool fusion_mode);

/*!
 *  @brief A function.
 *
 *  This function is used to add base operators to fusion operators.
 *
 *  @param[in] op
 *    Input. A pointer for adding base operators to fusion operators.
 *  @param[in] fusion_op
 *    Input. A pointer pointing to fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer or fusion_op is null.
 */
CNML_DLL_API cnmlStatus_t cnmlFuseOp(cnmlBaseOp_t op, cnmlFusionOp_t fusion_op);

/*!
 *  @brief A function.
 *
 *  This function is used to compile fusion operators.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] version
 *    Input. Kernel version.
 *  @param[in] core_limit
 *    Input. Kernel restriction.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCompileFusionOp(cnmlFusionOp_t op,
                                              cnmlCoreVersion_t version,
                                              int core_limit);

/*!
 *  @brief A function.
 *
 *  The function compiles the corresponding operating instructions according to the fusion operation
 *  pointer given by the user and the operating parameters (the default value can be used) set by
 *  the user in the pointer.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operation.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Platform version error.
 */
CNML_DLL_API cnmlStatus_t cnmlCompileFusionOp_V2(cnmlFusionOp_t op);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeFusionOpForward_V4 is recommended to use.
 *
 *  The interface is used to perform specified fusion operations on input in MLU.
 *
 *  @param[out] outputs[]
 *    Output. A pointer pointng to the MLU address of the output position.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] inputs[]
 *    Input. A pointer pointing to the initial address of input data.
 *  @param[in] input_num
 *    Input. The number of input.
 *  @param[in] output_num
 *    Input. The number of output.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeFusionOpForward_V3(cnmlFusionOp_t op,
                                                        void *inputs[],
                                                        int input_num,
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  The interface is used to perform specified fusion operations on input in MLU.
 *
 *  @param[out] outputs[]
 *    Output. A pointer pointng to the MLU address of the output position.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] inputs[]
 *    Input. A pointer pointing to the initial address of input data.
 *  @param[in] input_num
 *    Input. The number of input.
 *  @param[in] output_num
 *    Input. The number of output.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeFusionOpForward_V4(cnmlFusionOp_t op,
                                                        cnmlTensor_t input_tensors[],
                                                        void *inputs[],
                                                        int input_num,
                                                        cnmlTensor_t output_tensors[],
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtQueue_t queue,
                                                        void *extra);

/*!
 *  @brief A function.
 *
 *  This function is used to create a fusion operator pointer.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFusionOp(cnmlFusionOp_t *op);

/*!
 *  @brief A function.
 *
 *  This function is used to destroy the fusion operator pointer.
 *
 *  @param[out] op
 *    Output. A pointer to the address of the fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyFusionOp(cnmlFusionOp_t *op);

/*!
 *  @brief A function.
 *
 *  This function is used to set IO for the fusion operation.
 *
 *  @param[out] outputs
 *    Output. A pointer pointing to a four-dimensional MLU output tensor.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] inputs
 *    Input. A pointer pointing to a four-dimensional MLU input tensor.
 *  @param[in] input_num
 *    Input. The number of input.
 *  @param[in] output_num
 *    Input. The number of output.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionIO(cnmlFusionOp_t op,
                                          cnmlTensor_t *inputs,
                                          int input_num,
                                          cnmlTensor_t *outputs,
                                          int output_num);

/*!
 *  @brief A function.
 *
 *  This function is used to increase the input of the fusion operation.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddFusionInput(cnmlFusionOp_t op, cnmlTensor_t input_tensor);

/*!
 *  @brief A function.
 *
 *  This function is used to increase the output of the fusion operation.
 *
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] output
 *    Input. A four-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddFusionOutput(cnmlFusionOp_t op, cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  This function is used to obtain the stack size required by the fusion operator operation.
 *
 *  @param[out] size
 *    Output. A pointer pointing to the stack size.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlGetFusionOpRequiredStackSize(cnmlFusionOp_t op, int64_t *size);

/*!
 *  @brief A function.
 *
 *  This function is used to set a fusion op cache mode. This function should be called before
 *  adding cache graphs and make sure the cache mode is set to ``true`` during compiling. Default
 *  cache mode value is false.
 *
 *  @param[in] all_cache_graph
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] cache_mode
 *    Input. A bool value. Supported values are  ``true`` and ``false``. The default value is
 *    ``false``. You need to set this parameter to ``true`` before adding basic graphs.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - all_cache_graph pointer is null.
 *    - set an all_cach_graph which has been set cache mode true cache mode false.
 */
CNML_DLL_API cnmlStatus_t cnmlSetFusionOpCacheMode(cnmlFusionOp_t all_cache_graph, bool cache_mode);

/*!
 *  @brief A function.
 *
 *  This function is used to add basic_graph to all_cache_graph. Before calling this API, make sure
 *  the cache mode is set to ``true``. You can set the cache mode by calling the
 *  ``cnmlSetFusionOpCacheMode`` API.
 *
 *  @param[in] all_cache_graph
 *    Input. A pointer pointing to fusion operator, should be created.
 *  @param[in] basic_graph
 *    Input. A pointer pointing to fusion operator, should be set all basic graph ready and
 *    should not set cache mode true.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - All cache graph pointer or basic_graph is null.
 *    - All cache graph's cache mode is false.
 *    - Basic graph is empty or is set cache mode true.
 */
CNML_DLL_API cnmlStatus_t cnmlAddFusionOpCacheGraph(cnmlFusionOp_t all_cache_graph,
                                                    cnmlFusionOp_t basic_graph);
/* fusion op end */

/*basic rnn pro operation start */
/*!
 *  @struct cnmlRNNOpParam
 *  @brief A struct.
 *
 *  cnmlRNNOpParam is a structure describing the param parameter of basic rnn pro operation, used to
 *  create basic rnn pro operation or LSTM operation. cnmlCreateRNNOpParam() is used to create an
 *  instance of cnmlRNNOpParam_t. cnmlDestroyRNNOpParam() is used to destroy an instance of
 *  cnmlRNNOpParam_t. */
struct cnmlRNNOpParam;
/*! ``cnmlRNNOpParam_t`` is a pointer to ``cnmlRNNOpParam`` which is a
    structure holding the description of a RNN operation param. */
typedef struct cnmlRNNOpParam *cnmlRNNOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, this function creates a struct of RNN operator
 *  operation parameters, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to another pointer, and the pointed pointer points to a struct
 *  describing the operation parameters of RNN operators.
 *  @param[in] is_bidirection
 *    Input. When the input is true, the operator is bidirectional RNN; when the input is false, the
 *  operator is unidirectional RNN. For the time being, bidirectional RNN is not supported.
 *  @param[in] batch_size
 *    Input. The number of sequences within the mini-batch.
 *  @param[in] vector_size
 *    Input. The vector length in input and output tensor for each time step (that is, embedding
 *  size).
 *  @param[in] hidden_size
 *    Input. The vector length in hidden layer state.
 *  @param[in] num_layers
 *    Input. The number of layer of RNN.
 *  @param[in] input_mode
 *    Input. When num_layers are greater than 1 and vector_size is not equal to hidden_size,
 *  input_mode must be RNN_LINEAR_INPUT.
 *  @param[in] max_seqlength
 *    Input. The maximum seqlength of mini-batch.
 *  @param[in] seqlength_array
 *    Input. The integer array with batchsize elements, and each element is seqlength.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateRNNOpParam(cnmlRNNOpParam_t *param,
                                               bool is_bidirection,
                                               int batch_size,
                                               int vector_size,
                                               int hidden_size,
                                               int num_layers,
                                               cnmlRNNInputMode_t input_mode,
                                               int max_seqlength,
                                               int seqlength_array[]);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of RNN operator
 *  operation parameters to free space.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the struct of RNN operator operation parameters.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyRNNOpParam(cnmlRNNOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  This function creates a basic RNN operator according to the pointer of base operator given by
 *  users. Its formula is:
 *
 *  ht = func(w1xt + w2ht-1 + b1 + b2).
 *
 *  If all parameters in the interface are arrays, the length of all arrays is num_layers, and the
 *  element with subscript 0 in arrays represents the initial value of hidden state of the first
 *  layer, the element with subscript 1 represents the second layer, and so on. The activation
 *  function func can be any activation function supported in CNML.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. Tensor, the output data of RNN. This Tensor is a TNC or NTC type.
 *  @param[out] state_output
 *    Output. The tensor array is the final result of the hidden state of RNN after T computations.
 *  This Tensor is a NCHW type with shape of [batchSize, hiddenSize, 1, 1].
 *  @param[in] param
 *    Input. A pointer, pointing to the struct describing RNN operation parameters.
 *  @param[in] input
 *    Input. Tensor, the input data of RNN. This Tensor is a TNC or NTC type.
 *  @param[in] state_input
 *    Input. The Tensor array is the initial value of RNN's hidden state. And the length of arrays
 *  is num_layers. This Tensor is a NCHW type with shape of [batchSize, vectorSize, 1,1].
 *  @param[in] input_weight
 *    Input. Tensor array is the weight of the matrix multiplied by the input data of RNN.
 *  @param[in] state_weight
 *    Input. Tensor array is the weight of the matrix multiplied by the hidden state of RNN.
 *  @param[in] active_func
 *    Input. Input specifies which activation function to be used. It can be any activation function
 *  that CNML already supports.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBasicRNNProOp(cnmlBaseOp_t *op,
                                                  cnmlRNNOpParam_t param,
                                                  cnmlTensor_t input,
                                                  cnmlTensor_t state_input[],
                                                  cnmlTensor_t output,
                                                  cnmlTensor_t state_output[],
                                                  cnmlTensor_t input_weight[],
                                                  cnmlTensor_t state_weight[],
                                                  cnmlTensor_t input_bias[],
                                                  cnmlTensor_t state_bias[],
                                                  cnmlActiveFunction_t active_func);
/*!
 *  @brief A function.
 *
 *  This interface is used to compute basic RNN on CPU;if all parameters in the interface are array
 *  type, all arrays include num_layers elements, and the element with subscript 0 in arrays
 *  corresponds to the first layer, the element with subscript 1 corresponds to the second layer,
 *  and so on.
 *
 *  Deprecated. This interface will be deleted in next version and
 * cnmlComputeBasicRNNProOpForward_V2
 *  is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tensor
 *    Output. A 3-dimensional output tensor of CPU, the tensor is TNC type with shape of
 *  [seqLength,batchSize,hiddenSize], supporting the data of float16 type.
 *  @param[out] output
 *    Output. A pointer pointing to the initial address of the output data of RNN.
 *  @param[out] state_output_tensor
 *    Output. NumLayers 4-dimensional input tensor of CPU, the tensor is NCHW type with shape of
 *  [batchSize, hiddenSize,1,1],supporting the data of float16 type.
 *  @param[out] state_output
 *    Output. A pointer array, and each element of the array is a pointer pointing to the initial
 *  address of the state output data of RNN.
 *  @param[in] input_weight_tensor
 *    Input. NumLayers 4-dimensional constant tensor of CPU, the tensor is NCHW type with shape of
 *  [hiddenSize,vectorSize,1,1],supporting the data of float16 type.
 *  @param[in] input_weight
 *    Input. Pointer array pointing to Tensor matrix multiplied by RNN input.
 *  @param[in] state_weight_tensor
 *    Input. NumLayers 4-dimensional constant tensor of CPU, the tensor is NCHW type with shape of
 *  [hiddenSize,hiddenSize,1,1],supporting the data of float16 type.
 *  @param[in] state_weight
 *    Input. Pointer array pointing to the Tensor matrix multiplied by the RNN state input.
 *  @param[in] input_bias_tensor
 *    Input. NumLayers 4-dimensional constant tensor of CPU, the tensor is NCHW type with shape of
 *  [1,hiddenSize,1,1],supporting the data of float16 type.
 *  @param[in] input_bias
 *    Input. Pointer array pointing to Bias matrix multiplied by RNN input.
 *  @param[in] state_bias_tensor
 *    Input. NumLayers 4-dimensional constant tensor of, the tensor is NCHW type with shape of
 *  [1,hiddenSize,1,1],supporting the data of float16 type.
 *  @param[in] state_bias
 *    Input. Pointer array pointing to Bias matrix multiplied by RNN state input.
 *  @param[in] active_func
 *    Input. Input specifies which activation function to be used. It can be any activation function
 *  that CNML already supports.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBasicRNNProOpForward(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *state_input[],
                                                          void *output,
                                                          void *state_output[],
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  This interface is used to compute basic RNN on CPU;if all parameters in the interface are array
 *  type, all arrays include num_layers elements, and the element with subscript 0 in arrays
 *  corresponds to the first layer, the element with subscript 1 corresponds to the second layer,
 *  and so on.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] state_input_tensors
 *    Input. MLU tensor pointer array. Pass NULL if not used.
 *  @param[in] state_input
 *    Input. MLU address array pointing to state_input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] state_output_tensor
 *    Input.  State_Output MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] state_output
 *    Output. MLU address array pointing to state_output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBasicRNNProOpForward_V2(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t state_input_tensors[],
                                                             void *state_input[],
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnmlTensor_t state_output_tensors[],
                                                             void *state_output[],
                                                             cnrtQueue_t queue,
                                                             void *extra);
/*basic rnn pro operation end */

/* gru operation start */
/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a GRU operator is created.
 *
 *  gru(gated recurrent unit)  operator is a variant of LSTM. gru has no cell, but only reset gate
 *  and update gate, which is simpler than LSTM struct.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct describing the parameter of RNN operator.
 *  @param[in] input_tensor
 *    Input. A 3-dimensional input tensor of MLU, the shape is [t, n, ci], supporting the data of
 *  float16 type.
 *  @param[in] state_input_tensor
 *    Input. A state input tensor array of MLU with the length of the number of layers of gru, the
 *  shape of each tensor is [n, 1, 1,co],supporting the data of float16 type.
 *  @param[in] rx_weight_tensor
 *    Input. A reset gate input weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,ci],supporting the data of float16 type.
 *  @param[in] rh_weight_tensor
 *    Input. A reset gate state weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,co],supporting the data of float16 type.
 *  @param[in] rx_bias_tensor
 *    Input. A reset gate input bias tensor array of MLU with the length of the number of layers of
 *  gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] rh_bias_tensor
 *    Input. A reset gate state bias tensor array of MLU with the length of the number of layers of
 *  gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] zx_weight_tensor
 *    Input. An update gate input weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,ci],supporting the data of float16 type.
 *  @param[in] zh_weight_tensor
 *    Input. An update gate state weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,co],supporting the data of float16 type.
 *  @param[in] zx_bias_tensor
 *    Input. An update gate input bias tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] zh_bias_tensor
 *    Input. An update gate state bias tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] nx_weight_tensor
 *    Input. An input weight tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1,1, ci],supporting the data of float16
 *  type.
 *  @param[in] nh_weigh_tensor
 *    Input. A state weight tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1,co],supporting the data of float16
 *  type.
 *  @param[in] nx_bias_tensor
 *    Input. An input bias tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16
 *  type.
 *  @param[in] nh_bias_tenosr
 *    Input. A state bias tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16
 *  type.
 *  @param[in] output_tensor
 *    Input. An output tensor of MLU, the shape is [n, 1, 1,co],supporting the data of float16 type.
 *  @param[in] state_output_tensor
 *    Input. A state output tensor array of MLU, and the length of array is the number of gru
 *  layers, the shape of each tensor is [n, 1, 1,co],supporting the data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Any input is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGRUOp(cnmlBaseOp_t *op,
                                          cnmlRNNOpParam_t param,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t state_input_tensor[],
                                          cnmlTensor_t output_tensor,
                                          cnmlTensor_t state_ouput_tensor[],
                                          cnmlTensor_t rx_weight_tensor[],
                                          cnmlTensor_t rh_weight_tensor[],
                                          cnmlTensor_t rx_bias_tensor[],
                                          cnmlTensor_t rh_bias_tensor[],
                                          cnmlTensor_t zx_weight_tensor[],
                                          cnmlTensor_t zh_weight_tensor[],
                                          cnmlTensor_t zx_bias_tensor[],
                                          cnmlTensor_t zh_bias_tensor[],
                                          cnmlTensor_t nx_weight_tensor[],
                                          cnmlTensor_t nh_weight_tensor[],
                                          cnmlTensor_t nx_bias_tensor[],
                                          cnmlTensor_t nh_bias_tensor[]);
/*!
 *  @brief A function.
 *
 *  The basic recurrent neural network operator, input, output, parameter at runtime, and
 *  computational queue are created and called, and GRU operation is performed on the MLU.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGRUOpForward_V2 is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] state_input
 *    Input. An MLU address points to state_input data array.
 *  @param[in] state_output
 *    Input. An MLU address points to state_output data array.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 *    - output is a null pointer.
 *    - state_output is a null pointer.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGRUOpForward(cnmlBaseOp_t op,
                                                  void *input,
                                                  void *state_input[],
                                                  void *output,
                                                  void *state_output[],
                                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                                  cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  The basic recurrent neural network operator, input, output, parameter at runtime, and
 *  computational queue are created and called, and GRU operation is performed on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] state_input_tensors
 *    Input. State input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] state_input
 *    Input. MLU address pointing to state_input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] state_output_tensors
 *    Input.  State_output MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] state_ouput
 *    Output. MLU address pointing to output array position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGRUOpForward_V2(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t state_input_tensors[],
                                                     void *state_input[],
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnmlTensor_t state_output_tensors[],
                                                     void *state_output[],
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* gru operation end*/

/* gru pro operation start */

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a GRU operator is created.
 *
 *  gru(gated recurrent unit)  operator is a variant of LSTM. gru has no cell, but only reset gate
 *  and update gate, which is simpler than LSTM struct.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct describing the parameter of RNN operator.
 *  @param[in] gru_mode
 *    Input. An enumeration value representing the mode of gru operation.
 *  @param[in] input_tensor
 *    Input. A 3-dimensional input tensor of MLU, the shape is [t, n, ci], supporting the data of
 *  float16 type.
 *  @param[in] state_input_tensor
 *    Input. A state input tensor array of MLU with the length of the number of layers of gru, the
 *  shape of each tensor is [n, 1, 1,co],supporting the data of float16 type.
 *  @param[in] rx_weight_tensor
 *    Input. A reset gate input weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,ci],supporting the data of float16 type.
 *  @param[in] rh_weight_tensor
 *    Input. A reset gate state weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,co],supporting the data of float16 type.
 *  @param[in] rx_bias_tensor
 *    Input. A reset gate input bias tensor array of MLU with the length of the number of layers of
 *  gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] rh_bias_tensor
 *    Input. A reset gate state bias tensor array of MLU with the length of the number of layers of
 *  gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] zx_weight_tensor
 *    Input. An update gate input weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,ci],supporting the data of float16 type.
 *  @param[in] zh_weight_tensor
 *    Input. An update gate state weight tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1,co],supporting the data of float16 type.
 *  @param[in] zx_bias_tensor
 *    Input. An update gate input bias tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] zh_bias_tensor
 *    Input. An update gate state bias tensor array of MLU with the length of the number of layers
 *  of gru, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16 type.
 *  @param[in] nx_weight_tensor
 *    Input. An input weight tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1,1, ci],supporting the data of float16
 *  type.
 *  @param[in] nh_weigh_tensor
 *    Input. A state weight tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1,co],supporting the data of float16
 *  type.
 *  @param[in] nx_bias_tensor
 *    Input. An input bias tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16
 *  type.
 *  @param[in] nh_bias_tenosr
 *    Input. A state bias tensor array of MLU in candidate state, and the length of array is the
 *  number of gru layers, the shape of each tensor is [co, 1, 1, 1], supporting the data of float16
 *  type.
 *  @param[in] output_tensor
 *    Input. An output tensor of MLU, the shape is [n, 1, 1,co],supporting the data of float16 type.
 *  @param[in] state_output_tensor
 *    Input. A state output tensor array of MLU, and the length of array is the number of gru
 *  layers, the shape of each tensor is [n, 1, 1,co],supporting the data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Any input is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGRUProOp(cnmlBaseOp_t *op,
                                             cnmlRNNOpParam_t param,
                                             cnmlGRUMode_t gru_mode,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t state_input_tensor[],
                                             cnmlTensor_t output_tensor,
                                             cnmlTensor_t state_ouput_tensor[],
                                             cnmlTensor_t rx_weight_tensor[],
                                             cnmlTensor_t rh_weight_tensor[],
                                             cnmlTensor_t rx_bias_tensor[],
                                             cnmlTensor_t rh_bias_tensor[],
                                             cnmlTensor_t zx_weight_tensor[],
                                             cnmlTensor_t zh_weight_tensor[],
                                             cnmlTensor_t zx_bias_tensor[],
                                             cnmlTensor_t zh_bias_tensor[],
                                             cnmlTensor_t nx_weight_tensor[],
                                             cnmlTensor_t nh_weight_tensor[],
                                             cnmlTensor_t nx_bias_tensor[],
                                             cnmlTensor_t nh_bias_tensor[]);
/*!
 *  @brief A function.
 *
 *  The basic recurrent neural network operator, input, output, parameter at runtime, and
 *  computational queue are created and called, and GRU operation is performed on the MLU.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGRUProOpForward_V2 is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] state_input
 *    Input. An MLU address points to state_input data array.
 *  @param[in] state_output
 *    Input. An MLU address points to state_output data array.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 *    - output is a null pointer.
 *    - state_output is a null pointer.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGRUProOpForward(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *state_input[],
                                                     void *output,
                                                     void *state_output[],
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  The basic recurrent neural network operator, input, output, parameter at runtime, and
 *  computational queue are created and called, and GRU operation is performed on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] state_input_tensors
 *    Input. State input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] state_input
 *    Input. MLU address pointing to state_input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] state_output_tensors
 *    Input.  State output MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] state_output
 *    Output. An MLU address pointing to state_output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGRUProOpForward_V2(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t state_input_tensors[],
                                                        void *state_input[],
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnmlTensor_t state_output_tensors[],
                                                        void *state_output[],
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* gru pro operation end*/

/* sequence_mask operation start */
/*!
 *  @struct cnmlSequenceMaskOpParam
 *  @brief A struct.
 *
 *  The cnmlSequenceMaskOpParam is a structure describing the param parameter of SequenceMask
 *  operation, used to create deconv operation. cnmlCreateSequenceMaskOpParam() is used to
 *  create an instance of cnmlSequenceMaskOpParam_t. cnmlDestroySequenceMaskOpParam() is used to
 *  destroy an instance of cnmlSequenceMaskOpParam_t. */
struct cnmlSequenceMaskOpParam;
/*! ``cnmlSequenceMaskOpParam_t`` is a pointer to ``cnmlSequenceMaskOpParam`` which is a
    structure holding the description of a SequenceMask operation param. */
typedef struct cnmlSequenceMaskOpParam *cnmlSequenceMaskOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, this function creates a struct of RNN operator
 *  operation parameters, and fills in the struct with parameters input by the user.
 *
 *
 *  @param[in] param
 *    Input. A pointer pointing to another pointer, and the pointed pointer points to a struct
 *  describing the operation parameters of SequenceMask operators.
 *  @param[in] use_sequence_length
 *    Input. A bool variable determins whethter to use variable sequence_length or not. If it is
 *  false, this operation works as identity operator.
 *  @param[in] sequence_length
 *    Input. A pointer pointing to a int array of dimension of batch size, which specifys the
 *  variable sequence length.
 *  @param[in] axis
 *    Input. A int variable to specify the sequence axis in input.
 *  @param[in] value
 *    Input. A float variable. The elements out of the sequence length would be replaced by this
 *  value
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateSequenceMaskOpParam(cnmlSequenceMaskOpParam_t *param,
                                                        bool use_sequence_length,
                                                        int sequence_length[],
                                                        int axis,
                                                        float value);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the SequenceMask operator
 *  operation parameter is freed.
 *
 *
 *  @param[in] param
 *    Input. A pointer pointing to another pointer, and the pointed pointer points to a struct
 *  describing the operation parameters of SequenceMask operators.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */

CNML_DLL_API cnmlStatus_t cnmlDestroySequenceMaskOpParam(cnmlSequenceMaskOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a SequenceMask operator is created.
 *
 *  After a pointer pointing to the address of base operator, the operation parameter of sequence
 *  mask operator and input-output tensor are created, they are introduced into the function to
 *  create the sequence mask operator.
 *
 *  Before the sequence mask operator is created, a pointer pointing to the address of the sequence
 *  mask operator parameter struct is declared, and the pointer and required operator parameter are
 *  introduced to the function to set the operator parameter.
 *
 *  The sequence mask operator set all elements outside the sequence to a constant value.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct describing the parameter of SequenceMask operator.
 *  @param[in] input_tensor
 *    Input. A 3-dimensional input tensor of MLU, the shape is [max_sequence_length, batch_size,
 *  other_feature_dims] or [batch_size, max_sequence_length, other_feature_dims], supporting the
 *  data of float16 and float32 type.
 *  @param[in] output_tensor
 *    Input. An output tensor of MLU, and its shape is the same as that of input_tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Any input is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateSequenceMaskOp(cnmlBaseOp_t *op,
                                                   cnmlSequenceMaskOpParam_t param,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  The SequenceMask operator, input, output, parameter at runtime, and
 *  computational queue are created and called, and SequenceMask operation is performed on the MLU.
 *
 *  **Summary**
 *
 *  For input[ti, ni, ci] in input[t, n, c],
 *
 *  if use_sequence_length,
 *
 *  output[ti, ni, ci] = ti < sequence_length[ni]? input[ti, ni, ci] : value
 *
 *  if not use_sequence_lenth,
 *
 *  output[ti, ni, ci] = input[ti, ni, ci]
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      in_type-in_oc_type-out_oc_type-out_type
 *
 *      float16-float16   -float16    -float16
 *
 *      float32-float32   -float32    -float32
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      Unlimited
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @param[in] extra
 *    Input. A pointer reserved for future use
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 *    - output is a null pointer.
 *    - state_output is a null pointer.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSequenceMaskOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);

/* sequence_mask operation end */

/* deconv operation start */
/*!
 *  @struct cnmlDeconvOpParam
 *  @brief A struct.
 *
 *  cnmlDeconvOpParam is a structure describing the param parameter of deconv operation, used to
 *  create deconv operation. cnmlCreateDeconvOpParam() and cnmlCreateDeconvOpParam_V2() is used to
 *  create an instance of cnmlDeconvOpParam_t. cnmlDestroyDeconvOpParam() is used to destroy an
 *  instance of cnmlDeconvOpParam_t. */
struct cnmlDeconvOpParam;
/*! ``cnmlDeconvOpParam_t`` is a pointer to ``cnmlDeconvOpParam`` which is a
    structure holding the description of a deconv operation param. */
typedef struct cnmlDeconvOpParam *cnmlDeconvOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of deconvolution
 *  operator operation parameters, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of deconvolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] hu_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the upside of
 *  the hw data block.
 *  @param[in] hd_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the down side of
 *  the hw data block.
 *  @param[in] wl_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the left
 *  side of the hw block.
 *  @param[in] wr_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the right
 *  side of the hw block.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateDeconvOpParam(cnmlDeconvOpParam_t *param,
                                                  int stride_height,
                                                  int stride_width,
                                                  int hu_crop,
                                                  int hd_crop,
                                                  int wl_crop,
                                                  int wr_crop);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of deconvolution
 *  operator operation parameters, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of deconvolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] hu_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the upside of
 *  the hw data block.
 *  @param[in] hd_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the down side of
 *  the hw data block.
 *  @param[in] wl_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the left
 *  side of the hw block.
 *  @param[in] wr_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the right
 *  side of the hw block.
 *  @param[in] adj_h
 *    Input. A value greater than or equal to zero, number of data columns supplemented in the row
 *  direction of the hw data block.
 *  @param[in] adj_w
 *    Input. A value greater than or equal to zero, number of data rows supplemented in the column
 *  direction of the hw data block.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvOpParam_V2(cnmlDeconvOpParam_t *param,
                                                     int stride_height,
                                                     int stride_width,
                                                     int hu_crop,
                                                     int hd_crop,
                                                     int wl_crop,
                                                     int wr_crop,
                                                     int adj_w,
                                                     int adj_h);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of deconvolution
 *  operator operation parameters, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of deconvolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] hu_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the upside of
 *  the hw data block.
 *  @param[in] hd_crop
 *    Input. A value greater than or equal to zero, number of rows to be removed on the down side of
 *  the hw data block.
 *  @param[in] wl_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the left
 *  side of the hw block.
 *  @param[in] wr_crop
 *    Input. A value greater than or equal to 0, and the number of rows to be removed on the right
 *  side of the hw block.
 *  @param[in] adj_h
 *    Input. A value greater than or equal to zero, number of data columns supplemented in the row
 *  direction of the hw data block.
 *  @param[in] dila_h
 *    Input. A value greater than or equal to 1, the dilation factor of kernel in height dimension.
 *  @param[in] dila_w
 *    Input. A value greater than or equal to 1, the dilation factor of kernel in width dimension
 *  @param[in] adj_w
 *    Input. A value greater than or equal to zero, number of data rows supplemented in the column
 *  direction of the hw data block.

 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateDeconvOpParam_V3(cnmlDeconvOpParam_t *param,
                                                     int stride_height,
                                                     int stride_width,
                                                     int hu_crop,
                                                     int hd_crop,
                                                     int wl_crop,
                                                     int wr_crop,
                                                     int adj_w,
                                                     int adj_h,
                                                     int dila_h,
                                                     int dila_w);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the deconvolution operator
 *  operation parameter is freed.
 *
 *  At the end of the convolution operator operation, the created struct pointer of the
 *  deconvolution operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of the struct of deconvolution operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyDeconvOpParam(cnmlDeconvOpParam_t *param);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateDeconvOpForward is recommended to use.
 *
 *  According to the basic operator pointer given by the user, a deconvolution operator is created.
 *
 *  After the pointer pointing to the address of the base operator, the deconvolution operator
 *  parameters and the input-output tensor are created, they are introduced into the function to
 *  create the deconvolution operator.
 *
 *  Before the deconvolution operator is created, a pointer pointing to the address of the
 *  deconvolution operator parameter struct is declared and the required operator parameters are
 *  introduced into the function to set the operator parameters.
 *
 *  Deconvolution operator.deconv operator can be transformed into conv operator. Firstly, for the
 *  h-w plane, 0 is inserted between two adjacent valid input values (stride_width - 1 0 are filled
 *  between two adjacent values in the w direction, and stride_height - 1 0 are filled between
 *  adjacent values in the h direction.) Meanwhile, the input kernal is also changed: firstly, the
 *  data of n and c dimensions are exchanged; secondly, the data of each plane in the h-w plane is
 *  rotated 180 degrees by the center of the plane; finally, the processed input and weight are used
 *  for convolution operation (the stride in both the h and w directions of the conv operation is 1,
 *  h_top_padding and h_bottom_padding are hf-1,w_left_padding and w_right_padding are wf-1, hf and
 *  wf are the size of dimensions of weight h and w respectively).
 *
 *  The crop operation is performed on the result after convolution, and if the bias is not null,
 *  add the bias to get the output of deconv.
 *
 *  If the weight is less than step, that is, hf < stride_height, wf < stride_wight, then add 0 to
 *  weight so that weight=step.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct of a deconvolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co],supporting data of
 *  float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, hf, wf, cf] (nf = ci, cf =
 *  co),supporting data of float16 type.
 *  @param[in] bias_filter
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, hb, wb, cb](nb = hb = wb = 1, cb =
 *  co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - param is null.
 *    - input_tensor is null.
 *    - output_tensor is null.
 *    - filter_tensor is null.
 *    - when the bias tensor is not null, the CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvOp(cnmlBaseOp_t *op,
                                             cnmlDeconvOpParam_t param,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor,
                                             cnmlTensor_t filter_tensor,
                                             cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a deconvolution operator is created.
 *
 *  After the pointer pointing to the address of the base operator, the deconvolution operator
 *  parameters and the input-output tensor are created, they are introduced into the function to
 *  create the deconvolution operator.
 *
 *  Before the deconvolution operator is created, a pointer pointing to the address of the
 *  deconvolution operator parameter struct is declared and the required operator parameters are
 *  introduced into the function to set the operator parameters.
 *
 *  Deconvolution operator.deconv operator can be transformed into conv operator. Firstly, for the
 *  h-w plane, 0 is inserted between two adjacent valid input values (stride_width - 1 0 are filled
 *  between two adjacent values in the w direction, and stride_height - 1 0 are filled between
 *  adjacent values in the h direction.) Meanwhile, the input kernal is also changed: firstly, the
 *  data of n and c dimensions are exchanged; secondly, the data of each plane in the h-w plane is
 *  rotated 180 degrees by the center of the plane; finally, the processed input and weight are used
 *  for convolution operation (the stride in both the h and w directions of the conv operation is 1,
 *  h_top_padding and h_bottom_padding are hf-1,w_left_padding and w_right_padding are wf-1, hf and
 *  wf are the size of dimensions of weight h and w respectively).
 *
 *  The crop operation is performed on the result after convolution, and if the bias is not null,
 *  add the bias to get the output of deconv.
 *
 *  If the weight is less than step, that is, hf < stride_height, wf < stride_wight, then add 0 to
 *  weight so that weight=step.
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct of a deconvolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co],supporting data of
 *  float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, hf, wf, cf] (nf = ci, cf =
 *  co),supporting data of float16 type.
 *  @param[in] bias_filter
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, hb, wb, cb](nb = hb = wb = 1, cb =
 *  co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - param is null.
 *    - input_tensor is null.
 *    - output_tensor is null.
 *    - filter_tensor is null.
 *    - when the bias tensor is not null, the CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvOpForward(cnmlBaseOp_t *op,
                                                    cnmlDeconvOpParam_t param,
                                                    cnmlTensor_t input_tensor,
                                                    cnmlTensor_t output_tensor,
                                                    cnmlTensor_t filter_tensor,
                                                    cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeDeConvOpForward_V4 is recommended to use.
 *
 *  Computing user-specified first-level convolution operator on MLU.
 *
 *  After the first-level convolution operator, input, output, parameter at runtime, and
 *  computational queue are created, they are introduced into the function to compute the
 *  first-level convolution operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeconvOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified first-level convolution operator on MLU.
 *
 *  After the first-level convolution operator, input, output, parameter at runtime, and
 *  computational queue are created, they are introduced into the function to compute the
 *  first-level convolution operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeconvOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);

/* deconv operation end */

/* Ndconv operation start */
/*!
 *  @struct cnmlNdConvParam
 *  @brief A struct.
 *
 *  cnmlNdConvParam is a structure holding the description of a nd-convolution
 *  operation param that is used  to create  a nd-convolution operation.
 *  cnmlCreateNdConvParam() is used to create an instance of
 *  cnmlNdConvParam_t.
 *  cnmlDestroyNdConvParam() is used to destroy an instance of cnmlNdConvParam_t. */
struct cnmlNdConvParam;
/*! ``cnmlNdConvParam_t`` is a pointer to ``cnmlNdConvParam`` which is a
    structure holding the description of a nd-convolution operation param. */
typedef struct cnmlNdConvParam *cnmlNdConvParam_t;

/*!
 *  @brief A function.
 *
 *  Creates a nd-convolution param object for holding the structure of the
 *  nd-convolution operator.
 *
 *  @param[out] param
 *    Output. A pointer to the struct of the nd-convolution operation parameter.
 *  operation parameter.
 *  @param[in] dilations
 *    Input. An integer array specifies the dilation factor of kernel. The array values
 *    should be greater than or equal to 0, and values should be setted by NCDHW order.
 *  @param[in] strides
 *    Input. An integer array specifies the stride factor of kernel. The array values
 *    should be greater than or equal to 0, and values should be setted by NCDHW order.
 *  @param[in] paddings
 *    Input. An integer array. The dimensions of the tensor are integer tensors with
 *    shape [Dn, 2], where n is the ndims of the input, and the array value   should be
 *    setted by NCDHW order. For each dimension D of the input, paddings[D, 0] specifies
 *    the number of extra zeros concatenated at the start of the input in that dimension.
 *    The paddings[D, 1] specifies the number of extra zeros concatenated at the end of
 *    the input in that dimension.
 *    The following formula specifies the padding size of each dimension D of the output.
 *    paddings(D, 0) + input.dim_size(D) + paddings(D, 1)
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The param pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdConvParam(cnmlNdConvParam_t *param,
                                                int array_length,
                                                int dilations[],
                                                int strides[],
                                                int paddings[][2]);

/*!
 *  @brief A function.
 *
 *  Creates a nd-convolution param object according to data order.
 *
 *  @param[out] param
 *    Output. A pointer to the struct of the nd-convolution operation parameter.
 * operation
 *  parameter.
 *  @param[in] date_order
 *    input. An enum variable indicating the order of param's value, only NCHW, NHWC, NCDHW, and
 *    NDHWC are supported currently. And the length of dilations, strides and paddings should
 *    match the length of data_order.
 *  @param[in] dilations
 *    Input. An integer array specifies the dilation factor of kernel. The array values
 *    should be greater than or equal to 0.
 *  @param[in] strides
 *    Input. An integer array specifies the stride factor of kernel. The array values
 *    should be greater than or equal to 0.
 *  @param[in] paddings
 *    Input. An integer array. The dimensions of the tensor are integer tensors with
 *    shape [Dn, 2], where n is the ndims of the input. For each dimension D of the input,
 *    paddings[D, 0] specifies the number of extra zeros concatenated at the start of the input in
 *    that dimension. The paddings[D, 1] specifies the number of extra zeros concatenated at
 *    the end of the input in that dimension.
 *    The following formula specifies the padding size of each dimension D of the output.
 *    paddings(D, 0) + input.dim_size(D) + paddings(D, 1)
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The param pointer is NULL.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdConvParam_V2(cnmlNdConvParam_t *param,
                                                   cnmlDataOrder_t data_order,
                                                   int dilations[],
                                                   int strides[],
                                                   int paddings[][2]);

/*!
 *  @brief A function.
 *
 *  Destroys the previously created nd-convolution operator param descriptor.
 *
 *  At the end of the nd-convolution operator operation, the struct pointer of the nd-convolution
 *  operator operation parameter is freed.
 *
 *  @param[in] param
 *    Input. A pointer to the nd-convolution operator param you want to destroy.
 *  @retval CNML_STATUS_SUCCESS
 *    The descriptor destroyed successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The param pointer is NULL.
 *    - The nd-convolution operator param that the pointer pointed has already destroyed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNdConvParam(cnmlNdConvParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, a nd-convolution operator is created.
 *
 *  After a pointer pointing to the address of base operator, the operation parameter of
 *  nd-convolution
 *  operator and input-output tensor are created, they are introduced into the function to create
 *  the nd-convolution operator.
 *
 *  Before the nd-convolution operator is created, a pointer pointing to the address of the
 *  nd-convolution
 *  operator parameter struct is declared, and the pointer and required operator parameter are
 *  introduced to the function to set the operator parameter.
 *
 *  A simple 3-dimensional convolution can be seen as a process that a 3-dimensional convolution
 *  kernel (weight matrix) slides on 3-dimensional input data, matrix multiplication is performed on
 *  some of the elements currently input, and then the results are summed into a single input pixel.
 *  The nd-convolution kernel repeats this process until it traverses the entire picture and
 *  converts a
 *  3-dimensional matrix into another. The special operation padding is equivalent to filling the
 *  edge of the input data with 0 , and stride refers to the sliding step of the nd-convolution
 *  kernel.
 *
 *  The n-dimension and c-dimension generally refer to batch and channel, and d-dimension generally
 *  refer to depth.
 *  The general nd-convolution operation (5-dimensional convolution) can be seen as a process that
 *  the input and weight of a
 *  batch is taken, and nd-convolution operation is performed on the 3-dimensional inputs and
 *  nd-convolution kernels of different channels, the computation results of different channels are
 *  added to get the output of the batch, after all the batches are completed, the bias is added to
 *  get the output.
 *
 *  The length of the weight in the Height direction must be less than or equal to the length of the
 *  input in the Height direction. The length of the weight in the Width direction must be less than
 *  or equal to the length of the input in the Width direction.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer struct of nd-convolution operation.
 *  @param[in] input_tensor
 *    Input. A 5-dimensional MLU input tensor, the shape is [ni, di, hi, wi, ci].
 *  @param[in] output_tensor
 *    Input. A 5-dimensional MLU output tensor, the shape is [no, do, ho, wo, co](no = ni).
 *  @param[in] filter_tensor
 *    Input. A 5-dimensional MLU weight tensor, the shape is [nf, df, hf, wf, cf] (nf = co, cf =
 *  ci).
 *  @param[in] bias_tensor
 *    Input. A 5-dimensional MLU bias tensor, the shape is [nb, db, hb, wb, cb] (nb = 1, db, hb = 1,
 * wb = 1, cb = co).
 *  @param[in] mean_tensor
 *    Input. A 5-dimensional MLU mean tensor.
 *  @param[in] stdt_tensor
 *    Input. A 5-dimensional MLU stdt tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdConvOp(cnmlBaseOp_t *op,
                                             cnmlConvMode_t conv_mode,
                                             cnmlNdConvParam_t param,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor,
                                             cnmlTensor_t filter_tensor,
                                             cnmlTensor_t bias_tensor,
                                             cnmlTensor_t mean_tensor,
                                             cnmlTensor_t stdt_tensor);

/*!
 *  @brief A function.
 *
 *  Computing user-specified nd-convolution operators on MLU.
 *
 *  After the nd-convolution operator, input, output, and computational queue are created, they are
 *  introduced into the function to compute the nd-convolution operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdConvOpForward_V2(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* conv operation start */
/*!
 *  @struct cnmlConvOpParam
 *  @brief A struct.
 *
 *  cnmlConvOpParam is a structure describing the param parameter of conv operation, used to create
 *  conv operation. cnmlCreateConvOpParam() is used to create an instance of cnmlConvOpParam_t.
 *  cnmlDestroyConvOpParam() is used to destroy an instance of cnmlConvOpParam_t. */
struct cnmlConvOpParam;
/*! ``cnmlConvOpParam_t`` is a pointer to ``cnmlConvOpParam`` which is a
    structure holding the description of a Conv operation param. */
typedef struct cnmlConvOpParam *cnmlConvOpParam_t;

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  This function fills cnmlConvOpParam_t struct with the convolution operation parameters input by
 *  the user, and return to the user.
 *
 *  This function allocates param memory, and after usage is done, the user needs to call
 *  cnmlDestroyConvOpParam destroy param parameters.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of the convolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] dilation_height
 *    Input. A value greater than or equal to 1, the dilation factor of kernel (that is, weight
 *  tensor) in height dimension.
 *  @param[in] dilation_width
 *    Input. A value greater than or equal to 1, the dilation factor of kernel (that is, weight
 *  tensor) in weight dimension.
 *  @param[in] pad_height
 *    Input. Pad length.
 *  @param[in] pad_width
 *    Input. Pad width.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvOpParam(cnmlConvOpParam_t *param,
                                                int stride_height,
                                                int stride_width,
                                                int dilation_height,
                                                int dilation_width,
                                                int pad_height,
                                                int pad_width);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Free the struct pointer of convolution operator operation parameter according to the pointer
 *  given by the user.
 *
 *  At the end of the convolution operator operation, the struct pointer of the convolution operator
 *  operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of the struct of the convolution operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyConvOpParam(cnmlConvOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateConvOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user, a convolution operator is created.
 *
 *  After a pointer pointing to the address of base operator, the operation parameter of convolution
 *  operator and input-output tensor are created, they are introduced into the function to create
 *  the convolution operator.
 *
 *  Before the convolution operator is created, a pointer pointing to the address of the convolution
 *  operator parameter struct is declared, and the pointer and required operator parameter are
 *  introduced to the function to set the operator parameter.
 *
 *  A simple 2-dimensional convolution can be seen as a process that a 2-dimensional convolution
 *  kernel (weight matrix) slides on 2-dimensional input data, matrix multiplication is performed on
 *  some of the elements currently input, and then the results are summed into a single input pixel.
 *  The convolution kernel repeats this process until it traverses the entire picture and converts a
 *  2-dimensional matrix into another. The special operation padding is equivalent to filling the
 *  edge of the input data with 0 (filling padding_height/2 0 in the height direction,
 *  padding_weight/2 0 in the weight direction), and stride refers to the sliding step of the
 *  convolution kernel.
 *
 *  The n-dimension and c-dimension generally refer to batch and channel. The general convolution
 *  operation (4-dimensional convolution) can be seen as a process that the input and weight of a
 *  batch is taken, and convolution operation is performed on the 2-dimensional inputs and
 *  convolution kernels of different channels, the computation results of different channels are
 *  added to get the output of the batch, after all the batches are completed, the bias is added to
 *  get the output.
 *
 *  hf <= hi,wf <= wi
 *
 *  if (dilation_height > 1 || dilation_width > 1) pad_height == 0 && pad_width == 0
 *
 *  The length of the weight in the Height direction must be less than or equal to the length of the
 *  input in the Height direction. The length of the weight in the Width direction must be less than
 *  or equal to the length of the input in the Width direction.
 *
 *  If dilation factor of Height dimension or dilation factor of Width dimension is greater than 1,
 *  the pad length in the Height direction and the Width direction is greater than 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer struct of convolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co](no = ni),supporting
 *  data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, hf, wf, cf] (nf = co, cf =
 *  ci),supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, hb, wb, cb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvOp(cnmlBaseOp_t *op,
                                           cnmlConvOpParam_t param,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor,
                                           cnmlTensor_t filter_tensor,
                                           cnmlTensor_t bias_tensor);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  According to the base operator pointer given by the user, a convolution operator is created.
 *
 *  After a pointer pointing to the address of base operator, the operation parameter of convolution
 *  operator and input-output tensor are created, they are introduced into the function to create
 *  the convolution operator.
 *
 *  Before the convolution operator is created, a pointer pointing to the address of the convolution
 *  operator parameter struct is declared, and the pointer and required operator parameter are
 *  introduced to the function to set the operator parameter.
 *
 *  2-D Convolution
 *
 *  A simple 2-dimensional convolution can be seen as a process that a 2-dimensional convolution
 *  kernel (weight matrix) slides on 2-dimensional input data, matrix multiplication is performed on
 *  some of the elements currently input, and then the results are summed into a single input pixel.
 *  The convolution kernel repeats this process until it traverses the entire picture and converts a
 *  2-dimensional matrix into another. The special operation padding is equivalent to filling the
 *  edge of the input data with 0 (filling padding_height/2 0 in the height direction,
 *  padding_weight/2 0 in the weight direction), and stride refers to the sliding step of the
 *  convolution kernel.
 *
 *  N-D Convolution
 *
 *  The n-dimension and c-dimension generally refer to batch and channel. The general convolution
 *  operation (4-dimensional convolution) can be seen as a process that the input and weight of a
 *  batch is taken, and convolution operation is performed on the 2-dimensional inputs and
 *  convolution kernels of different channels, the computation results of different channels are
 *  added to get the output of the batch, after all the batches are completed, the bias is added to
 *  get the output.
 *
 *  hf <= hi,wf <= wi
 *
 *  if (dilation_height > 1 || dilation_width > 1) pad_height == 0 && pad_width == 0
 *
 *  The length of the weight in the Height direction must be less than or equal to the length of the
 *  input in the Height direction. The length of the weight in the Width direction must be less than
 *  or equal to the length of the input in the Width direction.
 *
 *  If dilation factor of Height dimension or dilation factor of Width dimension is greater than 1,
 *  the pad length in the Height direction and the Width direction is greater than 1.
 *
 *  **Summary**
 *
 *  If the shape of an input tensor is [batch, in_height, in_width, in_channels] and the shape of a
 *  filter
 *
 *  tensor or a kernel tensor is [filter_height, filter_width, in_channels, out_channels],
 *  with the default NHWC format.
 *
 *  output[b, i, j, k] =
 *      sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
 *      filter[di, dj, q, k]
 *
 *  Ph = p_top + p_botton
 *
 *  Pw = p_left + p_right
 *
 *  Ho = (Hi + Ph - dh(Kh - 1) -1) / Sh + 1
 *
 *  Wo = (Wi + Pw - dw(Kw - 1) -1)/ Sw + 1
 *
 *  co = K
 *
 *  where ``di`` is the dialation in h dimension, ``dj`` is the dialation in w dimension,
 *  ``q`` is control variable in ci dimension, ``k`` is the variable in co dimension, ``Ph``
 *  is the size of the padding in h dimension, ``Pw`` is the size of the padding in w
 *  dimension, ``Ho`` is the height of the output tensor, ``Wo`` is the width of the output
 *  tensor, ``co`` is the channel of the output tensor, ``Hi`` is the height of the
 *  input tensor, ``dh`` is the dilation in h dimension, ``Kh`` is the height of the kernel
 *  ``Sh`` is height of the stride, ``Wi`` is the width of the input tensor, ``dw`` is the
 *  dilation in w dimension, ``Kw`` is the width of the kernel, ``Sw`` is the stride in w
 *  dimension, and ``k`` is the number of channels for output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type : Data type of the input tensor.
 *
 *      filter_type : Data type of the filter tensor.
 *
 *      bias_type : Data type of the bias tensor.
 *
 *      output_type : Data type of the output tensor.
 *
 *      in_oc_type : Data type of the input tensor used for computing.
 *
 *      filter_oc_type : Data type of the filter tensor used for computing.
 *
 *      bias_oc_type : Data type of the bias tensor used for computing.
 *
 *      output_oc_type : Data type of the output tensor used for computing.
 *
 *      If filter_type is int8, then input_type can be int8 or int16, and output_type can be
 *      float16,
 *      float32, or int16.
 *
 *      If filter_type is int16, then input_type can be int16, and output_type can be float16,
 *      float32, or int16.
 *
 *      **Notes:** The data type you set in bias_oc_type, bias_type, and out_oc_type must be the
 *      same.
 *
 *      The supported combinations of the data type of the tensors are as follows. The data type
 *      are shown in the following order:
 *
 *      input_type - input_oc_type - filter_type - filter_oc_type - out_oc_type - out_type
 *
 *      Supported combinations are:
 *
 *      int8-int8-int8-int8-float16-float16;
 *
 *      int8-int8-int8-int8-float16-int8;
 *
 *      int8-int8-int8-int8-float32-float32;
 *
 *      int8-int8-int8-int8-float32-int8;
 *
 *      float16-int8-int8-int8-float16-float16;
 *
 *      float16-int8-int8-int8-float16-int8;
 *
 *      float32-int8-int8-int8-float32-float32;
 *
 *      float32-int8-int8-int8-float32-int8;
 *
 *      int16-int16-int8-int8-float16-float16;
 *
 *      int16-int16-int8-int8-float16-int16;
 *
 *      int16-int16-int8-int8-float32-float32;
 *
 *      int16-int16-int8-int8-float32-int16;
 *
 *      float16-int16-int8-int8-float16-float16;
 *
 *      float16-int16-int8-int8-float16-int16;
 *
 *      float32-int16-int8-int8-float32-float32;
 *
 *      float32-int16-int8-int8-float32-int16;
 *
 *      int16-int16-int16-int16-float16-float16;
 *
 *      int16-int16-int16-int16-float16-int16;
 *
 *      int16-int16-int16-int16-float32-float32;
 *
 *      int16-int16-int16-int16-float32-int16;
 *
 *      float16-int16-int16-int16-float16-float16;
 *
 *      float16-int16-int16-int16-float16-int16;
 *
 *      float32-int16-int16-int16-float32-float32;
 *
 *      float32-int16-int16-int16-float32-int16;
 *
 *   **Scale Limitation**
 *
 *      MLU270:
 *
 *         kh <= hi，kw <= wi
 *
 *         where ``kh`` is the height of the kernel, ``hi`` is the height of the input tensor,
 *         ``kw`` is width of the kernel, and ``wi`` is the width of the input tensor.
 *
 *    **Supports both MLU220 and MLU270.**
 *
 *    **Performance Optimization**
 *
 *      For best practice, we suggest you call the cnmlComputeReshapeOpForward_V4() API to reshape
 *      the
 *      tensor, if you set the input tensor with the following:
 *
 *       - The size of ci dimension is less than 64.
 *
 *       - The size of h dimension of the input tensor is greater than 200.
 *
 *       - The size of w dimension is greater than 200.
 *
 *      Also, when you set the output tensor of the cnmlComputeReshapeOpForward_V4() call, the size
 *      of
 *      h and w dimensions should be less than or equal to 200 and the value of ci dimension should
 *      be
 *      greater or equal to 64.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer struct of convolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co](no = ni),supporting
 *  data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, hf, wf, cf] (nf = co, cf =
 *  ci),supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, hb, wb, cb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by the bias tensor is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvOpForward(cnmlBaseOp_t *op,
                                                  cnmlConvOpParam_t param,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor,
                                                  cnmlTensor_t filter_tensor,
                                                  cnmlTensor_t bias_tensor);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  This function fills cnmlConvOpParam_t struct with the convolution operation parameters input by
 *  the user, and return to the user.
 *
 *  This function allocates param memory, and after usage is done, the user needs to call
 *  cnmlDestroyConvOpParam destroy param parameters.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of the convolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] dilation_height
 *    Input. A value greater than or equal to 1, the dilation factor of kernel (that is, weight
 *  tensor) in height dimension.
 *  @param[in] dilation_width
 *    Input. A value greater than or equal to 1, the dilation factor of kernel (that is, weight
 *  tensor) in weight dimension.
 *  @param[in] pad_top
 *    Input. Pad_top the top of length, the default value is 0.
 *  @param[in] pad_bottom
 *    Input. Pad_bottom the bottom of length, the default value is 0.
 *  @param[in] pad_left
 *    Input. Pad_left the left of width , the default value is 0.
 *  @param[in] pad_right
 *    Input. Pad_right the right of width, the default value is 0.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvOpParam_V2(cnmlConvOpParam_t *param,
                                                   int stride_height,
                                                   int stride_width,
                                                   int dilation_height,
                                                   int dilation_width,
                                                   int pad_top,
                                                   int pad_bottom,
                                                   int pad_left,
                                                   int pad_right);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeConvOpForward_V4 is recommended to use.
 *
 *  Computing user-specified convolution operators on MLU.
 *
 *  After convolution operator, input, output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute convolution operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Computing user-specified convolution operators on MLU.
 *
 *  After convolution operator, input, output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute convolution operator.
 *
 *  **Summary**
 *
 *  If the shape of an input tensor is [batch, in_height, in_width, in_channels] and the shape of a
 * filter
 *
 *  tensor or a kernel tensor is [filter_height, filter_width, in_channels, out_channels],
 *  with the default NHWC format.
 *
 *  output[b, i, j, k] =
 *      sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
 *      filter[di, dj, q, k]
 *
 *  Ph = p_top + p_botton
 *
 *  Pw = p_left + p_right
 *
 *  Ho = (Hi + Ph - dh(Kh - 1) -1) / Sh + 1
 *
 *  Wo = (Wi + Pw - dw(Kw - 1) -1)/ Sw + 1
 *
 *  co = K
 *
 *  where ``di`` is the dialation in h dimension, ``dj`` is the dialation in w dimension,
 *  ``q`` is control variable in ci dimension, ``k`` is the variable in co dimension, ``Ph``
 *  is the size of the padding in h dimension, ``Pw`` is the size of the padding in w
 *  dimension, ``Ho`` is the height of the output tensor, ``Wo`` is the width of the output
 *  tensor, ``co`` is the channel of the output tensor, ``Hi`` is the height of the
 *  input tensor, ``dh`` is the dilation in h dimension, ``Kh`` is the height of the kernel
 *  ``Sh`` is height of the stride, ``Wi`` is the width of the input tensor, ``dw`` is the
 *  dilation in w dimension, ``Kw`` is the width of the kernel, ``Sw`` is the stride in w
 *  dimension, and ``k`` is the number of channels for output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type : Data type of the input tensor.
 *
 *      filter_type : Data type of the filter tensor.
 *
 *      bias_type : Data type of the bias tensor.
 *
 *      output_type : Data type of the output tensor.
 *
 *      in_oc_type : Data type of the input tensor used for computing.
 *
 *      filter_oc_type : Data type of the filter tensor used for computing.
 *
 *      bias_oc_type : Data type of the bias tensor used for computing.
 *
 *      output_oc_type : Data type of the output tensor used for computing.
 *
 *      If filter_type is int8, then input_type can be int8 or int16, and output_type can be
 *      float16,
 *      float32, or int16.
 *
 *      If filter_type is int16, then input_type can be int16, and output_type can be float16,
 *      float32, or int16.
 *
 *      **Notes:** The data type you set in bias_oc_type, bias_type, and out_oc_type must be the
 *      same.
 *
 *      The supported combinations of the data type of the tensors are as follows. The data type
 *      are shown in the following order:
 *
 *      input_type - input_oc_type - filter_type - filter_oc_type - out_oc_type - out_type
 *
 *      Supported combinations are:
 *
 *      int8-int8-int8-int8-float16-float16;
 *
 *      int8-int8-int8-int8-float16-int8;
 *
 *      int8-int8-int8-int8-float32-float32;
 *
 *      int8-int8-int8-int8-float32-int8;
 *
 *      float16-int8-int8-int8-float16-float16;
 *
 *      float16-int8-int8-int8-float16-int8;
 *
 *      float32-int8-int8-int8-float32-float32;
 *
 *      float32-int8-int8-int8-float32-int8;
 *
 *      int16-int16-int8-int8-float16-float16;
 *
 *      int16-int16-int8-int8-float16-int16;
 *
 *      int16-int16-int8-int8-float32-float32;
 *
 *      int16-int16-int8-int8-float32-int16;
 *
 *      float16-int16-int8-int8-float16-float16;
 *
 *      float16-int16-int8-int8-float16-int16;
 *
 *      float32-int16-int8-int8-float32-float32;
 *
 *      float32-int16-int8-int8-float32-int16;
 *
 *      int16-int16-int16-int16-float16-float16;
 *
 *      int16-int16-int16-int16-float16-int16;
 *
 *      int16-int16-int16-int16-float32-float32;
 *
 *      int16-int16-int16-int16-float32-int16;
 *
 *      float16-int16-int16-int16-float16-float16;
 *
 *      float16-int16-int16-int16-float16-int16;
 *
 *      float32-int16-int16-int16-float32-float32;
 *
 *      float32-int16-int16-int16-float32-int16;
 *
 *   **Scale Limitation**
 *
 *      MLU270:
 *
 *         kh <= hi，kw <= wi
 *
 *         where ``kh`` is the height of the kernel, ``hi`` is the height of the input tensor,
 *         ``kw`` is width of the kernel, and ``wi`` is the width of the input tensor.
 *
 *    **Supports both MLU220 and MLU270.**
 *
 *    **Performance Optimization**
 *
 *      For best practice, we suggest you call the cnmlComputeReshapeOpForward_V4() API to reshape
 *      the
 *      tensor, if you set the input tensor with the following:
 *
 *       - The size of ci dimension is less than 64.
 *
 *       - The size of h dimension of the input tensor is greater than 200.
 *
 *       - The size of w dimension is greater than 200.
 *
 *      Also, when you set the output tensor of the cnmlComputeReshapeOpForward_V4() call, the size
 *      of
 *      h and w dimensions should be less than or equal to 200 and the value of ci dimension should
 *      be
 *      greater or equal to 64.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);

/* conv operation end */

/* conv first operation start */
/*!
 *  @struct cnmlConvFirstOpParam
 *  @brief A struct.
 *
 *  cnmlConvFirstOpParam is a structure describing the param parameter of first conv operation, used
 *  to create first conv operation. cnmlCreateConvFirstOpParam() is used to create an instance of
 *  cnmlConvFirstOpParam_t. cnmlDestroyConvFirstOpParam() is used to destroy an instance of
 *  cnmlConvFirstOpParam_t. */
struct cnmlConvFirstOpParam;
/*! ``cnmlConvFirstOpParam_t`` is a pointer to ``cnmlConvFirstOpParam`` which is a
    structure holding the description of a conv first operation param. */
typedef struct cnmlConvFirstOpParam *cnmlConvFirstOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a first-level convolution
 *  operator operation parameter struct, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the first-level convolution operator
 *  operation parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] pad_l
 *    Input. Pad length, the pad number added on the left.
 *  @param[in] pad_r
 *    Input. Pad length, the pad number added on the right.
 *  @param[in] pad_t
 *    Input. Pad length, pad number added above.
 *  @param[in] pad_b
 *    Input. Pad length, pad number added below.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvFirstOpParam(cnmlConvFirstOpParam_t *param,
                                                     int stride_height,
                                                     int stride_width,
                                                     int pad_l,
                                                     int pad_r,
                                                     int pad_t,
                                                     int pad_b);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a first-level convolution
 *  operator operation parameter struct, and fills in the struct with parameters input by the user.
 *  Comparing with cnmlCreateConvFirstOpParam() API, this API supports expanding the first
 * convolution kernel in height and width direction.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the first-level convolution operator
 *  operation parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] dilation_height
 *    Input. A value greater than or equal to 1, to expand first convolution kernel in Height
 * direction.
 *  @param[in] dilation_width
 *    Input. A value greater than or equal to 1, to expand first convolution kernel in Width
 * direction.
 *  @param[in] pad_l
 *    Input. Pad length, the pad number added on the left.
 *  @param[in] pad_r
 *    Input. Pad length, the pad number added on the right.
 *  @param[in] pad_t
 *    Input. Pad length, pad number added above.
 *  @param[in] pad_b
 *    Input. Pad length, pad number added below.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvFirstOpParam_V2(cnmlConvFirstOpParam_t *param,
                                                        int stride_height,
                                                        int stride_width,
                                                        int dilation_height,
                                                        int dilation_width,
                                                        int pad_l,
                                                        int pad_r,
                                                        int pad_t,
                                                        int pad_b);
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the first-level convolution
 *  operator operation parameter is freed.
 *
 *  At the end of the convolution operator operation, the created struct pointer of the first-level
 *  convolution operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the first-level convolution operator
 *  operation parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyConvFirstOpParam(cnmlConvFirstOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateConvFirstOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user, a first-level convolution operator is
 *  created.
 *
 *  After a pointer pointing to the address of the base operator, the operation parameter of the
 *  first-level convolution operator and the input-output tensor are created, they are introduced
 *  into the function to create the first-level convolution operator.
 *
 *  Before the creation of the first-level convolution operator, a pointer pointing to the address
 *  of struct of the first-level convolution operator operation parameter is declared and the
 *  required operator parameter is introduced into the function to set the operator parameter.
 *
 *  It includes the process of normalized (before computation, the mean value is subtracted from the
 *  input, the variance is divided, and the division by the variance is replaced with the
 *  multiplication by the reciprocal of variance in the actual computation) and the special
 *  convolution layer of performance optimization.
 *
 *  A simple 2-dimensional convolution can be seen as a process that a 2-dimensional convolution
 *  kernel (weight matrix) slides on 2-dimensional input data, matrix multiplication is performed on
 *  some of the elements currently input, and then the results are summed into a single input pixel.
 *  The convolution kernel repeats this process until it traverses the entire picture and converts a
 *  2-dimensional matrix into another. The special operation padding is equivalent to filling the
 *  edge of the input data with 0 (filling padding_height/2 0 in the height direction,
 *  padding_weight/2 0 in the weight direction), and stride refers to the sliding step of the
 *  convolution kernel.
 *
 *  The n-dimension and c-dimension generally refer to batch and channel. The general convolution
 *  operation (4-dimensional convolution) can be seen as a process that the input and weight of a
 *  batch is taken, and convolution operation is performed on the 2-dimensional inputs and
 *  convolution kernels of different channels, the computation results of different channels are
 *  added to get the output of the batch, after all the batches are completed, the bias is added to
 *  get the output.
 *
 *  hf <= hi,wf <= wi
 *
 *  ci <= 4, co <= 224, wo > 1
 *
 *  The length of the weight in the Height direction must be less than or equal to the length of the
 *  input in the Height direction. The length of the weight in the Width direction must be less than
 *  or equal to the length of the input in the Width direction.
 *
 *  The dimension of input Feature is less than or equal to 4, the dimension of output Feature is
 *  less than or equal to 224, and the dimension of output Width is greater than 1.
 *
 *  Range of input values is [0,255], after subtracting mean value, the range is [-128, 127].
 *
 *  When the data layout transformation is not performed on the input, the input data format must be
 *  aligned with 8 in w dimension 8, and the order of data is nhwc, cnmlSetDataPreprocessStrategy()
 *  will be called. The interface is set to CNML_NO_PREPROCESS.
 *
 *  The representation range of float16 dat is 66504-65504.
 *
 *  mlu tensor type under fix8 mode:
 *
 *  input: uint8 (position is needed)
 *
 *  output: fix8 (position is needed)or float16
 *
 *  filter : fix8 (position is needed)
 *
 *  mean: float16
 *
 *  bias : float16
 *
 *  stdt : float16
 *
 *  mlu tensor type under float16 mode:
 *
 *  input : uint8
 *
 *  output: float16
 *
 *  filter : float16
 *
 *  mean : fix8 (mean file position is needed),float16 (mean value)
 *
 *  bias : float16
 *
 *  stdt : float16
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Perfromance Optimization**
 *
 *  For better performance, it is recommended that you set the size of
 *  C dimension to 4 in the framework layer.
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer struct of convolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi], supporting only
 *  uint8-type data.
 *  @param[in] mean_tensor
 *    Input. A 4-dimensional MLU mean tensor, the shape is [nm, cm, hm, wm] (nm = 1, hm = 1, wm = 1,
 *  cm = ci or nm = 1, hm = hi, wm = wi, cm = ci), supporting the data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni),supporting
 *  data of float16 type
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = co, cf =
 *  ci),supporting data of float16 type
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co), supporting the data of float16 type.
 *  @param[in] stdt
 *    Input. A 4-dimensional MLU variance tensor, the shape is [ns, cs, hs, ws] (ns = 1, hs = 1, ws
 *  = 1, cs = ci), supporting the data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 *    - param is a null pointer.
 *    - input_tensor is a null pointer.
 *    - mean_tensor is a null pointer.
 *    - output_tensor is a null pointer.
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - CPU tensor bound by mean tensor is null.
 *    - when variance tensor is not null, the CPU tensor bound by variance tensor is null.
 *    - when bias tensor is not null, the CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvFirstOp(cnmlBaseOp_t *op,
                                                cnmlConvFirstOpParam_t param,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t mean_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t filter_tensor,
                                                cnmlTensor_t bias_tensor,
                                                cnmlTensor_t std_tensor);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, a first-level convolution operator is
 *  created.
 *
 *  After a pointer pointing to the address of the base operator, the operation parameter of the
 *  first-level convolution operator and the input-output tensor are created, they are introduced
 *  into the function to create the first-level convolution operator.
 *
 *  Before the creation of the first-level convolution operator, a pointer pointing to the address
 *  of struct of the first-level convolution operator operation parameter is declared and the
 *  required operator parameter is introduced into the function to set the operator parameter.
 *
 *  It includes the process of normalized (before computation, the mean value is subtracted from the
 *  input, the variance is divided, and the division by the variance is replaced with the
 *  multiplication by the reciprocal of variance in the actual computation) and the special
 *  convolution layer of performance optimization.
 *
 *  A simple 2-dimensional convolution can be seen as a process that a 2-dimensional convolution
 *  kernel (weight matrix) slides on 2-dimensional input data, matrix multiplication is performed on
 *  some of the elements currently input, and then the results are summed into a single input pixel.
 *  The convolution kernel repeats this process until it traverses the entire picture and converts a
 *  2-dimensional matrix into another. The special operation padding is equivalent to filling the
 *  edge of the input data with 0 (filling padding_height/2 0 in the height direction,
 *  padding_weight/2 0 in the weight direction), and stride refers to the sliding step of the
 *  convolution kernel.
 *
 *  The n-dimension and c-dimension generally refer to batch and channel. The general convolution
 *  operation (4-dimensional convolution) can be seen as a process that the input and weight of a
 *  batch is taken, and convolution operation is performed on the 2-dimensional inputs and
 *  convolution kernels of different channels, the computation results of different channels are
 *  added to get the output of the batch, after all the batches are completed, the bias is added to
 *  get the output.
 *
 *  hf <= hi,wf <= wi
 *
 *  ci <= 4, co <= 224, wo > 1
 *
 *  The length of the weight in the Height direction must be less than or equal to the length of the
 *  input in the Height direction. The length of the weight in the Width direction must be less than
 *  or equal to the length of the input in the Width direction.
 *
 *  The dimension of input Feature is less than or equal to 4, the dimension of output Feature is
 *  less than or equal to 224, and the dimension of output Width is greater than 1.
 *
 *  Range of input values is [0,255], after subtracting mean value, the range is [-128, 127].
 *
 *  When the data layout transformation is not performed on the input, the input data format must be
 *  aligned with 8 in w dimension 8, and the order of data is nhwc, cnmlSetDataPreprocessStrategy()
 *  will be called. The interface is set to CNML_NO_PREPROCESS.
 *
 *  The representation range of float16 dat is 66504-65504.
 *
 *  mlu tensor type under fix8 mode:
 *
 *  input: uint8 (position is needed)
 *
 *  output: fix8 (position is needed)or float16
 *
 *  filter : fix8 (position is needed)
 *
 *  mean: float16
 *
 *  bias : float16
 *
 *  stdt : float16
 *
 *  mlu tensor type under float16 mode:
 *
 *  input : uint8
 *
 *  output: float16
 *
 *  filter : float16
 *
 *  mean : fix8 (mean file position is needed),float16 (mean value)
 *
 *  bias : float16
 *
 *  stdt : float16
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Perfromance Optimization**
 *
 *  For better performance, it is recommended that you set the size of
 *  C dimension to 4 in the framework layer.
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer struct of convolution operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi], supporting only
 *  uint8-type data.
 *  @param[in] mean_tensor
 *    Input. A 4-dimensional MLU mean tensor, the shape is [nm, cm, hm, wm] (nm = 1, hm = 1, wm = 1,
 *  cm = ci or nm = 1, hm = hi, wm = wi, cm = ci), supporting the data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni),supporting
 *  data of float16 type
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = co, cf =
 *  ci),supporting data of float16 type
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co), supporting the data of float16 type, defaults to a null pointer.
 *  @param[in] stdt
 *    Input. A 4-dimensional MLU variance tensor, the shape is [ns, cs, hs, ws] (ns = 1, hs = 1, ws
 *  = 1, cs = ci), supporting the data of float16 type, defaults to a null pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 *    - param is a null pointer.
 *    - input_tensor is a null pointer.
 *    - mean_tensor is a null pointer.
 *    - output_tensor is a null pointer.
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - CPU tensor bound by mean tensor is null.
 *    - when variance tensor is not null, the CPU tensor bound by variance tensor is null.
 *    - when bias tensor is not null, the CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvFirstOpForward(cnmlBaseOp_t *op,
                                                       cnmlConvFirstOpParam_t param,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t mean_tensor,
                                                       cnmlTensor_t output_tensor,
                                                       cnmlTensor_t filter_tensor,
                                                       cnmlTensor_t bias_tensor,
                                                       cnmlTensor_t std_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeConvFirstOpForward_V4 is recommended to use.
 *
 *  Computing user-specified first-level convolution operator on MLU.
 *
 *  After the first-level convolution operator, input, output, parameter at runtime, and
 *  computational queue are created, they are introduced into the function to compute the
 *  first-level convolution operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeConvFirstOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified first-level convolution operator on MLU.
 *
 *  After the first-level convolution operator, input, output, parameter at runtime, and
 *  computational queue are created, they are introduced into the function to compute the
 *  first-level convolution operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Perfromance Optimization**
 *
 *  For better performance, it is recommended that you set the size of
 *  C dimension to 4 in the framework layer.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvFirstOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *  @brief A function.
 *
 *  This interface is a discarded interface and is not currently enabled.
 */
CNML_DLL_API cnmlStatus_t cnmlEnableConvFirstOpBgraMode(cnmlBaseOp_t op);

/*!
 *  @brief A function.
 *
 *  This interface is a discarded interface and is not currently enabled.
 */
CNML_DLL_API cnmlStatus_t cnmlEnableConvFirstOpFusionPadMode(cnmlBaseOp_t op);

/* conv operation end */

/* conv group operation start */
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateConvGroupOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user, a grouping convolution operator is
 *  created.
 *
 *  Group convolution: firstly, the input and weight tensor are divided into several groups (the
 *  input is divided in the C dimension, the weight is divided in the N dimension), and the conv
 *  operation is performed on each group of input and weight correspondingly, and the computation
 *  result is sequentially spliced and output.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni),supporting
 *  data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = co, cf =
 *  ci),supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @param[in] group
 *    Input. Group number.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvGroupOp(cnmlBaseOp_t *op,
                                                cnmlConvOpParam_t param,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t filter_tensor,
                                                cnmlTensor_t bias_tensor,
                                                int group);
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, a grouping convolution operator is
 *  created.
 *
 *  Group convolution: firstly, the input and weight tensor are divided into several groups (the
 *  input is divided in the C dimension, the weight is divided in the N dimension), and the conv
 *  operation is performed on each group of input and weight correspondingly, and the computation
 *  result is sequentially spliced and output.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
      Input. Conv_Op param pointer.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni),supporting
 *  data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = co, cf =
 *  ci),supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @param[in] group
 *    Input. Group number.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvGroupOpForward(cnmlBaseOp_t *op,
                                                       cnmlConvOpParam_t param,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor,
                                                       cnmlTensor_t filter_tensor,
                                                       cnmlTensor_t bias_tensor,
                                                       int group);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeConvGroupOpForward_V4 is recommended to use.
 *
 *  Computing user-specified grouping convolution operator on MLU.
 *
 *  After the grouping convolution operator, input, output, parameter at runtime and computational
 *  queue are created, they are introduced into the function to compute grouping convolution
 *  operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeConvGroupOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified grouping convolution operator on MLU.
 *
 *  After the grouping convolution operator, input, output, parameter at runtime and computational
 *  queue are created, they are introduced into the function to compute grouping convolution
 *  operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvGroupOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* conv group operation end */

/* deconv_depthwise operation start */
/*!
 *  @struct cnmlDeconvDepthwiseOpParam
 *  @brief A struct.
 *
 *  cnmlDeconvDepthwiseOpParam is a structure describing the param parameter of depthwise deconv
 *  operation, used to create depthwise deconv operation. cnmlCreateDeconvDepthwiseOpParam() is
 *  used to create an instance of cnmlConvDepthwiseOpParam_t.
 *  cnmlDestroyConvDepthwiseOpParam() is used to destroy an instance of cnmlConvDepthwiseOpParam_t.
 */
struct cnmlDeconvDepthwiseOpParam;
/*! ``cnmlDeconvDepthwiseOpParam_t`` is a pointer to ``cnmlDeconvDepthwiseOpParam`` which is a
    structure holding the description of a deconv depthwise operation param. */
typedef struct cnmlDeconvDepthwiseOpParam *cnmlDeconvDepthwiseOpParam_t;
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of the deconv
 * depthwise
 *  operator operation parameter, and fills in the struct with parameter input by the
 *  user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the deconv depthwise operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] dilation_h
 *    Input. A value greater than or equal to 1, and the dilation in Height direction.
 *  @param[in] dilation_w
 *    Input. A value greater than or equal to 1, and the dilation in Width direction.
 *  @param[in] crop_uh
 *    Input. A value greater than or equal to 0, and the crop in Up Height direction.
 *  @param[in] crop_dh
 *    Input. A value greater than or equal to 0, and the crop in Down Height direction.
 *  @param[in] crop_lw
 *    Input. A value greater than or equal to 0, and the crop in Left Width direction.
 *  @param[in] crop_rw
 *    Input. A value greater than or equal to 0, and the crop in Right Width direction.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvDepthwiseOpParam(cnmlDeconvDepthwiseOpParam_t *param,
                                                           int stride_height,
                                                           int stride_width,
                                                           int dilation_h,
                                                           int dilatin_w,
                                                           int crop_uh,
                                                           int crop_dh,
                                                           int crop_lw,
                                                           int crop_rw);
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the operation parameter of the
 *  deconv depthwise operator is freed.
 *
 *  After the operation of deconv depthwise operator is finished, the created struct pointer of
 * deconv
 *  depthwise operator operation parameter is freed.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of  struct of the operation parameter of the deconv
 * depthwise
 *    operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyDeconvDepthwiseOpParam(cnmlDeconvDepthwiseOpParam_t *param);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateDeconvDepthwiseOpForward is recommended to use.
 *
 *  Computes the deconv depthwise of a 4-Dimensional input tensor.
 *
 *  Creates a Deconv Depthwise operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input, output, filter and bias tensor,
 *  pass them to the function to create a Deconv Depthwise operator.
 *
 *  **Note**
 *
 *  Deconv depthwise: in the current version this op only support the case of multipiler = 1.
 *  So the input, filter and output tensors in C dimension should be equal.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  **DataType**
 *
 *    MLU270 and MLU220:
 *
 *    The supported combinations of the data type of the tensors are as follows. The data type are
 *    shown in the following order where input represents the MLU input, oc_input represents the
 *    on-chip input, output represents the MLU output, and oc_output represents the on-chip output.
 *
 *      - input-oc_input-output-oc_output
 *
 *        Supported combinations are:
 *
 *        float16-float16-float16-float16
 *
 *        float32-float32-float32-float32
 *
 *  **Scale Limitation**
 *
 *    Unlmited.
 *
 *  **Performance Optimization**
 *
 *    It will reach its optimal performance, when the number of bytes in the C dimension is a
 * multiple of 64.
 *
 *  **Life Cycle**
 *
 *    Release the Deconv depthwise Op after calling the cnmlComputeDeconvDepthwiseOpForward function
 * and getting the result.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in]  input_tensor
 *    Input.  A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi], supporting data
 *  of float16 and float32 type.
 *  @param[in]  output_tensor
 *    Input.  A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo].
 *  supporting data of float16 and float32 type.
 *  @param[in]  filter_tensor
 *    Input.  A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf].
 *  supporting data of float16 and float32 type.
 *  @param[in]  bias_tensor
 *    Input.  A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb =
 * 1)
 *  supporting data of float16 and flaot 32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST
 *    - The CPU tensor bound by bias tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateDeconvDepthwiseOpForward(cnmlBaseOp_t *op,
                                                             cnmlDeconvDepthwiseOpParam_t param,
                                                             cnmlTensor_t input_tensor,
                                                             cnmlTensor_t output_tensor,
                                                             cnmlTensor_t filter_tensor,
                                                             cnmlTensor_t bias_tensor);
/*!
 *  @brief A function.
 *
 *  Computing user-specified deconv depthwise operator on MLU.
 *
 *  After the deconv depthwise operator, input, output and computational queue are created, they
 *  are introduced into the function to compute the deconv depthwise operator.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeconvDepthwiseOpForward(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* deconv_depthwise operation end */

/* deconv group operation start*/
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateDeconvGroupOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user, a grouping deconvolution operator
 *  is created.
 *
 *  Group deconvolution: the input and the weight tensor are divided into groups, the groups
 *  numbers is the size of C dimension, and the deconv opertion is not performed on each group
 *  of input and weight correspondingly, and the computation result is not sequentially spliced
 *  and output.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in]  input_tensor
 *    Input.  A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi], supporting data
 *  of float16 type.
 *  @param[in]  output_tensor
 *    Input.  A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni = 1),
 * supporting
 *  data of float16 type.
 *  @param[in]  filter_tensor
 *    Input.  A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = 1, cf = ci =
 * co),
 *  supporting data of float16 type.
 *  @param[in]  bias_tensor
 *    Input.  A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nv = 1, hb = 1, wb =
 * 1,
 *  cb co), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvGroupOp(cnmlBaseOp_t *op,
                                                  cnmlDeconvOpParam_t param,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor,
                                                  cnmlTensor_t filter_tensor,
                                                  cnmlTensor_t bias_tensor,
                                                  int group);
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, a grouping deconvolution operator
 *  is created.
 *
 *  Group deconvolution: the input and the weight tensor are divided into groups, the groups
 *  numbers is the size of C dimension, and the deconv opertion is not performed on each group
 *  of input and weight correspondingly, and the computation result is not sequentially spliced
 *  and output.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the cnmlDeconvGroupParam struct.
 *  @param[in]  input_tensor
 *    Input.  A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi], supporting data
 *  of float16 type.
 *  @param[in]  output_tensor
 *    Input.  A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni = 1),
 *    supporting data of float16 type.
 *  @param[in]  filter_tensor
 *    Input.  A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = 1, cf = ci =
 * co),
 *  supporting data of float16 type.
 *  @param[in]  bias_tensor
 *    Input.  A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nv = 1, hb = 1, wb =
 * 1,
 *  cb co), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST
 *    - The CPU tensor bound by bias tensor is null.
 *    -
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeconvGroupOpForward(cnmlBaseOp_t *op,
                                                         cnmlDeconvOpParam_t param,
                                                         cnmlTensor_t input_tensor,
                                                         cnmlTensor_t output_tensor,
                                                         cnmlTensor_t filter_tensor,
                                                         cnmlTensor_t bias_tensor,
                                                         int group);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeDeconvGroupOpForward_V2 is recommended to use.
 *
 *  Computing user-specified deconvolution group operator on MLU.
 *
 *  After the deconvolution group operator, input, output and computational stream are created, they
 *  are introduced into the function to compute the deconvolution group operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] type
 *    Input. An enumeration value representing the task type at runtime.
 *  @param[in] stream
 *    Input. A computational stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeconvGroupOpForward(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified deconvolution group operator on MLU.
 *
 *  After the deconvolution group operator, input, output and computational queue are created, they
 *  are introduced into the function to compute the deconvolution group operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeconvGroupOpForward_V2(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* deconv group operation end*/

/* conv_depthwise operation start */
/*!
 *  @struct cnmlConvDepthwiseOpParam
 *  @brief A struct.
 *
 *  cnmlConvDepthwiseOpParam is a structure describing the param parameter of depthwise conv
 *  operation, used to create depthwise conv operation. cnmlCreateConvDepthwiseOpParam() and
 *  cnmlCreateConvDepthwiseOpParam_V2() is used to create an instance of cnmlConvDepthwiseOpParam_t.
 *  cnmlDestroyConvDepthwiseOpParam() is used to destroy an instance of cnmlConvDepthwiseOpParam_t.
 */
struct cnmlConvDepthwiseOpParam;
/*! ``cnmlConvDepthwiseOpParam_t`` is a pointer to ``cnmlConvDepthwiseOpParam`` which is a
    structure holding the description of a conv depthwise operation param. */
typedef struct cnmlConvDepthwiseOpParam *cnmlConvDepthwiseOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of the deep
 *  convolution operator operation parameter, and fills in the struct with parameter input by the
 *  user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the deep convolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvDepthwiseOpParam(cnmlConvDepthwiseOpParam_t *param,
                                                         int stride_height,
                                                         int stride_width);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of the deep
 *  convolution operator operation parameter, and fills in the struct with parameter input by the
 *  user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the deep convolution operator operation
 *  parameter.
 *  @param[in] stride_height
 *    Input. A value greater than or equal to 1, and the sliding step in Height direction.
 *  @param[in] stride_width
 *    Input. A value greater than or equal to 1, and the sliding step in Width direction.
 *  @param[in] pad_height
 *    Input. Pad length.
 *  @param[in] pad_width
 *    Input. Pad width.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvDepthwiseOpParam_V2(cnmlConvDepthwiseOpParam_t *param,
                                                            int stride_height,
                                                            int stride_width,
                                                            int pad_height,
                                                            int pad_width);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the operation parameter of the
 *  deep convolution operator is freed.
 *
 *  After the operation of deep convolution operator is finished, the created struct pointer of deep
 *  convolution operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of  struct of the operation parameter of the deep
 *  convolution operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyConvDepthwiseOpParam(cnmlConvDepthwiseOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a deep convolution operator is
 *  created.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateConvDepthwiseOpForward is recommended to use.
 *
 *  If pad_height and pad_weight is not 0, the input data edges need to be filled, that is,
 *  pad_height/2 0 needs to be filled in height direction, pad_weight/2 0 needs to be filled in
 *  weight direction. The arrangement order of input, output, and weight during computation is NCHW.
 *  The summation is performed on the subscripts h and w of the filter, and the summation range is
 *  [i * stride_height, min {i * stride_height + hf, hi}], the sum range of w is [j * stride_weight,
 *  min {j * stride_weight + jf, ji}]. If the bias tensor is not null, the final output should add
 *  bias.
 *
 *  **Summary**
 *
 *  For input[ni, ci, hi, wi], output[no, co, ho, wo], filter[nf, cf, hf, wf] and
 *
 *  bias[nb, cb, hb, wb], multiplier = co / ci
 *
 *  output[n, k * multiplier + q, i, j] = sum_{di, dj} input[n, stride_h * i + di, stride_w * j +
 * dj, k] * filter[1, k * multiplier + q, di, dj] + bias[1, k * multiplier + q, 1, 1]
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     in_type-in_oc_type-out_oc_type-out_type
 *
 *     float16-float16   -float16    -float16
 *
 *     float32-float32   -float32    -float32
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      if data_type = float16 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 26 * 26
 *
 *      if data_type = float32 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 18 * 18
 *
 * **Performance Optimization**
 *
 *   1. The number of bytes in the C dimension is a multiple of 128.
 *
 *   2. multiplier = 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A deep convolution operation struct pointer.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](co = ci *
 *  multiplier),supporting data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = 1),supporting
 *  data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvDepthwiseOp(cnmlBaseOp_t *op,
                                                    cnmlConvDepthwiseOpParam_t param,
                                                    cnmlTensor_t input_tensor,
                                                    cnmlTensor_t output_tensor,
                                                    cnmlTensor_t filter_tensor,
                                                    cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, a deep convolution operator is
 *  created.
 *
 *  If pad_height and pad_weight is not 0, the input data edges need to be filled, that is,
 *  pad_height/2 0 needs to be filled in height direction, pad_weight/2 0 needs to be filled in
 *  weight direction. The arrangement order of input, output, and weight during computation is NCHW.
 *  The summation is performed on the subscripts h and w of the filter, and the summation range is
 *  [i * stride_height, min {i * stride_height + hf, hi}], the sum range of w is [j * stride_weight,
 *  min {j * stride_weight + jf, ji}]. If the bias tensor is not null, the final output should add
 *  bias.
 *
 *  **Summary**
 *
 *  For input[ni, ci, hi, wi], output[no, co, ho, wo], filter[nf, cf, hf, wf] and
 *
 *  bias[nb, cb, hb, wb], multiplier = co / ci
 *
 *  output[n, k * multiplier + q, i, j] = sum_{di, dj} input[n, stride_h * i + di, stride_w * j +
 * dj, k] * filter[1, k * multiplier + q, di, dj] + bias[1, k * multiplier + q, 1, 1]
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     in_type-in_oc_type-out_oc_type-out_type
 *
 *     float16-float16   -float16    -float16
 *
 *     float32-float32   -float32    -float32
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      if data_type = float16 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 26 * 26
 *
 *      if data_type = float32 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 18 * 18
 *
 * **Performance Optimization**
 *
 *   1. The number of bytes in the C dimension is a multiple of 128.
 *
 *   2. multiplier = 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A deep convolution operation struct pointer.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](co = ci *
 *  multiplier),supporting data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional MLU weight tensor, the shape is [nf, cf, hf, wf] (nf = 1),supporting
 *  data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional MLU bias tensor, the shape is [nb, cb, hb, wb] (nb = 1, hb = 1, wb = 1,
 *  cb = co),supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConvDepthwiseOpForward(cnmlBaseOp_t *op,
                                                           cnmlConvDepthwiseOpParam_t param,
                                                           cnmlTensor_t input_tensor,
                                                           cnmlTensor_t output_tensor,
                                                           cnmlTensor_t filter_tensor,
                                                           cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  Computing user-specified deep convolution operator on MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeConvDepthwiseOpForward_V4 is recommended to use.
 *
 *  After the deep convolution operator, input, output, parameter at runtime, and computational
 *  queue are created, they are introduced into the function to compute the deep convolution
 *  operator.
 *
 *  **Summary**
 *
 *  For input[ni, ci, hi, wi], output[no, co, ho, wo], filter[nf, cf, hf, wf] and
 *  bias[nb, cb, hb, wb], multiplier = co / ci
 *
 *  output[n, k * multiplier + q, i, j] = sum_{di, dj} input[n, stride_h * i + di, stride_w * j +
 * dj, k] * filter[1, k * multiplier + q, di, dj] + bias[1, k * multiplier + q, 1, 1]
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     in_type-in_oc_type-out_oc_type-out_type
 *
 *     float16-float16   -float16    -float16
 *
 *     float32-float32   -float32    -float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      if data_type = float16 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 26 * 26
 *
 *      if data_type = float32 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 18 * 18
 *
 *  **Performance Optimization**
 *
 *   1. The number of bytes in the C dimension is a multiple of 128.
 *
 *   2. multiplier = 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeConvDepthwiseOpForward_V3(cnmlBaseOp_t op,
                                     void *input,
                                     void *output,
                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified deep convolution operator on MLU.
 *
 *  After the deep convolution operator, input, output, parameter at runtime, and computational
 *  queue are created, they are introduced into the function to compute the deep convolution
 *  operator.
 *
 *  **Summary**
 *
 *  For input[ni, ci, hi, wi], output[no, co, ho, wo], filter[nf, cf, hf, wf] and
 *
 *  bias[nb, cb, hb, wb], multiplier = co / ci
 *
 *  output[n, k * multiplier + q, i, j] = sum_{di, dj} input[n, stride_h * i + di, stride_w * j +
 * dj, k] * filter[1, k * multiplier + q, di, dj] + bias[1, k * multiplier + q, 1, 1]
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     in_type-in_oc_type-out_oc_type-out_type
 *
 *     float16-float16   -float16    -float16
 *
 *     float32-float32   -float32    -float32
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      if data_type = float16 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 26 * 26
 *
 *      if data_type = float32 :
 *
 *         multiplier = 1, kh * kw * (ci > 256 ? 4 : ci / 64) <= 18 * 18
 *
 * **Performance Optimization**
 *
 *   1. The number of bytes in the C dimension is a multiple of 128.
 *
 *   2. multiplier = 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvDepthwiseOpForward_V4(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor,
                                                               void *input,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);
/* conv_depthwise operation end */

/* add pad operation start */
/*!
 *  @struct cnmlAddPadOpParam
 *  @brief A struct.
 *
 *  cnmlAddPadOpParam is a structure describing the param parameter of addpad operation, used to
 *  create addpad operation. cnmlCreateAddPadOpParam() and cnmlCreateAddPadOpParam_V2() is used to
 *  create an instance of cnmlAddPadOpParam_t. cnmlDestroyAddPadOpParam() is used to destroy an
 *  instance of cnmlAddPadOpParam_t. */
struct cnmlAddPadOpParam;
/*! ``cnmlAddPadOpParam_t`` is a pointer to ``cnmlAddPadOpParam`` which is a
    structure holding the description of a addpad operation param. */
typedef struct cnmlAddPadOpParam *cnmlAddPadOpParam_t;

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  According to the pointer given by the user, the function creates an AddPad operation parameter
 *  struct and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of AddPad operator operation parameter.
 *  @param[in] pad_h
 *    Input. Pad length.
 *  @param[in] pad_w
 *    Input. Pad width.
 *  @param[in] pad_value
 *    Input. The data filled into input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadOpParam(cnmlAddPadOpParam_t *param,
                                                  int pad_h,
                                                  int pad_w,
                                                  float pad_value);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates an AddPad operation parameter
 *  struct and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of AddPad operator operation parameter.
 *  @param[in] pad_htop
 *    Input. Above pad length.
 *  @param[in] pad_hbottom
 *    Input. Below padmlength.
 *  @param[in] pad_wleft
 *    Input. Left pad width.
 *  @param[in] pad_wright
 *    Input. Right pad width.
 *  @param[in] pad_value
 *    Input. The data filled into input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadOpParam_V2(cnmlAddPadOpParam_t *param,
                                                     int pad_htop,
                                                     int pad_hbottom,
                                                     int pad_wleft,
                                                     int pad_wright,
                                                     float pad_value);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  According to the pointer given by the user, the struct pointer of AddPad operator operation
 *  parameter is freed.
 *
 *  After the operation of the AddPad operator is finished, the created struct pointer of AddPad
 *  operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of AddPad operator operation parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyAddPadOpParam(cnmlAddPadOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  According to the basic Operator pointer given by the user, an AddPad operator is created.
 *
 *  The addpad operation in the h, w direction can be used to fill the input h, w direction to a
 *  preset size.
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      hi < 2^16
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *     The C dimension is a multiple of 128.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct of AddPad operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni),supporting
 *  data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadOp(cnmlBaseOp_t *op,
                                             cnmlAddPadOpParam_t param,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Computing user-specified AddPad operator on MLU.
 *
 *  After the AddPad operator, Input. output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute the AddPad operator.
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      hi < 2^16
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAddPadOpForward_V4
 *  is recommended to use.
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAddPadOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Computing user-specified AddPad operator on MLU.
 *
 *  After the AddPad operator, Input. output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute the AddPad operator.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      hi < 2^16
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *     The value of C dimension is a multiple of 128.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAddPadOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* add pad operation end */

/* tril operation start */
/*!
 *  @ struct cnmlTrilOpParam
 *  @ brief A struct.
 *
 *  cnml TrilOpParam is a struct describing the param parameter of tril
 *  used to create tril operation. cnmlCreateTrilOpParam() is used to create
 *  an instance of cnmlTrilOpParam_t, cnmlDestroyTrilOpParam() is used to
 *  destroy an instance of cnmlTrilOpParam_t */

struct cnmlTrilOpParam;
/*!    ``cnmlTrilOpParam_t `` is a pointer to ``cnmlTrilOpParam`` which is a
 * structure holding the description of a tril operation param */
typedef struct cnmlTrilOpParam *cnmlTrilOpParam_t;

/*!
 *  @brief A function
 *
 *  According to the pointer given by the user, the function creates a tril
 *  operation parameter struct and fills in the struct with the parameters input
 *  by the user.
 *
 *  **Support only MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of Tril operator
 *    operation parameter.
 *  @param[in] dia;
 *    Input. Diagonal of the matrix.
 *  @retval CNML_STATUS_SUCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following condition is met:
 *      - param is a null pointer
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTrilOpParam(cnmlTrilOpParam_t *param, int dia);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of Tril
 *  operator operation parameter is freed.
 *
 *  **Support only MLU270.**
 *
 *  After the operation of the Tril operator is finished, the created struct
 *  pointer of Tril operator operation parameter is freed.
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of Tril operator
 *  operation parameter.
 *  @retval CNML_STATUS_SUCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *      - param is null pointer.
 *      - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyTrilOpParam(cnmlTrilOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the basic Operator pointer given by the user, a Tril operator
 *  is created.
 *
 *  The tril operation in the n c direction can be set to get the low triangle
 *  matrix.
 *
 *  The input tenosr and output tensor must have the same shape.
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  Formula:
 *
 *    output[no,co,1,1] = (ni - ci >= dia) ? input[ni,ci,1,1] : 0.
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Support only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A pointer pointing to the struct of Tril operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, 1, 1],
 *  supporting data of float16 type and float32 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, 1, 1],
 *  supporting data of float16 type and float32 type.
 *  @retval CNML_STATUS_SUCESS
 *    the function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *      - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *      - The CPU tensor bounded by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTrilOp(cnmlBaseOp_t *op,
                                           cnmlTrilOpParam_t param,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Computing user-specified Tril operator on MLU.
 *
 *  After the Tril operator, Input. output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute the Tril operator.
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Formula**
 *
 *    output[no,co,1,1] = (ni - ci >= dia) ? input[ni,ci,1,1] : 0.
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeTrilOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);

/* tril operation end */

/* add pad channel operation start */
/*!
 *  @struct cnmlAddPadChannelOpParam
 *  @brief A struct.
 *
 *  cnmlAddPadChannelOpParam is a structure describing the param parameter of addpad channel
 *  operation, used to create addpad channel operation. cnmlCreateAddPadChannelOpParam() and
 *  cnmlCreateAddPadChannelOpParam_V2() is used to create an instance of cnmlAddPadChannelOpParam_t
 * .
 *  cnmlDestroyAddPadChannelOpParam() is used to destroy an instance of cnmlAddPadChannelOpParam_t.
 */
struct cnmlAddPadChannelOpParam;
/*! ``cnmlAddPadChannelOpParam_t`` is a pointer to ``cnmlAddPadChannelOpParam`` which is a
    structure holding the description of a addpad channel operation param. */
typedef struct cnmlAddPadChannelOpParam *cnmlAddPadChannelOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of AddPadChannel
 *  operator operation parameter, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the AddPadChannel operator parameter.
 *  @param[in] channel_
 *    Input. The size of filling in C direction.
 *  @param[in] pad_value
 *    Input. The data filled into input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadChannelOpParam(cnmlAddPadChannelOpParam_t *param,
                                                         int channel_,
                                                         float pad_value);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of AddPadChannel
 *  operator operation parameter, and fills in the struct with parameter input by the user.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[out] param
 *    Output. A pointer pointing address of struct of the AddPadChannel operator operation
 *  parameter.
 *  @param[in] c_front_
 *    Input. The length of lower filling in C direction.
 *  @param[in] c_back_
 *    Input. The length of upper filling in C direction.
 *  @param[in] pad_value
 *    Input. The data filled into input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadChannelOpParam_V2(cnmlAddPadChannelOpParam_t *param,
                                                            int c_front_,
                                                            int c_back_,
                                                            float pad_value);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of AddPadChannel operator
 *  operation parameter is freed.
 *
 *  After the operation of the AddPadChannel operator is completed, the created struct pointer of
 *  AddPadChannel operator operation parameter is freed.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the AddPadChannel operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyAddPadChannelOpParam(cnmlAddPadChannelOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the basic operator pointer given by the user, an AddPad Channel operator is
 *  created.
 *
 *  The addpad operation of feature direction can be used to fill the c direction of input to a
 *  preset size.
 *
 *  **Related APIs**
 *
 *    After calling this API, you may need to call the following APIs:
 *
 *      ``cnmlFuseOp`` or ``cnmlComputeAddPadChannelOpForward``, and ``cnmlDestroyBaseOp``.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      - input: float16, float32
 *      - output: float16, float32
 *
 *    MLU220:
 *
 *      - input: float16, float32
 *      - output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited.
 *
 *    MLU220:
 *
 *      Unlimited.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A struct pointer of AddPadChannel operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi].
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddPadChannelOp(cnmlBaseOp_t *op,
                                                    cnmlAddPadChannelOpParam_t param,
                                                    cnmlTensor_t input_tensor,
                                                    cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Computing the AddPadChannel operator specified by the user on MLU.
 *  Deprecated. This interface will be deleted in next version and
 * cnmlComputeAddPadChannelOpForward_v4 is recommended to use.
 *
 *  After the AddPadChannel operator, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute the AddPadChannel operator.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeAddPadChannelOpForward_V3(cnmlBaseOp_t op,
                                     void *input,
                                     void *output,
                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing the AddPadChannel operator specified by the user on MLU.
 *
 *  After the AddPadChannel operator, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute the AddPadChannel operator.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAddPadChannelOpForward_V4(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor,
                                                               void *input,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);
/* add pad channel operation end */

/* scatterref operation start */
/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function creates the parameters required by
 * ScatterRef operator.
 * @param[out] param
 *   Output. A pointer pointing to the address of the parameter of the ScatterRef operator.
 * @param[in] scatter type
 *   Input. A parameter controlling the type of scatterRef, including scatter_add,
 *   scatter_sub, scatter_mul, scatter_div, scatter_max, scatter_min and scatter_udpate
 *   scatter_div is not supported for now.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *   - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterRefOpParam(cnmlScatterRefOpParam_t *param,
                                                      cnmlScatterType_t scatter_type);
/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function destroys the parameters of the
 * ScatterRef operator.
 *
 * After the ScatterRef operator is finished, the created struct pointer of ScatterRef operator is
 * freed.
 * @param[in] param
 *   Input. A pointer pointing to the address of the struct of ScatterRef operator parameters.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *   - param is a null pointer.
 *   - the pointer has been freed in advance.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyScatterRefOpParam(cnmlScatterRefOpParam_t *param);
/*!
 * @brief A function.
 *
 * The function creates a ScatterRef operator according to the base operator pointer given by users.
 * The scatterRef operator is the collection of scatter_add(sub, max, min, mul, div, update).
 *
 * After creating a pointer pointing to the base operators, the functions pass the ref tensor,
 * the index tensor, update tensor and the ref_out Tensor into the function to create the ScatterRef
 * operator.
 *
 * Note that the length of the udpate tensor on the highest dimension should be equal to the length
 * of index, which can be expressed in the form of equation as: input_tensor.shape[0] ==
 * len(index). The operator is an in-place tensor, which requires that the ref and the ref_out
 * tensor be the same.
 *
 * In addition, the value of the index tensor should not beyond the size of ref(out) tensor.
 * Otherwise, an invalid address of the ref tensor is encountered.
 *
 *   **Formula**
 *
 *     For ref[ni, ci, hi, wi], index[1, c_index, 1, 1] and updates[c_index, ci, hi, wi]
 *
 *     scatter_add:
 *
 *       ref(out)[index[i], ci, hi, wi] += update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *    scatter_sub:
 *
 *       ref(out)[index[i], ci, hi, wi] -= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_mul:
 *
 *       ref(out)[index[i], ci, hi, wi] *= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_div:
 *
 *       ref(out)[index[i], ci, hi, wi] /= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_max:
 *
 *       ref(out)[index[i], ci, hi, wi] = max(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_min:
 *
 *       ref(out)[index[i], ci, hi, wi] = min(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_update:
 *
 *       ref(out)[index[i], ci, hi, wi] = update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *    The supported combinations of the data type of the tensors are as follows. The data type
 *    are shown in the following order:
 *
 *    ref_type -index_type -update_type -ref_out_type
 *
 *    Supported combinations are:
 *
 *    float16 -int32 -float16 -float16
 *
 *    float32 -int32 -float32 -float32
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the dimension other than N (ci * hi * wi) is a multiple of 128.
 *
 *  **Supports only MLU270.**
 *
 * @param[out] op
 *   Output. A pointer pointing to the base operator address.
 * @param[in] ref_tensor
 *   Input. A four-dimensional input tensor, the shape of which is [ni, ci, hi, wi].
 *   The datatype of the ref can be float16 or float32.
 * @param[in] index_tensor
 *   Input. A four-dimensional input tensor, the shape of which is
 *   [1, 1, 1, c_index], int32 or uint32 datatype is supported.
 * @param[in] updates_tensor
 *   Input. A four-dimensional tensor, the shape of which is [c_index, ci, hi, wi].
 *   The datatype of the update should be the same as the ref.
 * @param[in] ref_out_tensor
 *   Input. A four-dimensional tensor. Because that the tensor is an in-place operator,
 * ref_out_tensor should be the same as the ref_tensor.
 * @param[in] param
 *   Input. A struct param for the scatterref operator, including a scatterType scatter_add,
 * scatter_sub, scatter_max, scatter_min, scatter_mul, scatter_div and scatter_update.
 *   scatter_div is not supported for now.
 *   @retval CNML_STATUS_SUCCESS
 *     The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterRefOp(cnmlBaseOp_t *op,
                                                 cnmlTensor_t ref_tensor,
                                                 cnmlTensor_t index_tensor,
                                                 cnmlTensor_t updates_tensor,
                                                 cnmlTensor_t ref_out_tensor,
                                                 cnmlScatterRefOpParam_t param);
/*!
 * @brief A function.
 *
 * Compute the ScatterRef operator specified by users on MLU.
 *
 * After creating a pointer pointing to the base operators, the ScatterRef operator ref tensor,
 * index tensor, updates Tensor and output Tensor, pass them into the function to create the
 * ScatterRef operator.
 *
 *   **Formula**
 *
 *     For ref[ni, ci, hi, wi], index[1, c_index, 1, 1] and updates[c_index, ci, hi, wi]
 *
 *     scatter_add:
 *
 *       ref(out)[index[i], ci, hi, wi] += update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *    scatter_sub:
 *
 *       ref(out)[index[i], ci, hi, wi] -= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_mul:
 *
 *       ref(out)[index[i], ci, hi, wi] *= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_div:
 *
 *       ref(out)[index[i], ci, hi, wi] /= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_max:
 *
 *       ref(out)[index[i], ci, hi, wi] = max(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_min:
 *
 *       ref(out)[index[i], ci, hi, wi] = min(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_update:
 *
 *       ref(out)[index[i], ci, hi, wi] = update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *    The supported combinations of the data type of the tensors are as follows. The data type
 *    are shown in the following order:
 *
 *    ref_type -index_type -update_type -ref_out_type
 *
 *    Supported combinations are:
 *
 *    float16 -int32 -float16 -float16
 *
 *    float32 -int32 -float32 -float32
 *
 *  **Scale limitation**
 *
 *    Scatter_div is not supported for now.
 *
 * @param[out] output
 *   Output. The MLU address of the output position.
 * @param[in] op
 *   Input. A pointer to the base operators.
 * @param[in] ref
 *   Input. The MLU address of the ref data.
 * @param[in] index
 *   Input. The MLU address of the index data.
 * @param[in] updates
 *   Input. The MLU address of the updates data.
 * @param[in] param
 *   Input. A pointer to the struct address, which records the degree of data parallelism and device
 * affinity of runtime.
 * @param[in] queue
 *   Input. A comutational queue pointer.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 */
cnmlStatus_t cnmlComputeScatterRefOpForward(cnmlBaseOp_t op,
                                            void *ref,
                                            void *index,
                                            void *udpates,
                                            void *ref_out,
                                            cnrtInvokeFuncParam_t *compute_forw_param,
                                            cnrtQueue_t queue);

/*!
 * @brief A function.
 *
 * Compute the ScatterRef operator specified by users on MLU.
 *
 * After creating a pointer pointing to the base operators, the ScatterRef operator ref tensor,
 * index tensor, updates Tensor and output Tensor, pass them into the function to create the
 * ScatterRef operator.
 *
 *   **Formula**
 *
 *     For ref[ni, ci, hi, wi], index[1, c_index, 1, 1] and updates[c_index, ci, hi, wi]
 *
 *     scatter_add:
 *
 *       ref(out)[index[i], ci, hi, wi] += update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *    scatter_sub:
 *
 *       ref(out)[index[i], ci, hi, wi] -= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_mul:
 *
 *       ref(out)[index[i], ci, hi, wi] *= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_div:
 *
 *       ref(out)[index[i], ci, hi, wi] /= update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *     scatter_max:
 *
 *       ref(out)[index[i], ci, hi, wi] = max(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_min:
 *
 *       ref(out)[index[i], ci, hi, wi] = min(update[i, ci, hi, wi], ref[index[i], ci, hi, wi])
 *       {i in [0, c_index]}
 *
 *     scatter_update:
 *
 *       ref(out)[index[i], ci, hi, wi] = update[i, ci, hi, wi] {i in [0, c_index]}
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *    The supported combinations of the data type of the tensors are as follows. The data type
 *    are shown in the following order:
 *
 *    ref_type -index_type -update_type -ref_out_type
 *
 *    Supported combinations are:
 *
 *    float16 -int32 -float16 -float16
 *
 *    float32 -int32 -float32 -float32
 *
 *  **Scale limitation**
 *
 *    Scatter_div is not supported for now.
 *
 *  @param[out] ref_out
 *   Output. The MLU address of the output position.
 *  @param[in] op
 *   Input. A pointer to the base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] ref
 *   Input. The MLU address of the ref data.
 *  @param[in] index_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] index
 *   Input. The MLU address of the index data.
 *  @param[in] updates_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] updates
 *   Input. The MLU address of the updated data.
 *  @param[in] ref_out_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] queue
 *   Input. A comutational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 */
cnmlStatus_t cnmlComputeScatterRefOpForward_V4(cnmlBaseOp_t op,
                                               cnmlTensor_t input_tensor,
                                               void *ref,
                                               cnmlTensor_t index_tensor,
                                               void *index,
                                               cnmlTensor_t updates_tensor,
                                               void *updates,
                                               cnmlTensor_t ref_out_tensor,
                                               void *ref_out,
                                               cnrtQueue_t queue,
                                               void *extra);
/* scatterref operation end */

/* normalizeLite operation start */
/*!
 * @struct cnmlNormalizeLiteOpParam
 * @brief A struct
 *
 * cnmlNormalizeLiteOpParam is a structure describing the param parameter of normalize
 * operation,used to create normalizeLite operation.
 * cnmlCreateNormalizeLiteOpParam() is used to create an instance of cnmlNormalizeLiteOpParam_t.
 * cnmlDestroyNormalizeLiteOpParam() is used to destroy an instance of cnmlNormalizeLiteOpParam_t.
 * **/
struct cnmlNormalizeLiteOpParam;
/*!
 * ``cnmlNormalizeLiteOpParam_t`` is a pointer to ``cnmlNormalizeLiteOpParam`` ,which is a
 * structure holding the description of an normalized operation param.
 */
typedef struct cnmlNormalizeLiteOpParam *cnmlNormalizeLiteOpParam_t;
/*!
 * **Description**
 *
 *  @brief A function.
 *  According to the pointer given by the user, the function createss a sample normalized operator
 *  operation parameter struct, and fills in the struct with the parameters input by the user.
 *
 *  Description: normalize lite operation use L2-norm
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the L2-Normalized operator parameter.
 *  @param[in] axis
 *    Input. The range of value is [-4 ,3] , axis={0,1,2,3} or axis={-4,-3,-2,-1} perform
 *normalization on (N,C,H,W)
 *  respectively.
 *  @param[in] epsilon
 *    Input. Add epsilon param at denonminator to avoid denominator value is zero.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 **/
CNML_DLL_API cnmlStatus_t cnmlCreateNormalizeLiteOpParam(cnmlNormalizeLiteOpParam_t *param,
                                                         int axis,
                                                         float epsilon);
/*!
 * **Description**
 *
 * @brief A function.
 *
 * According to the pointer given by the user, the struct pointer of normalized operator operation
 * parameter is freed.
 *
 * At the end of normalized operator operation, the created struct pointer of normalized operator
 * operation parameter is freed.
 *
 * **Supports only MLU270.**
 *
 **  @param[in] param
 **    Input. A pointer pointing to the address of struct of normalized operator operation
 *parameter.
 **  @retval CNML_STATUS_SUCCESS
 **    The function ends normally.
 **  @retval CNML_STATUS_INVALIDPARAM
 **    At least one of the following conditions are met:
 **    - param is a null pointer.
 **    - The content of the pointer pointed to by param has been freed.
 **/
CNML_DLL_API cnmlStatus_t cnmlDestroyNormalizeLiteOpParam(cnmlNormalizeLiteOpParam_t *param);

/*!
 *  **Description**
 *
 *  @brief A function.
 *
 *  According to the basic Operator pointer given by the user, a normalized operator is created.
 *  Typically the normalization is performed by calculating the mean and standard deviation of
 *  a subgroup in your input tensor.
 *  The normalization operation is performed on the input N, C, H, W,direction (Only
 *   L2 norm can be used). The axis can be used to control the range of normalized
 *  data values.
 *
 *  **Reference:** This function is based on the https://arxiv.org/pdf/1803.08494/pdf
 *   *
 *
 *  **Formula**
 *
 *  L2 noramalization:
 *
 *  such as ``specified_dims`` is set to 3, Tensor Layout is NHWC
 *
 *  for all n  in [0,N), h in [0,H), w in [0,W);
 *
 *    sum = param.epsilon;
 *
 *    for c in [0,C);
 *
 *      sum =+ Square(in[n,c,h,w]);
 *
 *    norm[n,1,w,h] = Sqrt(sum);
 *
 *    for c in [0,C];
 *
 *      out[n,c,h,w] = in[n,c,h,w]/norm[n,1,w,h];
 *
 *
 *  The ``spacified_dim``` are dimensions to calculate the L2 norm, which is specified by the
 *
 *  variable model param: axis, it can be a negative number;
 *
 *  ``in[]`` specifies the input_tensor;
 *
 *  ``norm[]`` spacifies the norm_tensor;
 *
 *  ``out[]`` spacifies the output_tensor;
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     -input: float16, float32
 *
 *     -output:float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     Unlimited in FP32.
 *
 *     limited in FP16: Due to the range of fp16 numbers, output may be some deviation , when norm
 * is less than 1E-3.
 *
 *  **Support only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A struct pointer of normalized operation param.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi].
 *  @param[out] norm_tensor
 *    Output. A 4-dimensional MLU output tensor,
 *    if param.axis=0 or -4 , the shape of norm tensor is [ 1, ci, hi, wi].
 *    if param.axis=1 or -3 , the shape of norm tnesor is [ni,  1, hi, wi].
 *    if param.axis=2 or -2 , the shape of norm tnesor is [ni, ci,  1, wi].
 *    if param.axis=3 or -1 , the shape of norm tnesor is [ni, ci, hi,  1].
 *
 *  @param[out] output_tensor
 *    Output. A 4-dimensional MLU output tensor, the shape is [ni, ci, hi, wi].
 *
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNormalizeLiteOp(cnmlBaseOp_t *op,
                                                    cnmlNormalizeLiteOpParam_t param,
                                                    cnmlTensor_t input_tensor,
                                                    cnmlTensor_t norm_tensor,
                                                    cnmlTensor_t output_tensor);

/*!
 *  **Description**
 *  @brief A function.
 *  Computing user-specified normalized operators on MLU.
 *
 *  After the normalized operator, input, output and computational stream are created, they are
 *  introduced into the function to compute normalized operator.
 *
 *  **Supports only MLU270.**
 *
 *  **DataType**
 *    MLU270:
 *       -input:float16, float32
 *       -output:float16,float32
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[out] norm
 *    Output. An MLU address pointing to the denominator of Normalization.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNormalizeLiteOpForward(cnmlBaseOp_t op,
                                                            cnmlTensor_t *input_tensor,
                                                            void *input,
                                                            cnmlTensor_t *norm_tensor,
                                                            void *norm,
                                                            cnmlTensor_t *output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/* normalizeLite operation end */

/* normalize operation start */
/*!
 *  @struct cnmlNormalizeOpParam
 *  @brief A struct.
 *
 *  cnmlNormalizeOpParam is a structure describing the param parameter of normalize operation, used
 *  to create normalize operation. cnmlCreateNormalizeOpParam() is used to create an instance of
 *  cnmlNormalizeOpParam_t. cnmlDestroyNormalizeOpParam() is used to destroy an instance of
 *  cnmlNormalizeOpParam_t. */
struct cnmlNormalizeOpParam;
/*! ``cnmlNormalizeOpParam_t`` is a pointer to ``cnmlNormalizeOpParam`` which is a
    structure holding the description of a normalized operation param. */
typedef struct cnmlNormalizeOpParam *cnmlNormalizeOpParam_t;
//  mode=(0, 1, 2, 3, 4, 5) ---> (channel, space, instance, batch, height, width)
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a normalized operator operation
 *  parameter struct, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the normalized operator operation
 *  parameter.
 *  @param[in] p
 *    Input. When the input is 1, L1 norm is adopted, otherwise L2 norm is adopted.
 *  @param[in] use_scale
 *    Input. When the input is 1, scale_tensor is used to control the value range of output;
 * otherwise, the weight in the parameter is used to control the value range of output.
 *  @param[in] mode
 *    Input. The range of value is 0-5, mode=(0, 1, 2, 3, 4, 5) perform normalization on (C, HW,
 *  HWC, N, H, W) respectively.
 *  @param[in] weight
 *    Input. If use_scale == 0, when normalization is complete, multiply the result by weight.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNormalizeOpParam(cnmlNormalizeOpParam_t *param,
                                                     int p,
                                                     int use_scale,
                                                     int mode,
                                                     float weight);
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a normalized operator operation
 *  parameter struct, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU 270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of the normalized operator operation
 *  parameter.
 *  @param[in] p
 *    Input. When the input is 1, L1 norm is adopted, otherwise L2 norm is adopted.
 *  @param[in] use_scale
 *    Input. When the input is 1, scale_tensor is used to control the value range of output;
 *  otherwise, the weight in the parameter is used to control the value range of output.
 *  @param[in] mode
 *    Input. The range of value is 0-5, mode=(0, 1, 2, 3, 4, 5) perform normalization on (C, HW,
 *  HWC, N, H, W) respectively.
 *  @param[in] weight
 *    Input. If use_scale == 0, when normalization is complete, multiply the result by weight.*
 *  @param[in] eps
 *    Input. Add eps param at denominator to avoid denominator value is zero .
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNormalizeOpParamV2(cnmlNormalizeOpParam_t *param,
                                                       int p,
                                                       int use_scale,
                                                       int mode,
                                                       float weight,
                                                       float eps);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of normalized operator operation
 *  parameter is freed.
 *
 *  At the end of normalized operator operation, the created struct pointer of normalized operator
 *  operation parameter is freed.
 *
 *  **Supports only MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of normalized operator operation parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNormalizeOpParam(cnmlNormalizeOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Creates a Normalization operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, a pointer to normalize operation param,
 *  input, scale(optional) and output tensors, pass them to the function to create a Normalization
 *  operator.
 *
 *  The normalization operation performs L1 or L2 normalization on varied dimensions of input
 *  tensor. Additionally, a zooming factor can be used to control the range of normalized data
 *  values.
 *
 *  **Related APIs**
 *    APIs Before:
 *      createCnmlNormalizeOpParamV2(or createCnmlNormalizeOpParam), cnmlCreateTensor
 *    APIs After:
 *      cnmlDestroyBaseOp, cnmlFuseOp(optional), cnmlComputeNormalizeOp(optional)
 *
 *  **Lifetime**
 *    The op can be released after calling cnmlFuseOp or cnmlComputeNormalizeOp.
 *    The param, input_tensor, scale_tensor, and output_tensor can be released intermediatelly
 *    after this function.
 *
 *  **Formula**
 *  L1 normalization:
 *    for all n in [0, N), c in [O, C), h in [0, H), w in [0, W):
 *       out[n, c, h, w] = in[n, c, h, w] / (Sum(Abs(in[n, c, h, w]), specified_dims) + eps)
 *       if use_scale == 0:
 *         out[n, c, h, w] = weight * out[n, c, h, w]
 *       else:
 *         out[n, c, h, w] = scale[n, c, h, w] * out[n, c, h, w]
 *  L2 normalization:
 *    for all n in [0, N), c in [O, C), h in [0, H), w in [0, W):
 *       out[n, c, h, w] = in[n, c, h, w] / Sqrt((Sum(Square(in[n, c, h, w]), specified_dims) + eps)
 *       if use_scale == 0:
 *         out[n, c, h, w] = weight * out[n, c, h, w]
 *       else:
 *         out[n, c, h, w] = scale[n, c, h, w] * out[n, c, h, w]
 *
 *  The ``specified_dims`` are dimensions to calculate the L1 or L2 norm, which is specified by
 *  the variable mode in param. The eps is a value specified in param.
 *  ``in[]`` specifies the input_tensor, ``scale[]`` specifies the scale_tensor  and ``out[]``
 *  specifies the output_tensor.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      - input: float16, float32
 *      - output: float16, float32
 *
 * **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited.
 *
 *  **Performance Optimization**
 *
 *    The normalization across Channel(mode = c) or Instance(mode = hwc) is faster than other modes,
 *    since other modes require inner data transpose.
 *
 *    The number of bytes of elements within specified_dims is a multiple of 128.
 *
 *  **Deep Fusion**
 *
 *    Not involved
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A struct pointer of normalized operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo](no = ni).
 *  @param[in] scale_tensor
 *    Input. Optional. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi]. Required
 *    when the variable use_scale of param is not equal to 0.
 *  @param[in] is_fix8_mode
 *    Input. A bool type to set fix8 quant mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNormalizeOp(cnmlBaseOp_t *op,
                                                cnmlNormalizeOpParam_t param,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t scale_tensor,
                                                bool is_fix8_mode);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNormalizeOpForward_V4 is recommended to use.
 *
 *  Computing user-specified normalized operators on MLU.
 *
 *  After the normalized operator, input, output, parameter at runtime and computational queue are
 *  created, they are introduced into the function to compute normalized operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeNormalizeOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 void *scale,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified normalized operators on MLU.
 *
 *  After the normalized operator, input, output, parameter at runtime and computational queue are
 *  created, they are introduced into the function to compute normalized operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] scale_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] scale
 *    Input. An MLU address pointing to input data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNormalizeOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnmlTensor_t scale_tensor,
                                                           void *scale,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* normalize operation end */

/* Cos Similarity operation start */

/*!
 *  @brief cnmlCreateCosSimilarityOp.
 *
 *  It creates a cos similarity operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, two inputs tensors and an output tensor,
 *  introduce them into function to creat a cos similarity operation.
 *
 *  **Formula**
 *
 *  Refer to: y = A.B/(||A||.||B||) =(âˆ‘(Ai* Bi))/(sqrt(âˆ‘(Ai^2)*sqrt(âˆ‘(Bi^2))
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  inputA
 *    inputA. An MLU input tensor. Input data range should in [-1, 1]. if the input count exceeds
 *    512, the error rate will increase.
 *  @param[in]  inputB
 *    inputB. An MLU input tensor. Input data range should in [-1, 1]. if the input count exceeds
 *    512, the error rate will increase.
 *  @param[in]  output
 *    Output. An MLU address pointing to output tensor. The output shape is [1, 1, 1, 1].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - The input tensor type is either CNML_TENSOR or CNML_CONST.
 *    - The CPU tensor bound to the bias tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCosSimilarityOp(cnmlBaseOp_t *op,
                                                    const cnmlTensor_t inputTensorA,
                                                    const cnmlTensor_t inputTensorB,
                                                    const cnmlTensor_t outputTensor);
/*!
 *  @brief cnmlComputeCosSimilarityOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCosSimilarityOpForward_V2 is recommended to use.
 *
 *  It computes the user-specified cos similariy operation on the MLU.
 *
 *  After creating cos similarity operation, related parameters and computation stream, introduce
 *  them into the function to cumpute the cos similarity operation.
 *
 *  **Formula**
 *
 *  Refer to: y = A.B/(||A||.||B||) =(âˆ‘(Ai* Bi))/(sqrt(âˆ‘(Ai^2)*sqrt(âˆ‘(Bi^2))
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input1
 *    Input1. An MLU address pointing to the input1 data, input range should in [-1, 1]. if the
 * input
 *    count exceeds 512, the error rate will increase.
 *  @param[in] input2
 *    Input2. An MLU address pointing to the input2 data, input range should in [-1, 1]. if the
 * input
 *    count exceeds 512, the error rate will increase.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *    parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeCosSimilarityOpForward(cnmlBaseOp_t op,
                                  void *inputTensor1,
                                  void *inputTensor2,
                                  void *outputTensor,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeCosSimilarityOpForward_V2.
 *
 *  It computes the user-specified cos similariy operation on the MLU.
 *
 *  After creating cos similarity operation, related parameters and computation stream, introduce
 *  them into the function to cumpute the cos similarity operation.
 *
 *  **Formula**
 *
 *  Refer to: y = A.B/(||A||.||B||) =(âˆ‘(Ai* Bi))/(sqrt(âˆ‘(Ai^2)*sqrt(âˆ‘(Bi^2))
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCosSimilarityOpForward_V2(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor1,
                                                               void *input1,
                                                               cnmlTensor_t input_tensor2,
                                                               void *input2,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);
/* Cos Similarity operation end */

/* grep channel operation start */
/*!
 *  @struct cnmlGrepChannelOpParam
 *  @brief A struct.
 *
 *  cnmlGrepChannelOpParam. is a structure describing the param parameter of grep channel operation,
 *  used to create grep channel operation. cnmlCreateGrepChannelOpParam() and
 *  cnmlCreateGrepChannelOpParam_V2() is used to create an instance of cnmlGrepChannelOpParam_t.
 *  cnmlDestroyGrepChannelOpParam() is used to destroy an instance of cnmlGrepChannelOpParam_t. */
struct cnmlGrepChannelOpParam;
/*! ``cnmlGrepChannelOpParam_t`` is a pointer to ``cnmlGrepChannelOpParam`` which is a
    structure holding the description of a grep channel operation param. */
typedef struct cnmlGrepChannelOpParam *cnmlGrepChannelOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a GrepChannel operator
 *  operation parameter struct, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of GrepChannel operator operation
 *  parameter.
 *  @param[in] channel
 *    Input. The discarded length in c direction.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrepChannelOpParam(cnmlGrepChannelOpParam_t *param,
                                                       int channel_);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct of GrepChannel
 *  operator operation parameter, and fills in the struct with parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of GrepChannel operator operation
 *  parameter.
 *  @param[in] c_front_
 *    Input. The discarded length above the c direction.
 *  @param[in] c_back_
 *    Input. The discarded length down in the c direction.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrepChannelOpParam_V2(cnmlGrepChannelOpParam_t *param,
                                                          int c_front_,
                                                          int c_back_);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of GrepChannel operator operation
 *  parameter is freed.
 *
 *  At the end of GrepChannel operator operation, the created struct pointer of GrepChannel operator
 *  operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of GrepChannel operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyGrepChannelOpParam(cnmlGrepChannelOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the basic Operator pointer given by the user, a GrepChannel operator is created.
 *
 *  Similarly to grep, a small tensor is intercepted from the input tensor. Note: can only be
 *  intercepted from c direction.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] param
 *    Input. A struct pointer of normalized operation.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, the shape is [no, co, ho, wo],supporting data of
 *  float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrepChannelOp(cnmlBaseOp_t *op,
                                                  cnmlGrepChannelOpParam_t param,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGrepChannelOpForward_V4 is recommended to use.
 *
 *  Computing user-specified GrepChannel operators on MLU.
 *
 *  After the GrepChannel operators, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute GrepChannel operators.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeGrepChannelOpForward_V3(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified GrepChannel operators on MLU.
 *
 *  After the GrepChannel operators, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute GrepChannel operators.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGrepChannelOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* grep channel operation end */

/* crop start */
/*!
 *  @struct cnmlCropOpParam
 *  @brief A struct.
 *
 *  cnmlCropOpParam is a structure describing the param parameter of crop operation, used to create
 *  crop operation. cnmlCreateCropOpParam() is used to create an instance of cnmlCropOpParam_t.
 *  cnmlDestroyCropOpParam() is used to destroy an instance of cnmlCropOpParam_t. */
struct cnmlCropOpParam;
/*! ``cnmlCropOpParam_t`` is a pointer to ``cnmlCropOpParam`` which is a
    structure holding the description of a crop operation param. */
typedef struct cnmlCropOpParam *cnmlCropOpParam_t;

/*!
 *  @brief A function.
 *
 *  Constructing the param of the crop operator requires offset of the starting address
 *  in the four directions n, c, h, w.
 *
 *  Space_number is the number that needs to be complemented in four directions
 *  (currently, it is not supported to make a complement in each direction).
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input.  A param pointer.
 *  @param[in] start_index_n
 *    Input.  The four int data are the start positions where the four dimensions are intercepted.
 *  @param[in] start_index_c
 *    Input.  The four int data are the start positions where the four dimensions are intercepted.
 *  @param[in] start_index_h
 *    Input.  The four int data are the start positions where the four dimensions are intercepted.
 *  @param[in] start_index_w
 *    Input.  The four int data are the start positions where the four dimensions are intercepted.
 *  @param[in] space_number
 *    Input.  A float type to fill up.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCropOpParam(cnmlCropOpParam_t *param,
                                                int start_index_n,
                                                int start_index_c,
                                                int start_index_h,
                                                int start_index_w,
                                                float space_number);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of Grep operator operation
 *  parameter is freed.
 *
 *  At the end of Grep operator operation, the created struct pointer of Grep operator
 *  operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of Grep operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyCropOpParam(cnmlCropOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the param input by the user, intercept the data from the param.start_index_n by the
 *  length of the output_Tensor_shape.n on the input_Tensor_shape.n, and perform the same operation
 *  in the C, H, W directions.
 *
 *  If only intercept in direction C(no = ni, ho = hi, wo = wi), it will call split operation
 *  actually.
 *
 *  If don't intercept in direction C(co = ci), it will call grep operation actually.
 *
 *  For other strategies, it will call stride_slice actually.
 *
 *  **Formula**
 *
 *    Intercept output tensor from each dimension of input tensor.
 *
 *    output[n, c, h, w] = input[start_index_n + n, start_index_c + c, start_index_h + h,
 *    start_index_w + w]
 *
 *    start_index_n is the start positions where the n dimensions are intercepted.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    no <= (ni - start_index_n);
 *
 *    co <= (ci - start_index_c);
 *
 *    ho <= (hi - start_index_h);
 *
 *    wo <= (wi - start_index_w);
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] param
 *    Input.  Param of crop.
 *  @param[in] input_tensor
 *    Input.  A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A 4-dimensional MLU input tensor, of which the shape is [no, co, ho, wo],
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions is not met:
 *    - Op is empty.
 *    - Input_tensor is empty.
 *    - Output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCropOp(cnmlBaseOp_t *op,
                                           cnmlCropOpParam_t param,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCropOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified threshold operator on the MLU.
 *
 *  **Formula**
 *
 *    Intercept output tensor from each dimension of input tensor.
 *
 *    output[n, c, h, w] = input[start_index_n + n, start_index_c + c, start_index_h + h,
 *    start_index_w + w]
 *
 *    start_index_n is the start positions where the n dimensions are intercepted.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    no <= (ni - start_index_n);
 *
 *    co <= (ci - start_index_c);
 *
 *    ho <= (hi - start_index_h);
 *
 *    wo <= (wi - start_index_w);
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Input.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the address of the struct, in which the data parallelism
 *    and device affinity at runtime are recorded.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - Input parameter operator pointer op is empty.
 *    - Input parameter tensor pointer input is empty.
 *    - Output parameter tensor pointer output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCropOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  It is used to compute the user-specified crop operator on the MLU.
 *
 *  **Formula**
 *
 *    Intercept output tensor from each dimension of input tensor.
 *
 *    output[n, c, h, w] = input[start_index_n + n, start_index_c + c, start_index_h + h,
 *    start_index_w + w]
 *
 *    start_index_n is the start positions where the n dimensions are intercepted.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    no <= (ni - start_index_n);
 *
 *    co <= (ci - start_index_c);
 *
 *    ho <= (hi - start_index_h);
 *
 *    wo <= (wi - start_index_w);
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCropOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* crop operation end */

/* Nd crop start */
/*!
 *  @struct cnmlNdCropOpParam
 *  @brief A struct.
 *
 *  cnmlNdCropOpParam is a structure describing the param parameter of crop operation, used to
 * create
 *  crop operation. cnmlCreateNdCropOpParam() is used to create an instance of cnmlNdCropOpParam_t.
 *  cnmlDestroyNdCropOpParam() is used to destroy an instance of cnmlNdCropOpParam_t. */
struct cnmlNdCropOpParam;
/*! ``cnmlNdCropOpParam_t`` is a pointer to ``cnmlNdCropOpParam`` which is a
    structure holding the description of a crop operation param. */
typedef struct cnmlNdCropOpParam *cnmlNdCropOpParam_t;

/*!
 *  @brief A function.
 *
 *  Constructing the param of the crop operator requires offset of the starting address.
 *
 *  Space_number is the number that needs to be complemented in four directions
 *  (currently, it is not supported to make a complement in each direction).
 *
 *  **Supports MLU270.**
 *
 *  @param[in] param
 *    Input.  A param pointer.
 *  @param[in] dimNum
 *    Input. Total dimNum of start.
 *  @param[in] start
 *    Input.  The start positions.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCropOpParam(cnmlNdCropOpParam_t *param,
                                                  int dimNum,
                                                  int *start);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of Grep operator operation
 *  parameter is freed.
 *
 *  At the end of Grep operator operation, the created struct pointer of Grep operator
 *  operation parameter is freed.
 *
 *  **Supports both MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of nd Crop operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNdCropOpParam(cnmlNdCropOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the param input by the user, intercept the data from the param.start_index_n by the
 *  length of the output_Tensor_shape.n on the input_Tensor_shape.n, and perform the same operation
 *  in the C, H, W directions.
 *
 *  **Supports MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] param
 *    Input.  Param of nd crop.
 *  @param[in] input_tensor
 *    Input.  A n-dimensional MLU input tensor, of which the shape is array,
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A n-dimensional MLU input tensor, of which the shape is arry,
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions is not met:
 *    - Op is empty.
 *    - Input_tensor is empty.
 *    - Output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCropOp(cnmlBaseOp_t *op,
                                             cnmlNdCropOpParam_t param,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  It is used to compute the user-specified threshold operator on the MLU.
 *
 *  **Supports MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdCropOpForward(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* Nd crop operation end */

/* pool operation start */
/*!
 *  @struct cnmlPoolOpParam
 *  @brief A struct.
 *
 *  ``cnmlPoolOpParam`` is a structure holding the description of
 *  a pooling operation param. */
struct cnmlPoolOpParam;
/*! ``cnmlPoolOpParam_t`` is a pointer to ``cnmlPoolOpParam`` which is a
    structure holding the description of a pooling operation param. */
typedef struct cnmlPoolOpParam *cnmlPoolOpParam_t;
/*!
 *  @brief A function.
 *
 *  This function creates a pooling param object by allocating the
 *  memory needed to hold its opaque structure.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. The returning param descriptor.
 *  @param[in] window_height
 *    Input. Height of the pooling window.
 *  @param[in] window_width
 *    Input. Width of the pooling window.
 *  @param[in] stride_height
 *    Input. Pooling vertical stride.
 *  @param[in] stride_width
 *    Input. Pooling horizontal stride.
 *  @param[in] pad_height
 *    Input. Size of vertical padding.
 *  @param[in] pad_width
 *    Input. Size of horizontal padding.
 *  @param[in] dilation_height
 *    Input. Size of vertical dilation.
 *  @param[in] dilation_width
 *    Input. Size of horizontal dilation.
 *  @param[in] pool_mode Input.
 *    Enumerant to specify the pooling mode.
 *  @param[in] strategy_mode
 *    Input. Enumerant to specify the pooling strategy mode.
 *  @param[in] real
 *    Input. real
 *  @param[in] blend_factor
 *    Input. BlendFactor used in blend pool mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolOpParam_V2(cnmlPoolOpParam_t *param,
                                                   int window_height,
                                                   int window_width,
                                                   int stride_height,
                                                   int stride_width,
                                                   int pad_height,
                                                   int pad_width,
                                                   int dilation_height,
                                                   int dilation_width,
                                                   cnmlPoolMode_t pool_mode,
                                                   cnmlPoolStrategyMode_t strategy_mode,
                                                   bool real,
                                                   float blend_factor);

/*!
 *  @brief A function.
 *
 *  This function creates a pooling param object by allocating the
 *  memory needed to hold its opaque structure.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww].
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. The returning param descriptor.
 *  @param[in] window_height
 *    Input. Height of the pooling window.
 *  @param[in] window_width
 *    Input. Width of the pooling window.
 *  @param[in] stride_height
 *    Input. Pooling vertical stride.
 *  @param[in] stride_width
 *    Input. Pooling horizontal stride.
 *  @param[in] pad_height
 *    Input. Size of vertical padding.
 *  @param[in] pad_width
 *    Input. Size of horizontal padding.
 *  @param[in] dilation_height
 *    Input. Size of vertical dilation.
 *  @param[in] dilation_width
 *    Input. Size of horizontal dilation.
 *  @param[in] pool_mode Input.
 *    Enumerant to specify the pooling mode.
 *  @param[in] strategy_mode
 *    Input. Enumerant to specify the pooling strategy mode.
 *  @param[in] real
 *    Input. real
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolOpParam(cnmlPoolOpParam_t *param,
                                                int window_height,
                                                int window_width,
                                                int stride_height,
                                                int stride_width,
                                                int pad_height,
                                                int pad_width,
                                                int dilation_height,
                                                int dilation_width,
                                                cnmlPoolMode_t pool_mode,
                                                cnmlPoolStrategyMode_t strategy_mode,
                                                bool real);

/*!
 *  @brief A function.
 *
 *  This function creates a pooling param object by allocating the
 *  memory needed to hold its opaque structure.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. The returning param descriptor.
 *  @param[in] window_height
 *    Input. Height of the pooling window.
 *  @param[in] window_width
 *    Input. Width of the pooling window.
 *  @param[in] stride_height
 *    Input. Pooling vertical stride.
 *  @param[in] stride_width
 *    Input. Pooling horizontal stride.
 *  @param[in] pad_top
 *    Input. Size of vertical top padding.
 *  @param[in] pad_bottom
 *    Input. Size of vertical bottom padding.
 *  @param[in] pad_left
 *    Input. Size of horizontal left padding.
 *  @param[in] pad_bottom
 *    Input. Size of horizontal right padding.
 *  @param[in] dilation_height
 *    Input. Size of vertical dilation.
 *  @param[in] dilation_width
 *    Input. Size of horizontal dilation.
 *  @param[in] pool_mode Input.
 *    Enumerant to specify the pooling mode.
 *  @param[in] strategy_mode
 *    Input. Enumerant to specify the pooling strategy mode.
 *  @param[in] real
 *    Input. real
 *  @param[in] blend_factor
 *    Input. BlendFactor used in blend pool mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolOpParam_V3(cnmlPoolOpParam_t *param,
                                                   int window_height,
                                                   int window_width,
                                                   int stride_height,
                                                   int stride_width,
                                                   int pad_top,
                                                   int pad_bottom,
                                                   int pad_left,
                                                   int pad_right,
                                                   int dilation_height,
                                                   int dilation_width,
                                                   cnmlPoolMode_t pool_mode,
                                                   cnmlPoolStrategyMode_t strategy_mode,
                                                   bool real,
                                                   float blend_factor);

/*!
 *  @brief A function.
 *
 *  This function destroys a previously created pooling param
 *  descriptor object
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. Pointer to the structure holding the description of the
 *    pooling param to be deleted.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyPoolOpParam(cnmlPoolOpParam_t *param);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreatePoolOpForward is recommended to use.
 *
 *  This function creates a pooling op object by allocating the memory
 *  needed to hold its opaque structure.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww].
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. The returning op descriptor.
 *  @param[in] param
 *    Input. Param of this pooling op.
 *  @param[in] input
 *    Input. Input cnml tensor of this pooling op.
 *  @param[in] output
 *    Input. Input cnml tensor of this pooling op.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolOp(cnmlBaseOp_t *op,
                                           cnmlPoolOpParam_t param,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  This function creates a pooling op object by allocating the memory
 *  needed to hold its opaque structure.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    kernel[kh, kw]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < kh, 0 <= dj < kw}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (kh * kw), {0 <= di < kh, 0 <= dj < kw}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input_typetype: int8, int16, float16, float32
 *
 *        compute_type: float16, float32
 *
 *        output_type: int8, int16, float16, float32
 *
 *        compute_type.dataSize >= input_type.dataSize
 *
 *        compute_type.dataSize >= output_type.dataSize
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *        compute_type.dataSize >= input_type.dataSize
 *
 *        compute_type.dataSize >= output_type.dataSize
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 * **Performance Optimization**
 *
 *   maxpool and avgpool :
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *   avgpool:
 *
 *    When kh * kw <= 36, the computing speed is higher with the loss of precision up to 1%
 *
 *    When kh * kw > 36, the precision is better with lower computing speed.
 *
 *      For best practice and higher performance, the size of the data in C dimension should
 *    be less than 131,072B, and the data in C dimension should be a multiple of 128.
 *    Otherwise the performance is getting worse.
 *
 *    Where ``kh`` is the height of the kernel tensor and ``kw`` is the width of the kernel tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. The returning op descriptor.
 *  @param[in] param
 *    Input. Param of this pooling op.
 *  @param[in] input
 *    Input. Input cnml tensor of this pooling op.
 *  @param[in] output
 *    Input. Input cnml tensor of this pooling op.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolOpForward(cnmlBaseOp_t *op,
                                                  cnmlPoolOpParam_t param,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputePoolOpForward_V4 is recommended to use.
 *
 *  Computing pool operator run on MLU.
 *
 *  After the pool operator, input, output, and computational stream are created, they are
 *  introduced into the function for operation.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    window[wh, ww]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < wh, 0 <= dj < ww}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (wh * ww), {0 <= di < wh, 0 <= dj < ww}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] type
 *    Input. An enumeration value specifying how to compute on MLU.
 *  @param[in] stream
 *    Input. A computational stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputePoolOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing pool operator run on MLU.
 *
 *  After the pool operator, input, output, and computational stream are created, they are
 *  introduced into the function for operation.
 *
 *  **Formula**
 *
 *    For input[ni, ci, hi, wi], output[no. co. ho. wo], stride[sh, sw],
 *    kernel[kh, kw]
 *
 *    maxpool:
 *
 *      output[n, c, i, j] = max(input[n, c, i * sh + di, j * sw + dj]),
 *      {0 <= di < kh, 0 <= dj < kw}
 *
 *    avgpool:
 *
 *      output[n, c, i, j] = sum(input[n, c, i * sh + di, j * sw + dj]) /
 *      (kh * kw), {0 <= di < kh, 0 <= dj < kw}
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      maxpool:
 *
 *        input_typetype: int8, int16, float16, float32
 *
 *        compute_type: float16, float32
 *
 *        output_type: int8, int16, float16, float32
 *
 *        compute_type.dataSize >= input_type.dataSize
 *
 *        compute_type.dataSize >= output_type.dataSize
 *
 *      avgpool:
 *
 *        input: int8, int16, float16, float32
 *
 *        compute: float16, float32
 *
 *        output: int8, int16, float16, float32
 *
 *        compute_type.dataSize >= input_type.dataSize
 *
 *        compute_type.dataSize >= output_type.dataSize
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 * **Performance Optimization**
 *
 *   maxpool and avgpool :
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *   avgpool:
 *
 *    When kh * kw <= 36, the computing speed is higher with the loss of precision up to 1%
 *
 *    When kh * kw > 36, the precision is better with lower computing speed.
 *
 *    For best practice and higher performance, the size of the data in C dimension should
 *    be less than 131,072B, and the data in C dimension should be a multiple of 128.
 *    Otherwise the performance is getting worse.
 *
 *    Where ``kh`` is the height of the kernel tensor and ``kw`` is the width of the kernel tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputePoolOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* pool operation end */

/* reduce product operation start  */
/*!
 *  @brief A function.
 *
 *  Create a Reduce Product operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output tensor,  pass
 *  them into the fucntion to create a Reduce Product operator.
 *
 *  The Reduce Product loads data continuously, therefore, if the direction of reduce is n and the
 * size of seg*H*W is too large to load two Ns, the maximum value cannot be obtained.
 *
 *  **Supports only MLU270.**
 *
 *  **Formula**
 *
 *    Such as when input[ni, ci, hi, wi], output[no, co, ho, wo] and `d` direction is `c`, then
 *    output[n, c, h, w] = reduceproduct(n, c, h, w) = product_i(input[n, i, h, w])
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32, int16, int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 65280 because of at least process one full line c at a time
 *
 *  @param[out] op
 *    Output. A pointer to the Reduce Product operator you have created.
 *  @param[in] mode
 *    Input. An enumerated type specifies the dimension to reduce. Supported values are: N, C, H,
 *     and W.
 *  @param[in] input_tensor
 *    Input. A 4-D MLU tensor to reduce. You need to declare a tensor using the cnmlTensor_t
 *     datatype and create the tensor using the cnmlCreateTensor API.
 *  @param[in] output_tensor
 *    Input. The descriptor of the 4-D MLU output tensor. The size of other dimensions must be
 *    consistent with the input tensor.
 *    Supported data type of this tensor descriptor is FP32.
 *    You need to declare a tensor using the cnmlTensor_t datatype and create the tensor using the
 *    cnmlCreateTensor API.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateReduceProductOp(cnmlBaseOp_t *op,
                                                    cnmlDimension_t mode,
                                                    cnmlTensor_t input,
                                                    cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  Computes the product elements for a specified dimension of a tensor on MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReduceProductOpForward_V2 is recommended to use.
 *
 *  After creating Reduce Product operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute Reduce Product operator.
 *
 *  *  **Supports both MLU220 and MLU270.*
 *
 *  **Supports only MLU270.**
 *
 *  **Formula**
 *
 *    Such as when input[ni, ci, hi, wi], output[no, co, ho, wo] and `d` direction is `c`, then
 *    output[n, c, h, w] = reduceproduct(n, c, h, w) = product_i(input[n, i, h, w])
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32, int16, int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 65280 because of at least process one full line c at a time
 *
 *  @param[in] op
 *    Input. A pointer to the Reduce Product operator you have created.
 *  @param[in] input
 *    Input. A pointer to the data of the tensor you want to reduce.
 *  @param[out] output
 *    Output. A pointer to the data of the reduced tensor.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address that records the data parallelism and device affinity
 *    for runtime.
 *  @param[in] queue
 *    Input. A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions occurred:
 *    - The pointer to the Reduce Product operator is null.
 *    - The pointer to the data of the reduced tensor is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeReduceProductOpForward(cnmlBaseOp_t op,
                                  void *input,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the Reduce Product operator given by users on the MLU.
 *
 *  After creating Reduce Product operator, input, output, runtime parameters, and computation
 * queue, pass them into the function to compute Reduce Product operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReduceProductOpForward_V2(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor,
                                                               void *input,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);

/* ndpool operation start */
/*!
 *  @struct cnmlNdPoolOpParam
 *  @brief A struct.
 *
 *  ``cnmlNdPoolOpParam`` is a structure holding the description of
 *  a pooling nd operation param.
 *  Use cnmlCreateNdPoolOpParam to create an instance and cnmlDestroyNdPoolOpParam
 *  to destroy this instance. */
struct cnmlNdPoolOpParam;
/*! ``cnmlNdPoolOpParam_t`` is a pointer to a structure (cnmlNdPoolOpParam)
 *   holding the description of a pooling ND operation param. */
typedef struct cnmlNdPoolOpParam *cnmlNdPoolOpParam_t;

/*!
 *  @brief A function.
 *
 *  Creates a pooling ND param object by allocating the
 *  memory used for holding the opaque structure of the pooling ND op.
 *
 *  **Formula**
 *
 *    maxpool:
 *
 *      output[n, c, d, h, w] = max(input[n, c, d * sd + dd, h * sh + dh, w * sw + dw]),
 *      {0 <= dd <= wd, 0 <= dh < wh, 0 <= dw < ww}
 *
 *    avgpool:
 *
 *      output[n, c, d, h, w] = sum(input[n, c, d* sd + dd, h * sh + dh, w * sw + dw]) /
 *      (wd * wh * ww), {0 <= dd <= wd, 0 <= di < wh, 0 <= dj < ww}
 *
 *  OutputDim:
 *
 *    if strategy_mode is KVALID:
 *
 *      outputDim = 1 + (inputDim + 2 * paddings - kernel_size) / strides
 *
 *    else if strategy_mode if KFULL:
 *
 *      if poolingStride > poolingKernel:
 *
 *        outputDim = (inputDim - 1) / strides + 1
 *
 *      else:
 *
 *        outputDim = (inputDim + 2 * paddings - 1 + strides - kernel_size) / strides + 1
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to a param descriptor.
 *  @param[in] pool_mode
 *    Input. An enumerated type specifies the mode of how the pool is used to compute in the pooling
 *    ND operation. When used as pool 3d, supported values are: CNML_POOL_AVG and CNML_POOL_MAX,
 * used as pool 2d, support value same as pool 2d. You need to use the
 *    cnmlPoolMode_t datatype to declare the pool_mode value first. For more information about the
 *    supported values, see the cnmlPoolMode_t datatype.
 *  @param[in] strategy_mode
 *    Input. An enumerated type specifies whether the edge is used to compute in the pooling ND
 *    operation if the edge is shorter than a stride length. Supported values are: CNML_POOL_KFULL
 *    and CNML_POOL_KVALID. You need to use the nmlActiveFunction_t datatype to declare the
 * strategy_mode
 *    value first. For more information about the supported values, see the cnmlPoolStrategyMode_t
 * datatype.
 *  @param[in] array_length
 *    Input. An integer specifies the length of the data arrays for kenel_size, dilations, strides,
 *    and paddings. You need to set the array length in the order of kenel_size, dilations, strides,
 *    and paddings.
 *  @param[in] kernel_size
 *    Input. An integer array specifies all kernel sizes of the pooling ND operation. When using
 * this
 *    function for pool3d, the values need to be set in the d, h, w order, and for pool2d, order
 * should be h, w.
 *  @param[in] dilations
 *    Input. An integer array specifies all dilation of the pooling ND operation. The array values
 * must
 *    be greater than 0. This parameter is used to control the size of the kernel extension. The
 * kernel
 *    is extended to the size based on the forma: (kernel_size â€“ 1)*dilations + 1. When using this
 *    function for pool3d, the values need to be set in the d, h, w order, and for pool2d, order
 * should be h, w.
 *  @param[in] strides
 *    Input. An integer array specifies all the strides of the pooling ND operation. When using this
 *    function for pool3d, the values need to be set in d, h, w order, and for pool2d, order should
 * be h, w.
 *  @param[in] paddings
 *    Input. An integer array specifies all padding of the pooling ND operation. When using this
 * function
 *    for pool3d, the values need to be set in the d, h, w and front, behind, top, bottom, left,
 * right order, and for pool2d, order should be h, w and top, bottom, left, right.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The param pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdPoolOpParam(cnmlNdPoolOpParam_t *param,
                                                  cnmlPoolMode_t pool_mode,
                                                  cnmlPoolStrategyMode_t strategy_mode,
                                                  bool real,
                                                  int array_length,
                                                  int kernel_size[],
                                                  int dilations[],
                                                  int strides[],
                                                  int paddings[][2]);
/*!
 *  @brief A function.
 *
 *  Destroys a previously created pooling ND param, ndpool support pool3d and pool2d now.
 *
 *  **Only supports MLU270.**
 *
 *  @param[in] param
 *    Input. Pointer to the pooling ND param you want to destroy.
 *  @retval CNML_STATUS_SUCCESS
 *    The descriptor destroyed successfully.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNdPoolOpParam(cnmlNdPoolOpParam_t *param);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdPoolOpForward_V2 is recommended to use.
 *
 *  Creates a pooling ND op object by allocating the memory
 *  needed to hold the opaque structure of the op.
 *
 *  **Formula**
 *
 *    maxpool:
 *
 *      output[n, c, d, h, w] = max(input[n, c, d * sd + dd, h * sh + dh, w * sw + dw]),
 *      {0 <= dd <= wd, 0 <= dh < wh, 0 <= dw < ww}
 *
 *    avgpool:
 *
 *      output[n, c, d, h, w] = sum(input[n, c, d* sd + dd, h * sh + dh, w * sw + dw]) /
 *      (wd * wh * ww), {0 <= dd <= wd, 0 <= di < wh, 0 <= dj < ww}
 *
 *  OutputDim:
 *
 *    if strategy_mode is KVALID:
 *
 *      outputDim = 1 + (inputDim + 2 * paddings - kernel_size) / strides
 *
 *    else if strategy_mode if KFULL:
 *
 *      if poolingStride > poolingKernel:
 *
 *        outputDim = (inputDim - 1) / strides + 1
 *
 *      else:
 *
 *        outputDim = (inputDim + 2 * paddings - 1 + strides - kernel_size) / strides + 1
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the pooling ND operator you created.
 *  @param[in] param
 *    Input. A pointer to the params of this pooling ND op.
 *  @param[in] input
 *    Input. A pointer to tensor descriptor to do pooling ND op.
 *  @param[in] output
 *    Input. The descriptor of the output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions occurred:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdPoolOp(cnmlBaseOp_t *op,
                                             cnmlNdPoolOpParam_t param,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Creates a pooling ND op object by allocating the memory
 *  needed to hold the opaque structure of the op.
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the pooling ND operator you created.
 *  @param[in] param
 *    Input. A pointer to the params of this pooling ND op.
 *  @param[in] input_tensor
 *    Input. A pointer to tensor descriptor to do pooling ND op.
 *  @param[in] output_tensor
 *    Input. The descriptor of the output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions occurred:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.

 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdPoolOpForward(cnmlBaseOp_t *op,
                                                    cnmlNdPoolOpParam_t param,
                                                    cnmlTensor_t input_tensor,
                                                    cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdPoolOpForward_V2 is recommended to use.
 *
 *  Computes the pool operation on MLU.
 *
 *  **Formula**
 *
 *    maxpool:
 *
 *      output[n, c, d, h, w] = max(input[n, c, d * sd + dd, h * sh + dh, w * sw + dw]),
 *      {0 <= dd <= wd, 0 <= dh < wh, 0 <= dw < ww}
 *
 *    avgpool:
 *
 *      output[n, c, d, h, w] = sum(input[n, c, d* sd + dd, h * sh + dh, w * sw + dw]) /
 *      (wd * wh * ww), {0 <= dd <= wd, 0 <= di < wh, 0 <= dj < ww}
 *
 *  OutputDim:
 *
 *    if strategy_mode is KVALID:
 *
 *      outputDim = 1 + (inputDim + 2 * paddings - kernel_size) / strides
 *
 *    else if strategy_mode if KFULL:
 *
 *      if poolingStride > poolingKernel:
 *
 *        outputDim = (inputDim - 1) / strides + 1
 *
 *      else:
 *
 *        outputDim = (inputDim + 2 * paddings - 1 + strides - kernel_size) / strides + 1
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] output
 *    Output. A pointer to the output data after the pooling ND operator is applied.
 *  @param[in] op
 *    Input. A pointer to the pooling ND operator you have created.
 *  @param[in] input
 *    Input.  A pointer to the input data you want to compute.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address that records the data parallelism.
 *  @param[in] queue
 *    Input. A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *   This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions occurred:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdPoolOpForward(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing pool operator run on MLU.
 *
 *  After the pool operator, input, output, and computational queue are created, they are
 *  introduced into the function for operation.
 *
 *  **Supports only MLU270.**
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdPoolOpForward_V2(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* ndpool operation end */

/* active operation start */
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  This function creates an activation operator according to the basic operator pointer given by
 *  the user.
 *
 *  After a pointer to the base operator, activation operator, input and output tensor are created,
 *  they are introduced into the function to create the activation operator.
 *
 *  The operator implements activation operation, ``Out(i, j, k, l) = function ( In(i, j, k, l) )``
 * .
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Formula**
 *
 *    INVALID: out[n c h w] = in[n c h w];
 *
 *    SIGMOID: out[n c h w] = 1.0 / (1.0 + exp(0.0 - in[n c h w]));
 *
 *    TANH:
 *
 *      a = exp(in[n c h w]);
 *
 *      b = exp(0.0 - in[n c h w]);
 *
 *      out[n c h w] = (a - b) / (a + b);
 *
 *    RELU : out[n c h w] = (in[n c h w] <  0) ?  0 :   in[n c h w];
 *
 *    RELU1: out[n c h w] = (in[n c h w] < -1) ? -1 : ((in[n c h w] < 1) ? in[n c h w] : 1);
 *
 *    RELU6: out[n c h w] = (in[n c h w] <  0) ?  0 : ((in[n c h w] < 6) ? in[n c h w] : 6);
 *
 *    HARD_SIGMOID:
 *
 *      out[n c h w] = (in[n c h w] < -2.5) ? 0 : ((in[n c h w] < 2.5) ? (0.2 * in[n c h w] + 0.5) :
 * 1);
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     -input_data_type: int8, int16, float16, float32
 *
 *     -compute_data_type: float16, float32
 *
 *     -output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] function
 *     Input. An enumeration variable, the following can be selected:
 *     - `CNML_ACTIVE_NONE` represents identity.
 *     - `CNML_ACTIVE_SIGMOID`
 *     - `CNML_ACTIVE_RELU`
 *     - `CNML_ACTIVE_TANH`
 *     - `CNML_ACTIVE_RELU1`
 *     - `CNML_ACTIVE_RELU6`
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateActiveOp(cnmlBaseOp_t *op,
                                             cnmlActiveFunction_t active_func,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Computing the activation operator specified by the user on the MLU.
 *  Deprecated. This interface will be deleted in next version and cnmlComputeActiveOpForward_V4
 *  is recommended to use.
 *  After the activation operator, input, output and computational stream are created, they are
 *  introduced into the function to compute the activation operator.
 *
 *  **Formula**
 *
 *    INVALID: out[n c h w] = in[n c h w];
 *    SIGMOID: out[n c h w] = 1.0 / (1.0 + exp(0.0 - in[n c h w]));
 *    TANH:
 *      float a = exp(in[n c h w]);
 *      float b = exp(0.0 - in[n c h w]);
 *      out[n c h w] = (a - b) / (a + b);
 *    RELU : out[n c h w] = (in[n c h w] <  0) ?  0 :   in[n c h w];
 *    RELU1: out[n c h w] = (in[n c h w] < -1) ? -1 : ((in[n c h w] < 1) ? in[n c h w] : 1);
 *    RELU6: out[n c h w] = (in[n c h w] <  0) ?  0 : ((in[n c h w] < 6) ? in[n c h w] : 6);
 *    HARD_SIGMOID:
 *      out[n c h w] = (in[n c h w] < -2.5) ? 0 : ((in[n c h w] < 2.5) ? (0.2 * in[n c h w] + 0.5) :
 * 1);
 *
 *  DataType:
 *    MLU270:
 *     if RELU :
 *      input: int8, int16, float16, float32
 *      compute: float16, float32
 *      output: int8, int16, float16, float32
 *     else :
 *       input_dt = output_dt
 *       float16, float32
 *  Scale limitation:
 *    MLU270:
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] output
 *    Output. An MLU address that specifies the position of the output.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeActiveOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Computing the activation operator specified by the user on the MLU.
 *
 *  After the activation operator, input, output and computational queue are created, they are
 *  introduced into the function to compute the activation operator.
 *
 *  **Formula**
 *
 *    INVALID: out[n c h w] = in[n c h w];
 *
 *    SIGMOID: out[n c h w] = 1.0 / (1.0 + exp(0.0 - in[n c h w]));
 *
 *    TANH:
 *
 *       a = exp(in[n c h w]);
 *
 *       b = exp(0.0 - in[n c h w]);
 *
 *       out[n c h w] = (a - b) / (a + b);
 *
 *    RELU : out[n c h w] = (in[n c h w] <  0) ?  0 :   in[n c h w];
 *
 *    RELU1: out[n c h w] = (in[n c h w] < -1) ? -1 : ((in[n c h w] < 1) ? in[n c h w] : 1);
 *
 *    RELU6: out[n c h w] = (in[n c h w] <  0) ?  0 : ((in[n c h w] < 6) ? in[n c h w] : 6);
 *
 *    HARD_SIGMOID:
 *      out[n c h w] = (in[n c h w] < -2.5) ? 0 : ((in[n c h w] < 2.5) ? (0.2 * in[n c h w] + 0.5) :
 * 1);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      - input_data_type: int8, int16, float16, float32
 *
 *      - compute_data_type: float16, float32
 *
 *      - output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *    See "Error Codes" for more information.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeActiveOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* active operation end */

/* customized active operation start */
/*!
 *  @struct cnmlCustomizedActiveOpParam
 *  @brief A struct.
 *
 *  cnmlCustomizedActiveOpParam is a structure describing the param parameter of customize active
 *  operation, used to create customize active operation. cnmlCreateCustomizedActiveOpParam() is
 *  used to create an instance of cnmlCustomizedActiveOpParam_t.
 *  cnmlDestroyCustomizedActiveOpParam() is
 *  used to destroy an instance of cnmlCustomizedActiveOpParam_t. */
struct cnmlCustomizedActiveOpParam;
/*! ``cnmlCustomizedActiveOpParam_t`` is a pointer to ``cnmlCustomizedActiveOpParam`` which is a
    structure holding the description of a customized active operation param. */
typedef struct cnmlCustomizedActiveOpParam *cnmlCustomizedActiveOpParam_t;

/*!
 *  @brief A function.
 *
 *  This function fills in the cnmlCustomizedActiveOpParam_t struct with the operation parameters
 *  input by the user and returns it to the user.
 *
 *  This function allocates param memory. After the usage is completed, the user needs to call
 *  cnmlDestroycnmlCustomizedActiveOpParam to destroy the param parameter at the appropriate time.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of the convolution operator operation
 *  parameter.
 *  @param[in] x_start
 *    Input. The range of independent variables of activation function.
 *  @param[in] x_end
 *    Input. The range of independent variables of activation function.
 *  @param[in] y_min
 *    Input. The infimum of activation function within the effective range (x_start, y_start).
 *  @param[in] segment_num
 *    Input. The number of segment of the activation function. When implemented, piecewise linear
 *  interpolation is used to approximate the activation function.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCustomizedActiveOpParam(cnmlCustomizedActiveOpParam_t *param,
                                                            float x_start,
                                                            float x_end,
                                                            float y_min,
                                                            int segment_num);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the Active operator operation
 *  parameter is freed.
 *
 *  After the operation of the customized active operator is completed, the struct pointer of the
 *  Active operator
 *  operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the Active operator operation parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyCustomizedActiveOpParam(cnmlCustomizedActiveOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  This function creates a CustomizedActive operator according to the basic Operator pointer given
 *  by the user.
 *
 *  After the pointer pointing to the base operator, the CustomizedActive operator operation
 *  parameter and the input-output tensor are created, they are introduced into the function to
 *  create the CustomizedActive operator.
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] input
 *    Input. A 1 to n-dimensional tensor, supporting data of float16 type.
 *  @param[in] output
 *    Input. A 1 to n-dimensional tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCustomizedActiveOp(cnmlBaseOp_t *op,
                                                       void *active_func,
                                                       cnmlCustomizedActiveOpParam_t param,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCustomizedActiveForward_V4 is recommended to use.
 *
 *  Computing the CustomizedActive operator specified by the user on MLU.
 *
 *  After the CustomizedActive operators, input, output, parameter at runtime, and computational
 *  queue are created, they are introduced into the function to compute CustomizedActive operators.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeCustomizedActiveForward_V3(cnmlBaseOp_t op,
                                      void *input,
                                      void *output,
                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                      cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Computing the CustomizedActive operator specified by the user on MLU.
 *
 *  After the CustomizedActive operators, input, output, parameter at runtime, and computational
 *  queue are created, they are introduced into the function to compute CustomizedActive operators.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCustomizedActiveForward_V4(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);
/* customized active operation end */

/* device memcpy operation start */
/*!
 *  @brief A function.
 *
 *  According to the basic Operator pointer given by the user, a DeviceMemcpy operator is created.
 *
 *  After a pointer pointing to the address of the base operator and an input-output tensor are
 *  created, they are introduced into the function to create the DeviceMemcpy operator.
 *
 *  **Summary**
 *
 *  Copy a tensor to another tensor.
 *
 *  DataType:
 *
 *    MLU270:
 *
 *      input output data and their onchip datatype should be the same, the data type is not limited
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor, the shape is [n, h, w, c],supporting data of float16
 *  type.
 *  @param[in] output
 *    Input. A 4-dimensional MLU weight tensor, the shape is [n, h, w, c],supporting data of float16
 *  type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDeviceMemcpyOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Computing DeviceMemcpy operators specified by users on MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeDeviceMemcpyOpForward_V4 is recommended to use.
 *
 *  After the Mult operator, input, output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute DeviceMemcpy operators.
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeDeviceMemcpyOpForward_V3(cnmlBaseOp_t op,
                                    void *input,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing DeviceMemcpy operators specified by users on MLU.
 *
 *  After the Mult operator, input, output, parameter at runtime, and computational queue are
 *  created, they are introduced into the function to compute DeviceMemcpy operators.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDeviceMemcpyOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* active operation end */

/* transpose pro operation start */
/*!
 *  @struct cnmlTransposeOpParam
 *  @brief A struct.
 *
 *  cnmlTransposeOpParam is a structure describing the param parameter of transpose operation, used
 *  to create transpose operation. cnmlCreateTransposeOpParam() is used to create an instance of
 *  cnmlTransposeOpParam_t. cnmlDestroyTransposeOpParam() is used to destroy an instance of
 *  cnmlTransposeOpParam_t. */
struct cnmlTransposeOpParam;
/*! ``cnmlTransposeOpParam_t`` is a pointer to ``cnmlTransposeOpParam`` which is a
    structure holding the description of a transpose operation param. */
typedef struct cnmlTransposeOpParam *cnmlTransposeOpParam_t;

/*!
 *  @brief A function.
 *
 *  This function fills in the cnmlTransposeOpParam_t struct with the Transpose operation parameters
 *  input by users and returns them to the user.
 *
 *  This function allocates param memory. After the usage is completed, the user needs to call
 *  cnmlDestroyTransposeOpParam to destroy the param parameter at the appropriate time.
 *
 *  The corresponding input_order of cpuDataOrder is 0123 regardless of the arrangement order.
 *  dimId0 - dimId3 is a rearrangement of input_order, for example, input_order is NCHW (0123)
 *  actually, dimId0 - dimId3 is 3210 in turn, the actual user_output_order is WHCN(3210). If
 *  input_order is actually NHWC (0123), then the user_output_order should be CWHN (3210).
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of struct of the Transpose operator operation parameter.
 *  @param[in] cpu_data_order
 *    Input. The data of cnmlTransposeOpParam_t type. There are 24 possible arrangement orders of
 *  the four dimensions, such as NCHW, while currently only NCHW and NHWC are supported by
 *  transpose_pro operator.
 *  @param[in] dim_id_0
 *    Input. The dimension of input_order corresponding to the zeroth dimension of
 *  user_output_order.
 *  @param[in] dim_id_1
 *    Input. The dimension of input_order corresponding to the first dimension of user_output_order.
 *  @param[in] dim_id_2
 *    Input. The dimension of input_order corresponding to the second dimension of
 *  user_output_order.
 *  @param[in] dim_id_3
 *    Input. The dimension of input_order corresponding to the third dimension of user_output_order.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTransposeOpParam(cnmlTransposeOpParam_t *param,
                                                     cnmlDataOrder_t data_order,
                                                     int dim_id_0,
                                                     int dim_id_1,
                                                     int dim_id_2,
                                                     int dim_id_3);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the Transpose operator
 *  operation parameter is freed.
 *
 *  After the operation of the transpose operator is completed, the created struct pointer of the
 *  Transpose operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the Transpose operator operation
 *  parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyTransposeOpParam(cnmlTransposeOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  This function creates a TransposePro operator based on the basic Operator pointer given by the
 *  user.
 *
 *  After a pointer pointing to the base operator, the TransposePro operator operation parameter and
 *  the input-output tensor are created, they are introduced into the function to create the
 *  TransposePro operator.
 *
 *  **Formula**
 *
 *    output[n,h,w,c] = input[n,h,w,c]
 *
 *    output[n,w,h,c] = input[n,h,w,c]
 *
 *    output[h,n,w,c] = input[n,h,w,c]
 *
 *    output[h,w,n,c] = input[n,h,w,c]
 *
 *    output[w,n,h,c] = input[n,h,w,c]
 *
 *    output[w,h,n,c] = input[n,h,w,c]
 *
 *    output[n,h,c,w] = input[n,h,w,c]
 *
 *    output[n,c,h,w] = input[n,h,w,c]
 *
 *    output[h,n,c,w] = input[n,h,w,c]
 *
 *    output[h,c,n,w] = input[n,h,w,c]
 *
 *    output[c,n,h,w] = input[n,h,w,c]
 *
 *    output[c,h,n,w] = input[n,h,w,c]
 *
 *    output[n,w,c,h] = input[n,h,w,c]
 *
 *    output[n,c,w,h] = input[n,h,w,c]
 *
 *    output[w,n,c,h] = input[n,h,w,c]
 *
 *    output[w,c,n,h] = input[n,h,w,c]
 *
 *    output[c,n,w,h] = input[n,h,w,c]
 *
 *    output[c,w,n,h] = input[n,h,w,c]
 *
 *    output[h,w,c,n] = input[n,h,w,c]
 *
 *    output[h,c,w,n] = input[n,h,w,c]
 *
 *    output[w,h,c,n] = input[n,h,w,c]
 *
 *    output[w,c,h,n] = input[n,h,w,c]
 *
 *    output[c,h,w,n] = input[n,h,w,c]
 *
 *    output[c,w,n,h] = input[n,h,w,c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int8, int16, int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] input
 *    Input. A 4-dimensional input tensor with the shape of [ni,ci,hi,wi],supporting data of float16
 *  type.
 *  @param[in] output
 *    Input. A 4-dimensional output tensor,the shape is [no,co,ho,wo](after transposition, one
 *  dimension of the output data should be the same size as the dimension of corresponding input
 *  data) ,supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Input pointer is null.
 *    - Output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTransposeProOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor,
                                                   cnmlTransposeOpParam_t param);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeTransposeProOpForward_V4 is recommended to use.
 *
 *  Computing user-specified TransposePro operators on MLU.
 *
 *  After the TransposePro operator, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute the TransposePro operator.
 *
 *  **Formula**
 *
 *    output[n,h,w,c] = input[n,h,w,c]
 *
 *    output[n,w,h,c] = input[n,h,w,c]
 *
 *    output[h,n,w,c] = input[n,h,w,c]
 *
 *    output[h,w,n,c] = input[n,h,w,c]
 *
 *    output[w,n,h,c] = input[n,h,w,c]
 *
 *    output[w,h,n,c] = input[n,h,w,c]
 *
 *    output[n,h,c,w] = input[n,h,w,c]
 *
 *    output[n,c,h,w] = input[n,h,w,c]
 *
 *    output[h,n,c,w] = input[n,h,w,c]
 *
 *    output[h,c,n,w] = input[n,h,w,c]
 *
 *    output[c,n,h,w] = input[n,h,w,c]
 *
 *    output[c,h,n,w] = input[n,h,w,c]
 *
 *    output[n,w,c,h] = input[n,h,w,c]
 *
 *    output[n,c,w,h] = input[n,h,w,c]
 *
 *    output[w,n,c,h] = input[n,h,w,c]
 *
 *    output[w,c,n,h] = input[n,h,w,c]
 *
 *    output[c,n,w,h] = input[n,h,w,c]
 *
 *    output[c,w,n,h] = input[n,h,w,c]
 *
 *    output[h,w,c,n] = input[n,h,w,c]
 *
 *    output[h,c,w,n] = input[n,h,w,c]
 *
 *    output[w,h,c,n] = input[n,h,w,c]
 *
 *    output[w,c,h,n] = input[n,h,w,c]
 *
 *    output[c,h,w,n] = input[n,h,w,c]
 *
 *    output[c,w,n,h] = input[n,h,w,c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int8, int16, int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to the output position.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeTransposeProOpForward_V3(cnmlBaseOp_t op,
                                    void *input,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing user-specified TransposePro operators on MLU.
 *
 *  After the TransposePro operator, input, output, parameter at runtime, and computational queue
 *  are created, they are introduced into the function to compute the TransposePro operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeTransposeProOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* transpose pro operation end */

/* transpose pro nd operation start */
/*!
 *  @struct cnmlNdTransposeOpParam
 *  @brief A struct.
 *
 *  cnmlNdTransposeOpParam is a structure describing the param parameter of transpose nd operation,
 *  used to create transpose nd operation. cnmlCreateNdTransposeOpParam() is used to create an
 *  instance of cnmlNdTransposeOpParam_t. cnmlDestroyNdTransposeOpParam() is used to destroy an
 *  instance of cnmlNdTransposeOpParam_t. */
struct cnmlNdTransposeOpParam;
/*! ``cnmlNdTransposeOpParam_t`` is a pointer to ``cnmlNdTransposeOpParam`` which is a
    structure holding the description of a transpose nd operation param. */
typedef struct cnmlNdTransposeOpParam *cnmlNdTransposeOpParam_t;

/*!
 *  @brief A function.
 *
 *  This function fills in the cnmlNdTransposeOpParam_t struct with the Transpose multi-dimension
 *  operation parameters input by users and returns them to the user.
 *
 *  This function allocates param memory. After the usage is completed, the user needs to call
 *  cnmlDestroyNdTransposeOpParam to destroy the param parameter at the appropriate time.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of struct of the NdTranspose operator operation parameter.
 *  @param[in] dim_order[]
 *    Input. The dimensions of input_order corresponding to the user_output_order.
 *  @param[in] dim_num
 *    Input. The number of dim_order, equal to the number of input tensor and output tensor
 *  dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdTransposeOpParam(cnmlNdTransposeOpParam_t *param,
                                                       int dim_order[],
                                                       int dim_num);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of the Transpose multi-dimension
 *  operator operation parameter is freed.
 *
 *  After the operation of the nd transpose operator is completed, the created struct pointer of the
 *  nd transpose operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the NdTranspose operator operation
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNdTransposeOpParam(cnmlNdTransposeOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create a Transpose operator supporting multi-dimension according to base operator pointers given
 *  by users.
 *
 *  This operator extens to support multi-dimension based on the Transpose operator.
 *
 *  After creating a pointer pointing to base operator address, dimension of transpose operation,
 *  and input and output Tensor, pass them into the fucntion to create a transpose operator
 *  supporting multi-dimension.
 *
 *  Before creating a transpose operator, declare a pointer pointing to the struct address of
 *  operation parameters of the operator, and pass the pointer and operator parameters required into
 *  the function to set operator parameters.
 *
 *  Compute the tensor position along the dimension that users will trans.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A multi-dimensional MLU input tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of the NdTranspose operator param.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdTransposeProOp(cnmlBaseOp_t *op,
                                                     cnmlTensor_t input_tensor,
                                                     cnmlTensor_t output_tensor,
                                                     cnmlNdTransposeOpParam_t param);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdTransposeProOpForward_V2 is recommended to use.
 *
 *  Compute the transpose operator supporting multi-dimension on the MLU.
 *
 *  After creating a transpose operator supporting multi-dimension, input, output, and computation
 *  queue, pass them into the function to compute the transpose operator supporting
 *  multi-dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeNdTransposeProOpForward(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the transpose operator supporting multi-dimension on the MLU.
 *
 *  After creating a transpose operator supporting multi-dimension, input, output, and computation
 *  queue, pass them into the function to compute the transpose operator supporting
 *  multi-dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdTransposeProOpForward_V2(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);
/* transpose pro nd operation end */

/* mlp operation start */
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateMlpOpForward is recommended to use.
 *
 *  According to the basic operator pointer given by the use, this function creates a Multiple-layer
 *  perceptron operator.
 *
 *  After the pointer pointing to the base operator, the sparse mode of MLP operator and the
 *  input-output tensor are created, they are introduced into the function to create the MLP
 *  operator.
 *
 *  **Summary**
 *
 *  Assuming input, weight, and output are arranged in NCHW order, output[n, coo, 1, 1] =
 *  âˆ‘input[n,cii, h, w] * filter[coo, cii, h, w]
 *
 *  the sum of subscripts cii, h and W is carried out, and the
 *  summation range is [0, ci - 1],[0, hi - 1],[0, wi - 1], if the bias tensor is not null, the
 *  final output should add bias.
 *
 *  **DataType**
 *
 *    MLU270:
 *        input_type : Data type of the input tensor.
 *
 *        filter_type : Data type of the filter tensor.
 *
 *        bias_type : Data type of the bias tensor.
 *
 *        output_type : Data type of the output tensor.
 *
 *        in_oc_type : Data type of the input tensor used for computing.
 *
 *        filter_oc_type : Data type of the filter tensor used for computing.
 *
 *        bias_oc_type : Data type of the bias tensor used for computing.
 *
 *        output_oc_type : Data type of the output tensor used for computing.
 *
 *        If filter_type is int8, then input_type can be int8 or int16, and output_type can be
 *        float16,
 *        float32, or int16.
 *
 *        If filter_type is int16, then input_type can be int16, and output_type can be float16,
 *        float32, or int16.
 *
 *        **Notes:** The data type you set in bias_oc_type, bias_type, and out_oc_type must be the
 *        same.
 *
 *        The supported combinations of the data type of the tensors are as follows. The data type
 *        are shown in the following order:
 *
 *        input_type - input_oc_type - filte_type - filte_oc_type - output_oc__type - output_type
 *
 *         int8-int8-int8-int8-float16-float16;
 *
 *         int8-int8-int8-int8-float16-int8;
 *
 *         int8-int8-int8-int8-float32-float32;
 *
 *         int8-int8-int8-int8-float32-int8;
 *
 *         float16-int8-int8-int8-float16-float16;
 *
 *         float16-int8-int8-int8-float16-int8;
 *
 *         float32-int8-int8-int8-float32-float32;
 *
 *         float32-int8-int8-int8-float32-int8;
 *
 *         int16-int16-int8-int8-float16-float16;
 *
 *         int16-int16-int8-int8-float16-int16;
 *
 *         int16-int16-int8-int8-float32-float32;
 *
 *         int16-int16-int8-int8-float32-int16;
 *
 *         float16-int16-int8-int8-float16-float16;
 *
 *         float16-int16-int8-int8-float16-int16;
 *
 *         float32-int16-int8-int8-float32-float32;
 *
 *         float32-int16-int8-int8-float32-int16;
 *
 *         int16-int16-int16-int16-float16-float16;
 *
 *         int16-int16-int16-int16-float16-int16;
 *
 *         int16-int16-int16-int16-float32-float32;
 *
 *         int16-int16-int16-int16-float32-int16;
 *
 *         float16-int16-int16-int16-float16-float16;
 *
 *         float16-int16-int16-int16-float16-int16;
 *
 *         float32-int16-int16-int16-float32-float32;
 *
 *         float32-int16-int16-int16-float32-int16;
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *   For best practice, we suggest you call the cnmlComputeReshapeOpForward_V4() API to reshape the
 * tensor, if you set the input tensor with the following:
 *
 *   - The size of ci dimension is less than 64.
 *   - The size of h dimension of the input tensor is greater than 200.
 *   - The size of w dimension is greater than 200.
 *
 *   Also, when you set the output tensor of the cnmlComputeReshapeOpForward_V4() call, the size of
 *   h and w dimensions should be less than or equal to 200 and the value of ci dimension should be
 *   greater or equal to 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator
 *  @param[in] input_tensor
 *    Input. A 4-dimensional input tensor with the shape of [ni, ci, hi, wi],supporting data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional output tensor,the shape is [no, co, ho, wo] (no = ni, co = nf, ho = 1,
 *  wo = 1),supporting data of float16 type.
 *  @param[in] filter_tensor
 *    Input. A 4-dimensional weight tensor with the shape of   [nf, cf, hf, wf] (nf = co, cf = ci,
 *  hf = hi, wf = wi),supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A 4-dimensional bias tensor with the shape of [nb, cb, hb, wb] (nb = 1, cb = co, hb =
 *  1, wb = 1),supporting data of float16 type.
 *    selected.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMlpOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor,
                                          cnmlTensor_t filter_tensor,
                                          cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMlpOpForward_V4 is recommended to use.
 *
 *  Computing the MLP operator specified by the user on MLU.
 *
 *  After the MLP operator, input, output and computational stream are created, they are introduced
 *  into the function to compute the MLP operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that specifies the position of the output.
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the address of the struct, which records the degree of data
 *  parallelism and device affinity at runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMlpOpForward_V3(cnmlBaseOp_t op,
                                                     void *inputs,
                                                     void *outputs,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computing the MLP operator specified by the user on MLU.
 *
 *  After the MLP operator, input, output and computational stream are created, they are introduced
 *  into the function to compute the MLP operator.
 *
 *  **Summary**
 *
 *  Assuming input, weight, and output are arranged in NCHW order, output[n, coo, 1, 1] =
 *  âˆ‘input[n,cii, h, w] * filter[coo, cii, h, w]
 *
 *  the sum of subscripts cii, h and W is carried out, and the
 *  summation range is [0, ci - 1],[0, hi - 1],[0, wi - 1], if the bias tensor is not null, the
 *  final output should add bias.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     input_type : Data type of the input tensor.
 *
 *     filter_type : Data type of the filter tensor.
 *
 *     bias_type : Data type of the bias tensor.
 *
 *     output_type : Data type of the output tensor.
 *
 *     in_oc_type : Data type of the input tensor used for computing.
 *
 *     filter_oc_type : Data type of the filter tensor used for computing.
 *
 *     bias_oc_type : Data type of the bias tensor used for computing.
 *
 *     output_oc_type : Data type of the output tensor used for computing.
 *
 *     If filter_type is int8, then input_type can be int8 or int16, and output_type can be
 *     float16,
 *     float32, or int16.
 *
 *     If filter_type is int16, then input_type can be int16, and output_type can be float16,
 *     float32, or int16.
 *
 *     **Notes:** The data type you set in bias_oc_type, bias_type, and out_oc_type must be the
 *     same.
 *
 *     The supported combinations of the data type of the tensors are as follows. The data type
 *     are shown in the following order:
 *
 *     input_type - input_oc_type - filte_type - filte_oc_type - output_oc__type - output_type
 *
 *      int8-int8-int8-int8-float16-float16;
 *
 *      int8-int8-int8-int8-float16-int8;
 *
 *      int8-int8-int8-int8-float32-float32;
 *
 *      int8-int8-int8-int8-float32-int8;
 *
 *      float16-int8-int8-int8-float16-float16;
 *
 *      float16-int8-int8-int8-float16-int8;
 *
 *      float32-int8-int8-int8-float32-float32;
 *
 *      float32-int8-int8-int8-float32-int8;
 *
 *      int16-int16-int8-int8-float16-float16;
 *
 *      int16-int16-int8-int8-float16-int16;
 *
 *      int16-int16-int8-int8-float32-float32;
 *
 *      int16-int16-int8-int8-float32-int16;
 *
 *      float16-int16-int8-int8-float16-float16;
 *
 *      float16-int16-int8-int8-float16-int16;
 *
 *      float32-int16-int8-int8-float32-float32;
 *
 *      float32-int16-int8-int8-float32-int16;
 *
 *      int16-int16-int16-int16-float16-float16;
 *
 *      int16-int16-int16-int16-float16-int16;
 *
 *      int16-int16-int16-int16-float32-float32;
 *
 *      int16-int16-int16-int16-float32-int16;
 *
 *      float16-int16-int16-int16-float16-float16;
 *
 *      float16-int16-int16-int16-float16-int16;
 *
 *      float32-int16-int16-int16-float32-float32;
 *
 *      float32-int16-int16-int16-float32-int16;
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      kh <= hi，kw <= wi
 *
 *    where ``kh`` is the height of the kernel, ``hi`` is the height of the input tensor,
 *    ``kw`` is width of the kernel, and ``wi`` is the width of the input tensor.
 *
 *  **Performance Optimization**
 *
 *   For best practice, we suggest you call the cnmlComputeReshapeOpForward_V4() API to reshape the
 * tensor, if you set the input tensor with the following:
 *
 *   - The size of ci dimension is less than 64.
 *   - The size of h dimension of the input tensor is greater than 200.
 *   - The size of w dimension is greater than 200.
 *
 *   Also, when you set the output tensor of the cnmlComputeReshapeOpForward_V4() call, the size of
 *   h and w dimensions should be less than or equal to 200 and the value of ci dimension should be
 *   greater or equal to 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMlpOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);

/*!
 *  @brief A function.
 *
 *  According to the MLP operator given by the user, the 8-bit quantization mode is turned on.
 *
 *  After the MLP operator is created, this function is called to set the operation mode to binary
 *  mode.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to the base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlEnableMlpOpBinaryMode(cnmlBaseOp_t op);
/* mlp operation end */

/* matrix_mult operation start */
/*!
 *  @brief A function.
 *
 *  The function creates a matrix multiplication operator according to base operator pointers given
 *  by users.
 *
 *  After creating base operator pointers, matrix multiplication operator input tensor, weight
 *  tensor, output tensor, and bias Tensor, pass them into the function to create matrix
 *  multiplication operators.
 *
 *  If the order of input, weight, and output is NCHW, output [n, coo, 1, 1] = âˆ‘input[n, cii, h,
 *  w]
 *  * filter[coo, cii, h, w] and sum the subscripts cii, h, and W. The sum range is [0, cl-1], [0,
 *  hl-1], and [0, wl-1] respectively. If the bias tensor is not null, bias is added to the final
 *  output.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer which points to the base operator address.
 *  @param[in] lhs_tensor
 *    Input. A four-dimensional input tensor, the shape of which is [nl, cl, hl, wl], supporting
 *  data of float16 type.
 *  @param[in] rhs_tensor
 *    Input. A four-dimensional weight tensor, the shape of which is [nr, cr, hr, wr] (cr = cl, hr =
 *  hl, wr = wl), supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional output tensor, the shape of which is [no, co, ho, wo] (no = nl, co =
 *  nr, ho = 1, wo = 1), supporting data of float16 type.
 *  @param[in] bias_tensor
 *    Input. A four-dimensional bias tensor, the shape of which is [nb, cb, hb, wb] (nb = 1, cb =
 *  co, hb = 1, wb = 1), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMatrixMultOp(cnmlBaseOp_t *op,
                                                 cnmlTensor_t lhs_tensor,
                                                 cnmlTensor_t rhs_tensor,
                                                 cnmlTensor_t output_tensor,
                                                 cnmlTensor_t bias_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMatrixMultOpForward_V4 is recommended to use.
 *
 *  Compute the matrix multiplication operator specified by users on the MLU.
 *
 *  After creating matrix multiplication operators, input, output, and computation stream, pass them
 *  into the function to compute the matrix multiplication operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address specifying the output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] lhs
 *    Input. An MLU address which points to input data.
 *  @param[in] rhs
 *    Input. An MLU address which points to input weight data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeMatrixMultOpForward_V3(cnmlBaseOp_t op,
                                  void *lhs,
                                  void *rhs,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the matrix multiplication operator specified by users on the MLU.
 *
 *  After creating matrix multiplication operators, input, output, and computation queue, pass them
 *  into the function to compute the matrix multiplication operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] lhs_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] lhs
 *    Input. MLU address pointing to lhs data.
 *  @param[in] rhs_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] rhs
 *    Input. MLU address pointing to rhs data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMatrixMultOpForward_V4(cnmlBaseOp_t op,
                                                            cnmlTensor_t lhs_tensor,
                                                            void *lhs,
                                                            cnmlTensor_t rhs_tensor,
                                                            void *rhs,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);
/* matrix_mult operation end */

/* gatherv2 operation start */
/*!
 *  @brief A function.
 *
 *  The function creates a GatherV2 operator according to the base operator pointer given by users.
 *
 *  After creating a pointer pointing to base operators, the GatherV2 operator input tensor, index
 *  tensor, and output Tensor, pass them into the function to create the GatherV2 operator.
 *
 *  Obtain slices of input on a specified dimension according to the index,.Taking axis = CNML_DIM_N
 *  as an example, output[n, h, w, c] = input[index[n], h, w, c].
 *
 *  On the dimensions specified by axis, the shape of index is the same as that of output. On other
 *  dimensions, all the shape of index is 1, and the shape of output is the same as that of input.
 *  Taking axis = CNML_DIM_N as an example, the input shape is [ni, hi, wi, ci], the valid shape of
 *  index is [no, 1, 1, 1], and the valid shape of output is [no, hi, wi, ci].
 *
 *  **Formula**
 *
 *    if index[i] != -1:
 *
 *      dim==N:out[i][c][h][w]=input[index[i]][c][h][w]
 *
 *      dim==H:out[n][c][i][w]=input[n][c][index[i]][w]
 *
 *      dim==W:out[n][c][h][i]=input[n][c][h][index[i]]
 *
 *    if index[i] == -1:
 *
 *      dim==N:out[i][c][h][w]=0
 *
 *      dim==H:out[n][c][i][w]=0
 *
 *      dim==W:out[n][c][h][i]=0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_dt == output_dt
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] indexTensor
 *    Input. A four-dimensional index tensor, [n_index, h_index, w_index, c_index], only supporting
 *  data of uint32 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional output tensor, the shape of which is [no, co, ho, wo] (no = nl, co =
 *  nr, ho = 1, wo = 1), supporting data of float16 type.
 *  @param[in] axies
 *    Input. An enumeration variable of cnmlDimension_t, type can be one of CNML_DIM_N, CNML_DIM_C,
 *  CNML_DIM_H, and CNML_DIM_W.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGatherV2Op(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t index_tensor,
                                               cnmlTensor_t output_tensor,
                                               cnmlDimension_t dim);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGatherV2OpForward_V4 is recommended to use.
 *
 *  Compute the GatherV2 operator specified by users on the MLU.
 *
 *  After creating the GatherV2 operators, input, output, and computation stream, pass them into the
 *  function to compute the GatherV2 operator.
 *
 *  **Formula**
 *
 *    if index[i] != -1:
 *
 *      dim==N:out[i][c][h][w]=input[index[i]][c][h][w]
 *
 *      dim==H:out[n][c][i][w]=input[n][c][index[i]][w]
 *
 *      dim==W:out[n][c][h][i]=input[n][c][h][index[i]]
 *
 *    if index[i] == -1:
 *
 *      dim==N:out[i][c][h][w]=0
 *
 *      dim==H:out[n][c][i][w]=0
 *
 *      dim==W:out[n][c][h][i]=0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_dt == output_dt
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address specifying the output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] index
 *    Input. An MLU address pointing to index input data.
 *  @param[in] param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGatherV2OpForward_V3(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *index,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the GatherV2 operator specified by users on the MLU.
 *
 *  After creating the GatherV2 operators, input, output, and computation queue, pass them into the
 *  function to compute the GatherV2 operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] index_tensor
 *    Input. Index MLU tensor pointer. Pass NULL if not used.
 *  @param[in] index
 *    Input. MLU address pointing to index data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGatherV2OpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t index_tensor,
                                                          void *index,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* gatherv2 operation end */

/* batchdot operation start */
/*!
 *  @brief A function.
 *
 *  The function creates a BatchDot operator according to the base operator pointer given by users.
 *
 *  After creating a pointer pointing to base operators, matrix multiplication operator input tensor
 *  and output tensor, pass them into the function to create the BatchDot operator.
 *
 *  Realize dot product operation in batches.
 *
 *  the shape of input1 as(n,c1,h1,w1) and the shape of input2 as(n,c2,h2,w2),
 *
 *  set m = c1, p = h1 * w1, q = h2 * w2;
 *
 *  set the shape of input1 as(n,m,p,1)
 *
 *  set the shape of input2 as(n,p,q,1)
 *
 *  The output shape is output(n,m,p,1)
 *
 *  Compute Output:
 *
 *  output(n,m,p,q) = $\sum_{l}$input1(n,m,l,1) * input2(n,l,q,1)
 *
 *  If trans_a = true, transpose input1 in batches at first and then perform
 *  multiplication:input1(n,m,p,1)-> input1(n,p,m,1)
 *
 *  If trans_b = true, transpose input2 in batches at first and then perform
 *  multiplication:input2(n,p,q,1)-> input1(n,q,p,1)
 *
 *  Set the shape of two inputs as shape1 and shape2, and the output shape is: output (no,co,ho,wo).
 *
 *  shape1.h * shape1.w = shape2.c
 *
 *  shape1.n = shape2.n
 *
 *  Set p = shape1.w * shape1.h q =shape2.w * shape2.h
 *
 *  then no = shape1.n
 *
 *  co = trans_a ? p : shape1.c
 *
 *  ho = trans_b ? q : shape2.h
 *
 *  wo = 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor1
 *    Input. A four-dimensional input tensor, the shape of which is [n1, c1, h1,w1], supporting data
 *  of float16 type.
 *  @param[in] input_tensor2
 *    Input. A four-dimensional input tensor, the shape of which is [n2, c2, h2, w2](n2 = n1) ,
 *  supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional output tensor, the shape of which is [no, co, ho, wo] (no = n1),
 *  supporting data of float16 type.
 *  @param[in] trans_a
 *    Input. input_tensor1 transposing options, supporting input of bool type.
 *  @param[in] trans_b
 *    Input. input_tensor2 transposing options, supporting input of bool type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBatchDotOp(cnmlBaseOp_t *op,
                                               const cnmlTensor_t input_tensor_1,
                                               const cnmlTensor_t input_tensor_2,
                                               const cnmlTensor_t output_tensor,
                                               bool trans_a,
                                               bool trans_b);

/*!
 *  @brief A function.
 *
 *  Compute the BatchDot operator specified by users on the MLU.
 *
 *  After creating the BatchDot operator, Input. output, and computation stream, pass them into the
 *  function to compute the BatchDot operator.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeBatchDotOpForward_V4
 *  is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address specifying the output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] inputA
 *    Input. An MLU address which points to input data.
 *  @param[in] inputB
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBatchDotOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the BatchDot operator specified by users on the MLU.
 *
 *  After creating the BatchDot operator, Input. output, and computation queue, pass them into the
 *  function to compute the BatchDot operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBatchDotOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* batchdot operation end*/

/* add operation start */
/*!
 *  @brief A function.
 *
 *  Create an add operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the add operator, pass them into the function to create the add operator.
 *
 *  Before creating the add operator, declare a pointer pointing to the struct address of operation
 *  parameters of the add operator, and pass the pointer and operator parameters required into the
 *  function to set operator parameters.
 *
 *  Perform element-wise summation on the two inputs to obtain output.
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] + b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAddOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor_1,
                                          cnmlTensor_t input_tensor_2,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the add operator specified by users on the MLU.
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAddOpForward_V4
 *  is recommended to use.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the add operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] + b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAddOpForward_V3(cnmlBaseOp_t op,
                                                     void *input_1,
                                                     void *input_2,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the add operator specified by users on the MLU.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the add operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] + b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor_2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAddOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor1,
                                                     void *input_1,
                                                     cnmlTensor_t input_tensor2,
                                                     void *input_2,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* add operation end */
/* max_equal begin */
/*!
 *  @brief A function.
 *
 *  Create an maxequal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the maxequal operator, pass them into the function to create the maxequal
 * operator.
 *
 *  Before creating the maxequal operator, declare a pointer pointing to the struct address of
 *  operation parameters of the maxequal operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  output will be the max value of two input with same index, if two vaule eqaul both
 *  if the value of input1 >= input2 then output will be input1 ,else input2.
 *
 *  output[n, c,  h, w] = input1[n, c, h, w] >= input2[n, c, h, w] ? input1 : input2
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] >= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Suports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, hi, wi, ci], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU output tensor, the shape of which is [ni, hi, wi, ci],
 *  supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co] (no = ni,
 *  co = ci, ho = hi, wi = wo), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMaxEqualOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMaxEqualOpForward_V4 is recommended to use.
 *
 *  Compute the maxequal operator specified by users on the MLU.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the maxequal operator.
 *
 *  **Formula**
 *
 *     output[n, c,  h, w] = input1[n, c, h, w] >= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaxEqualOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the maxequal operator specified by users on the MLU.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the maxequal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] >= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.

 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaxEqualOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* max_equal operation end */
/* min_equal begin */
/*!
 *  @brief A function.
 *
 *  Create an minequal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the minequal operator, pass them into the function to create the minequal
 * operator.
 *
 *  Before creating the minequal operator, declare a pointer pointing to the struct address of
 * operation
 *  parameters of the minequal operator, and pass the pointer and operator parameters required into
 *  the function to set operator parameters.
 *
 *  output will be the min value of two input with same index, if two vaule equal will be the equal
 * value
 *  if the value of input1 <= input2 then output will be input1 ,else input2.
 *
 *  output[n, c,  h, w] = input1[n, c, h, w] <= input2[n, c, h, w] ? input1 : input2
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] <= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, hi, wi, ci], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU output tensor, the shape of which is [ni, hi, wi, ci],
 *  supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co] (no = ni,
 *  co = ci, ho = hi, wi = wo), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMinEqualOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMinEqualOpForward_V4 is recommended to use.
 *
 *  Compute the minequal operator specified by users on the MLU.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the minequal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] <= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinEqualOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the minequal operator specified by users on the MLU.
 *
 *  After creating adivision operator, input, output, runtime parameters, and computation queues,
 *  pass them into the function to compute the minequal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] <= input2[n, c, h, w] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinEqualOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* min_equal operation end */

/* cycle max_equal begin */
/*!
 *  @brief A function.
 *
 *  Create an cycle max_equal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the cycle max_equal operator, pass them into the function to create the cycle
 *  max_equal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] >= input2[1, c, 1, 1] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n, c, h, w], supporting
 *  data of float16/float32 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [1, c, 1, 1],
 *  supporting data of float16/float32 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [n, c, h, w], supporting
 *  data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCycleMaxEqualOp(cnmlBaseOp_t *op,
                                                    cnmlTensor_t input_tensor_1,
                                                    cnmlTensor_t input_tensor_2,
                                                    cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Create an cycle max_equal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the cycle max_equal operator, pass them into the function to create the cycle
 *  max_equal operator.
 *
 *  output[n, c,  h, w] = input1[n, c, h, w] >= input2[1, c, 1, 1] ? input1 : input2
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input1 tensor, supporting data of float16/float32 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input2 tensor, supporting data of float16/float32 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleMaxEqualOp(cnmlBaseOp_t *op,
                                                      int dim,
                                                      cnmlTensor_t input_tensor_1,
                                                      cnmlTensor_t input_tensor_2,
                                                      cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the cycle max_equal operator specified by users on the MLU.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleMaxEqualOpForward_V2 is recommended to use.
 *
 *  After creating cycle max_equal operator, input, output, runtime parameters, and computation
 * queues,
 *  pass them into the function to compute the cycle max_equal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] >= input2[1, c, 1, 1] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeCycleMaxEqualOpForward(cnmlBaseOp_t op,
                                  void *input_1,
                                  void *input_2,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the cycle max_equal operator specified by users on the MLU.
 *
 *  After creating cycle max_equal operator, input, output, runtime parameters, and computation
 *  queues, pass them into the function to compute the cycle max_equal operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCycleMaxEqualOpForward_V2(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor1,
                                                               void *input_1,
                                                               cnmlTensor_t input_tensor2,
                                                               void *input_2,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the cycle max_equal operator specified by users on the MLU.
 *
 *  After creating cycle max_equal operator, input, output, runtime parameters, and computation
 *  queues, pass them into the function to compute the cycle max_equal operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleMaxEqualOpForward(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);

/* cycle max_equal operation end */

/* cycle min_equal begin */
/*!
 *  @brief A function.
 *
 *  Create an cycle min_equal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the cycle min_equal operator, pass them into the function to create the cycle
 *  min_equal operator.
 *
 *  **Formula**
 *
 *    output[n, c,  h, w] = input1[n, c, h, w] <= input2[1, c, 1, 1] ? input1 : input2
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n, c, h, w], supporting
 *  data of float16/float32 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [1, c, h, w],
 *  supporting data of float16/float32 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [n, c, h, w], supporting
 *  data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCycleMinEqualOp(cnmlBaseOp_t *op,
                                                    cnmlTensor_t input_tensor_1,
                                                    cnmlTensor_t input_tensor_2,
                                                    cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create an nd cycle min_equal operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to the base operator address, operation parameters, input and
 *  output tensor of the cycle min_equal operator, pass them into the function to create the cycle
 *  min_equal operator.
 *
 *  output[n, c,  h, w] = input1[n, c, h, w] <= input2[1, c, 1, 1] ? input1 : input2
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] dim
 *    Input. A dim mark.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16/float32 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16/float32 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleMinEqualOp(cnmlBaseOp_t *op,
                                                      int dim,
                                                      cnmlTensor_t input_tensor_1,
                                                      cnmlTensor_t input_tensor_2,
                                                      cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the cycle min_equal operator specified by users on the MLU.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleMinEqualOpForward_V2 is recommended to use.
 *
 *  After creating cycle min_equal operator, input, output, runtime parameters, and computation
 * queues,
 *  pass them into the function to compute the cycle min_equal operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = [ a < b ? a : b for (a,b) in zip(a[n c_i h w], b[1 c_i 1 1]) for c_i in range(c)]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeCycleMinEqualOpForward(cnmlBaseOp_t op,
                                  void *input_1,
                                  void *input_2,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the cycle min_equal operator specified by users on the MLU.
 *
 *  After creating cycle min_equal operator, input, output, runtime parameters, and computation
 * queues,
 *  pass them into the function to compute the cycle min_equal operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCycleMinEqualOpForward_V2(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor1,
                                                               void *input_1,
                                                               cnmlTensor_t input_tensor2,
                                                               void *input_2,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the nd cycle min_equal operator specified by users on the MLU.
 *
 *  After creating cycle min_equal operator, input, output, runtime parameters, and computation
 * queues,
 *  pass them into the function to compute the cycle min_equal operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleMinEqualOpForward(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);

/* cycle min_equal operation end */

/* real div operation start */
/*!
 *  @brief A function.
 *
 *  Create a division operator according to base operator pointers given by users. After creating a
 *  pointer pointing to base operator address, and input and output Tesor, pass them into the
 *  fucntion to create the division operator.
 *
 *  Before creating a division operator, declare a pointer pointing to the struct address of
 *  operation parameters of the division operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  Perform element-wise division on the two inputs to obtain output.
 *
 *  The shape of the second input can be the same shape of first input or (1, 1, 1, 1).
 *  If the shape of second input is (1, 1, 1, 1), operation will expand it to a vector to excute div
 * operation.
 *  If the input tensor shape is (1, 1, 1, 1), the high precision interface should not be called.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] / b[n c h w]
 *
 *    or
 *
 *    c[n c h w] = a[n c h w] / b[1 1 1 1]
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU output tensor, the shape of which is [ni, ci, hi, wi],
 *  supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo] (no = ni,
 *  co = ci, ho = hi, wi = wo), supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateRealDivOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input_tensor_1,
                                              cnmlTensor_t input_tensor_2,
                                              cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Set a high-precision mode according to the division operator given by users.
 *
 *  After creating a division operator, calling this interface will start the high-precision mode.
 *
 *  If the high precision mode is set, the divisor can be negative. The precision will be improved
 *  when divisor interval is [0,1].
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] high_precision_flag
 *    Input. Set the operator as a high-precision identifier. The"true" represents the mode is set
 *  to the high-precision mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM:
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlSetRealDivHighPrecision(cnmlBaseOp_t *op, bool high_precision_flag);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeRealDivOpForward_V4 is recommended to use.
 *
 *  Compute the division operator given by users on the MLU.
 *
 *  After creating a division operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute the division operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The operator pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeRealDivOpForward_V3(cnmlBaseOp_t op,
                                                         void *input_1,
                                                         void *input_2,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the division operator given by users on the MLU.
 *
 *  After creating a division operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute the division operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeRealDivOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* real div operation end */

/* basic div operation begin */
/*!
 *  @brief A function.
 *
 *  The function Create basic division operator according to base operator pointers
 *  given by users on the MLU.
 *
 *  **Formula**
 *
 *    output[n c h w] = 1 / input[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *    MLU220:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *    MLU220:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi].
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo] (no = ni,
 *  co = ci, ho = hi, wi = wo).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateBasicDivOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute basic division operator on the MLU.
 *
 *  After creating a basic division operator, input, output, computation type, and computation
 * stream, pass them into the function to compute the basic division operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = 1 / input[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *    MLU220:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *    MLU220:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi].
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo]
 *    (no = ni, co = ci, ho = hi, wi = wo).
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM:
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeBasicDivOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);

/*!
 *  @brief A function.
 *
 *  Set a high-precision mode according to the basic division operator given by users.
 *
 *  After creating a division operator, calling this interface will enable the high-precision mode.
 *
 *  If the high precision mode is set, the operator will support negative input and the precision
 *  will be improved to 1E-20.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] high_precision_flag
 *    Input. Set the operator as a high-precision identifier. The value "true" represents the mode
 *    is set to the high-precision mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM:
 *    At least one of the following conditions are met:
 *    - op is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlSetBasicDivHighPrecision(cnmlBaseOp_t *op, bool high_precision_flag);

/* basic div operation end */

/* broadcast operation start */
/*!
 *  @brief A function.
 *
 *  **Descrption**
 *
 *  Create a broadcast operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor, pass
 *  them into the fucntion to create a broadcast operator.
 *
 *  Before creating a broadcast operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  When one dimension of the input is equal to 1 and not equal to the corresponding dimension of
 *  the output, duplicate the dimension data to expand the dimension to the output dimension.
 *
 *  For example:
 *
 *  1. int ni = 1, ci = 1, hi = 4, wi = 4;
 *
 *  int no = 1, co = 256, ho = 4, wo = 4;
 *
 *  duplicate and expand data of dimension c.
 *
 *  2. int ni = 1, ci = 256, hi = 4, wi = 4;
 *
 *  int no = 4, co = 256, ho = 4, wo = 4;
 *
 *  duplicate and expand data of dimension n.
 *
 *  3. int ni = 1, ci = 1, hi = 4, wi = 1;
 *
 *  int no = 1, co = 256, ho = 4, wo = 4;
 *
 *  simultaneously duplicate and expand data of dimension c and n.
 *
 *  @note
 *
 *  1. The shape of input cannot be 0.
 *
 *  2. Each dimension of the output shape is larger than or equal to the corresponding dimension of
 *  the input shape.
 *
 *  3. When the input dimension n is greater than 1, the output dimension n must be equal to the
 *  input dimension n.
 *
 *  When the input dimension c is greater than 1, the output dimension c must be equal to the input
 *  dimension c.
 *
 *  When the input dimension h is greater than 1, the output dimension h must be equal to the input
 *  dimension h.
 *
 *  When the input dimension w is greater than 1, the output dimension w must be equal to the input
 *  dimension w.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32, bool
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Create a broadcast operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor, pass
 *  them into the fucntion to create a broadcast operator.
 *
 *  Before creating a broadcast operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  When one dimension of the input is equal to 1 and not equal to the corresponding dimension of
 *  the output, duplicate the dimension data to expand the dimension to the output dimension.
 *
 *  For example:
 *
 *  1. int ni = 1, ci = 1, hi = 4, wi = 4;
 *
 *     int no = 1, co = 256, ho = 4, wo = 4;
 *
 *     duplicate and expand data of dimension c.
 *
 *  2. int ni = 1, ci = 256, hi = 4, wi = 4;
 *
 *     int no = 4, co = 256, ho = 4, wo = 4;
 *
 *     duplicate and expand data of dimension n.
 *
 *  3. int ni = 1, ci = 1, hi = 4, wi = 1;
 *
 *     int no = 1, co = 256, ho = 4, wo = 4;
 *
 *     simultaneously duplicate and expand data of dimension c and n.
 *
 *  @note
 *
 *  1. The shape of input cannot be 0.
 *
 *  2. Each dimension of the output shape is larger than or equal to the corresponding dimension of
 *  the input shape.
 *
 *  3. When the input dimension n is greater than 1, the output dimension n must be equal to the
 *  input dimension n.
 *
 *  When the input dimension c is greater than 1, the output dimension c must be equal to the input
 *  dimension c.
 *
 *  When the input dimension h is greater than 1, the output dimension h must be equal to the input
 *  dimension h.
 *
 *  When the input dimension w is greater than 1, the output dimension w must be equal to the input
 *  dimension w.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastOpForward(cnmlBaseOp_t *op,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create a n-dimensional broadcast operator according to base operator pointers given by users,
 *  which is the extension of broadcast operator. It supports tensor from one to any dimension.
 *  We recommend you use this interface to create the broadcast operator.
 *
 *  @note
 *
 *  1. The shape of input cannot be 0.
 *
 *  2. Each dimension of the output shape is larger than or equal to the corresponding dimension of
 *  the input shape.
 *
 *  3. When the dimension in input is greater than 1, the same dimension in output must be equal to
 *  the input.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A one to any dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A one to any dimensional MLU tensor,  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdBroadcastOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdBroadcastOpForward_V2 is recommended to use.
 *
 *  Compute the extensional broadcast operator on the MLU.
 *
 *  After creating a NdBroadcast operator, input, output, and computation stream, pass them into the
 *  function to compute the broadcast operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] type
 *    Input. An enumeration constant specifying the computation mode on the MLU.
 *  @param[in] stream
 *    Input. A computational stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdBroadcastOpForward(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the extensional broadcast operator on the MLU.
 *
 *  After creating a NdBroadcast operator, input, output, and computation stream, pass them into the
 *  function to compute the broadcast operator.
 *
 *  **Supports both MLU220 and MLU270.**

 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdBroadcastOpForward_V2(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast operator specified by users on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeBroadcastOpForward_V4 is recommended to use.
 *
 *  After creating a broadcast operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute broadcast operator.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, bool
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBroadcastOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the broadcast operator specified by users on the MLU.
 *
 *  After creating a broadcast operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute broadcast operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* broadcast operation end */

/* broadcast sub operation start */
/*!
 *  @brief A function.
 *
 *  Create a broadcast sub operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor, pass
 *  them into the fucntion to create a broadcast sub operator.
 *
 *  Before creating the broadcast sub operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast sub operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  Expand each dimension of the input respectively to the minimum common multiple of the dimension,
 *  and then perform element-wise subtraction on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *
 *  For example:
 *
 *  1. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 32, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension h and w of input2, and perform element-wise subtraction on the
 *  input.
 *
 *  2. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension c, h, and w of input2, and perform element-wise subtraction on
 *  the input.
 *
 *  In fact, addition, subtraction, and multiplication of broadcast match different NG operators
 *  according to the shape of operands: scale, cycle operators, and ordinary addition, subtraction,
 *  and multiplication operators.
 *
 *  Input1 has the same shape as output.
 *
 *  The shape of input2 supports three settings:
 *
 *  (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *  (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *  (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n1, c1, h1, w1], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n2, c2, h2, w2], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastSubOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast sub operator given by users on the MLU.
 *
 *  After creating a broadcast sub operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast sub operator.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeBroadcastSubOpForward_V4 is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBroadcastSubOpForward_V3(cnmlBaseOp_t op,
                                    void *input_1,
                                    void *input_2,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the broadcast sub operator given by users on the MLU.
 *
 *  After creating a broadcast sub operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast sub operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastSubOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* broadcast sub operation end */

/* broadcast add operation start */
/*!
 *  @brief A function.
 *
 *  Create a broadcast add operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a broadcast add operator.
 *
 *  Before creating a broadcast add operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast add operator, and pass the pointer and operator parameters
 *  required into the function to set operator parameters.
 *
 *  Expand each dimension of the input respectively to the minimum common multiple of the dimension,
 *  and then perform element-wise addition on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *
 *  For example:
 *
 *  1. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 32, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension h and w of input2, and perform element-wise addition on the
 *     input.
 *
 *  2. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension c, h, and w of input2, and perform element-wise addition on
 *     the
 *     input.
 *
 *  Input1 has the same shape as output.
 *
 *  The shape of input2 supports three settings:
 *
 *  (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *  (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *  (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n1, c1, h1, w1], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n2, c2, h2, w2], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastAddOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast add operator given by users on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 * cnmlComputeBroadcastAddOpForward_V4 is recommended to use.
 *
 *  After creating a broadcast add operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast add operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBroadcastAddOpForward_V3(cnmlBaseOp_t op,
                                    void *input_1,
                                    void *input_2,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the broadcast add operator given by users on the MLU.
 *
 *  After creating a broadcast add operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast add operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastAddOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* broadcast add operation end */

/* broadcast mult operation start */
/*!
 *  @brief A function.
 *
 *  Create a broadcast mult operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a broadcast mult operator.
 *
 *  Before creating a broadcast mult operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast mult operator, and pass the pointer and operator
 *  parameters required into the function to set operator parameters.
 *
 *  For example:
 *
 *  1. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 32, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension h and w of input2, and perform element-wise multiplication on
 *     the
 *     input.
 *
 *  2. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension c, h, and w of input2, and perform element-wise multiplication
 *     on
 *     the input.
 *
 *  **Formula**
 *
 *    Expand each dimension of the input respectively to the minimum common multiple of the
 *    dimension, and then perform element-wise multiplication on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    Input1 has the same shape as output.
 *
 *    The shape of input2 supports three settings:
 *
 *    (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *    (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *    (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n1, h1, w1, c1], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n2, h2, w2, c2], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastMultOp(cnmlBaseOp_t *op,
                                                    cnmlTensor_t input_tensor_1,
                                                    cnmlTensor_t input_tensor_2,
                                                    cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Create a broadcast mult operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a broadcast mult operator.
 *
 *  Before creating a broadcast mult operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast mult operator, and pass the pointer and operator
 *  parameters required into the function to set operator parameters.
 *
 *  Expand each dimension of the input respectively to the minimum common multiple of the dimension,
 *  and then perform element-wise multiplication on the input to obtain the output.
 *
 *  For example:
 *
 *  1. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *  const int n2 = 1, c2 = 32, h2 = 1, w2 = 1;
 *
 *  const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *  duplicate and expand dimension h and w of input2, and perform element-wise multiplication on the
 *  input.
 *
 *  2. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *  const int n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *  duplicate and expand dimension c, h, and w of input2, and perform element-wise multiplication on
 *  the input.
 *
 *  **Formula**
 *
 *    Expand each dimension of the input respectively to the minimum common multiple of the
 *    dimension, and then perform element-wise multiplication on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    Input1 has the same shape as output.
 *
 *    The shape of input2 supports three settings:
 *
 *    (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *    (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *    (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n1, h1, w1, c1], supporting
 *  data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n2, h2, w2, c2], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastMultOpForward(cnmlBaseOp_t *op,
                                                           cnmlTensor_t input_tensor_1,
                                                           cnmlTensor_t input_tensor_2,
                                                           cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast mlu operator specified by users on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeBroadcastMultOpForward_V4 is recommended to use.
 *
 *  After creating a broadcast mlu operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast mlu operator.
 *
 *  **Formula**
 *
 *    Expand each dimension of the input respectively to the minimum common multiple of the
 *  dimension, and then perform element-wise multiplication on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    Input1 has the same shape as output.
 *
 *    The shape of input2 supports three settings:
 *
 *    (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *    (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *    (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBroadcastMultOpForward_V3(cnmlBaseOp_t op,
                                     void *input_1,
                                     void *input_2,
                                     void *output,
                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the broadcast mlu operator specified by users on the MLU.
 *
 *  After creating a broadcast mlu operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast mlu operator.
 *
 *  **Formula**
 *
 *    Expand each dimension of the input respectively to the minimum common multiple of the
 *    dimension, and then perform element-wise multiplication on the input to obtain the output.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int32
 *
 *  **Scale Limitation**
 *
 *    Input1 has the same shape as output.
 *
 *    The shape of input2 supports three settings:
 *
 *    (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *    (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *    (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastMultOpForward_V4(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor1,
                                                               void *input_1,
                                                               cnmlTensor_t input_tensor2,
                                                               void *input_2,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);
/* broadcast mult operation end */

/* broadcast lesser operation start */
/*!
 *  @brief A function.
 *
 *  Create a broadcast lesser operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a broadcast lesser operator.
 *
 *  Before creating a broadcast lesser operator, declare a pointer pointing to the struct address of
 *  operation parameters of the broadcast lesser operator, and pass the pointer and operator
 *  parameters
 *  required into the function to set operator parameters.
 *
 *  Expand each dimension of the input respectively to the minimum common multiple of the dimension,
 *  and then perform element-wise lesser than comparison operation on the input to obtain the
 *  output.
 *
 *  For example:
 *
 *  1. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 32, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension h and w of input2, and perform element-wise lesser than
 *     comparison operation on the
 *     input.
 *
 *  2. const int n1 = 1, c1 = 32, h1 = 4, w1 = 4;
 *
 *     const int n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *     const int no = 1, co = 32, ho = 4, wo = 4;
 *
 *     duplicate and expand dimension c, h, and w of input2, and perform element-wise lesser than
 *     comparison operation on the
 *     input.
 *
 *  Input1 has the same shape as output.
 *
 *  The shape of input2 supports three settings:
 *
 *  (1)n2 = n1, c2 = c1, h2 = h1, w2 = w1;
 *
 *  (2)n2 = 1, c2 = c1, h2 = 1, w2 = 1;
 *
 *  (3)n2 = 1, c2 = 1, h2 = 1, w2 = 1;
 *
 *  **Summary**
 *
 *  For input1[n1, c1, h1, w1], input2[n2, c2, h2, w2],
 *
 *  output[n, c, h, w] = (broadcast(input1)[n, c, h, w] < broadcast(input2)[n, c, h, w]) ? 1 : 0
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      in_type-in_oc_type-out_oc_type-out_type
 *
 *      float16-float16   -float16    -float16
 *
 *      float32-float32   -float32    -float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n1, c1, h1, w1], supporting
 *  data of float16 and float32 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n2, c2, h2, w2], supporting
 *  data of float16 and float32 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo],
 *  supporting data of float16 and float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastLesserOp(cnmlBaseOp_t *op,
                                                      cnmlTensor_t input_tensor_1,
                                                      cnmlTensor_t input_tensor_2,
                                                      cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast lesser operator given by users on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeBroadcastLesserOpForward_V4 is recommended to use.
 *
 *  After creating a broadcast lesser operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast lesser operator.
 *
 *  **Summary**
 *
 *  For input1[n1, c1, h1, w1], input2[n2, c2, h2, w2],
 *
 *  output[n, c, h, w] = (broadcast(input1)[n, c, h, w] < broadcast(input2)[n, c, h, w]) ? 1 : 0
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      in_type-in_oc_type-out_oc_type-out_type
 *
 *      float16-float16   -float16    -float16
 *
 *      float32-float32   -float32    -float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBroadcastLesserOpForward_V3(cnmlBaseOp_t op,
                                       void *input_1,
                                       void *input_2,
                                       void *output,
                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                       cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast lesser operator specified by users on the MLU.
 *
 *  After creating a broadcast mlu operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the broadcast mlu operator.
 *
 *  **Summary**
 *
 *  For input1[n1, c1, h1, w1], input2[n2, c2, h2, w2],
 *
 *  output[n, c, h, w] = (broadcast(input1)[n, c, h, w] < broadcast(input2)[n, c, h, w]) ? 1 : 0
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *      in_type-in_oc_type-out_oc_type-out_type
 *
 *      float16-float16   -float16    -float16
 *
 *      float32-float32   -float32    -float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastLesserOpForward_V4(cnmlBaseOp_t op,
                                                                 cnmlTensor_t input_tensor1,
                                                                 void *input_1,
                                                                 cnmlTensor_t input_tensor2,
                                                                 void *input_2,
                                                                 cnmlTensor_t output_tensor,
                                                                 void *output,
                                                                 cnrtQueue_t queue,
                                                                 void *extra);
/* broadcast lesser operation end */

/* nddyadic operation start */
/*!
 *  @brief A function.
 *
 *   Unrestricts the order of input tensors.
 *   Expands each dimension of the input respectively to the minimum common multiple
 *   of the dimension, and then perform element-wise computing on the input to obtain the output.
 *   Currently supports element-wise add, sub, and mult operations.
 *
 *   Transmit two N-dimensional input tensors, one output tensor, and the dyadic type into the
 *   function to create a NdDyadic operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] d_type
 *    Input. The operation type, including CNML_DYADIC_ADD, CNML_DYADIC_SUB, CNML_DYADIC_MULT.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdDyadicOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor,
                                               cnmlDyadicType_t d_type);

/*!
 *  @brief A function.
 *
 *  Compute the nddyadic operator given by users on the MLU.
 *
 *  After creating a nddyadic operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the nddyadic operator. The nddyadic operator
 *  is determined by cnmlDyadicType_t.
 *
 *  **Formula**
 *
 *    c[n c h] = a[c h] op b[n c h]
 *
 *    c[n c h] = a[n c h] op b[c h]
 *
 *    c[n c h w] = a[1 c 1 1] op b[n c h w]
 *
 *    c[n c h w] = a[n c h w] op b[1 c 1 1]
 *
 *    c[n c h w d] = a[n c h w d] op b[1 1 1 1 1]
 *
 *    c[n c h w d] = a[1 1 1 1 1] op b[n c h w d]
 *
 *    c[n c h w d] = a[n c h w d] op b[n c h w d]
 *
 *    c[n c h w d] = a[n c 1 w d] op b[n 1 h 1 d]
 *
 *    The op type is determined by cnmlDyadicType_t.
 *
 *  **DataType**
 *
 *    MLU270/MLU220:
 *
 *     - input: float16, float32
 *
 *     - output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270/MLU220:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdDyadicOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor1,
                                                       void *input_1,
                                                       cnmlTensor_t input_tensor2,
                                                       void *input_2,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* nddyadic operation end */

/* sub operation start */
/*!
 *  @brief A function.
 *
 *  Create a Sub operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a Sub operator.
 *
 *  The shapes of the two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] - b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSubOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor_1,
                                          cnmlTensor_t input_tensor_2,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSubOpForward_V4 is recommended to use.
 *
 *  Compute the Sub operator specified by users on the MLU.
 *
 *  After creating a Sub operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Sub operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] - b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSubOpForward_V3(cnmlBaseOp_t op,
                                                     void *input_1,
                                                     void *input_2,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the Sub operator specified by users on the MLU.
 *
 *  After creating a Sub operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Sub operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSubOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor1,
                                                     void *input_1,
                                                     cnmlTensor_t input_tensor2,
                                                     void *input_2,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* sub operation end */

/* squared diff operation start */
/*!
 *  @brief A function.
 *
 *  Create a squared difference operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a squared difference operator.
 *
 *  output = (input1 - input2) * (input1 - input2)
 *
 *  The types of the two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c1 h w] = a[n c1 h w] - b[n c2 h w]
 *
 *    c2 can be the same with c2 or be 1.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 4-dimensional MLU tensor, supporting data of float16/float32 type.
 *  @param[in] input_tensor_2
 *    Input. A 4-dimensional MLU tensor, supporting data of float16/float32 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU tensor, supporting data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSquaredDiffOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t input_tensor_1,
                                                  cnmlTensor_t input_tensor_2,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSquaredDiffOpForward_V4 is recommended to use.
 *
 *  Compute the squared difference operator specified by users on the MLU.
 *
 *  After creating a squared difference operator, input, output, runtime parameters, and computation
 * queue, pass
 *  them into the function to compute the squared difference operator.
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeSquaredDiffOpForward_V3(cnmlBaseOp_t op,
                                   void *input_1,
                                   void *input_2,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the squared difference operator specified by users on the MLU.
 *
 *  After creating a squared difference operator, input, output, runtime parameters, and computation
 * queue, pass them into the function to compute the squared difference operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSquaredDiffOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor1,
                                                             void *input_1,
                                                             cnmlTensor_t input_tensor2,
                                                             void *input_2,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* squared diff operation end */

/* mult operation start */
/*!
 *  @brief A function.
 *
 *  Create a Mult operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor, pass
 *  them into the fucntion to create a Mult operator.
 *
 *  The shapes of the two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    output[n c h w] = intput1[n c h w] * input2[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMultOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor_1,
                                           cnmlTensor_t input_tensor_2,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMultOpForward_V4 is recommended to use.
 *
 *  Compute the Mult operator given by users on the MLU.
 *
 *  After creating a Mult operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Mult operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] * b[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address which points to input data.
 *  @param[in] input_2
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMultOpForward_V3(cnmlBaseOp_t op,
                                                      void *input_1,
                                                      void *input_2,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the Mult operator given by users on the MLU.
 *
 *  After creating a Mult operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Mult operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = intput1[n c h w] * input2[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMultOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor1,
                                                      void *input_1,
                                                      cnmlTensor_t input_tensor2,
                                                      void *input_2,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* mult operation end */

/* lrn operation start */
/*!
 *  @struct cnmlLrnOpParam
 *  @brief A struct.
 *
 *  cnmlLrnOpParam is a structure describing the param parameter of lrn operation, used to create
 *  lrn operation. cnmlCreateLrnOpParam() is used to create an instance of cnmlLrnOpParam_t.
 *  cnmlDestroyLrnOpParam() is used to destroy an instance of cnmlLrnOpParam_t. */
struct cnmlLrnOpParam;
/*! ``cnmlLrnOpParam_t`` is a pointer to ``cnmlLrnOpParam`` which is a
    structure holding the description of a LRN operation param. */
typedef struct cnmlLrnOpParam *cnmlLrnOpParam_t;

/*!
 *  @brief A function.
 *
 *  This function creates a struct of Lrn operator operation parameters according to pointers given
 *  by users, and fills the struct with the parameters input by users.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the struct address of Lrn operator operaion parameters.
 *  @param[in] type
 *    Input. An enumeration type, representing the mode of lrn parameters.
 *  @param[in] local_size
 *    Input. Extract local_size numbers in the direction c.
 *  @param[in] alpha
 *    Input. A variance scaling parameter.
 *  @param[in] beta
 *    Input. An exponential item.
 *  @param[in] k
 *    Input. A hyper parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  param limitation:
 *    Highly recommend to use hyper parameters as follows:
 *    local_size: 5
 *    alpha: 0.0001
 *    beta: 0.75
 *    k: 2
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLrnOpParam(cnmlLrnOpParam_t *param,
                                               cnmlLrnType_t lrn_type,
                                               int local_size,
                                               double alpha,
                                               double beta,
                                               double k);

/*!
 *  @brief A function.
 *
 *  Release the struct pointer of Lrn operator operation parameters according to the pointer given
 *  by users.
 *
 *  After the operation of the Lrn operator is finished, release the struct pointer of the Lrn
 *  operator operation parameters.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the struct address of the Lrn operator operation parameters.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyLrnOpParam(cnmlLrnOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create an Lrn operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor, pass
 *  them into the fucntion to create Lrn operator.
 *
 *  **Formula**
 *
 *  1. CNML_LRN_V1,
 *    Yi = Xi / [(alpha * sum(Xj^2) / m + k) ^ beta], m = min(local_size, 2*ci-1)
 *
 *  2. CNML_LRN_V2,
 *    Yi = Xi / [(alpha * sum(Xj^2) + k) ^ beta]
 *
 *  3. CNML_LRN_V3,
 *    Yi = Xi / [(alpha * sum(Xj^2) / local_size + k) ^ beta]
 *
 *    j = i - local_size / 2 ~~ i + local_size / 2, (i and j are in C dimention)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32
 *
 *      compute: float16, float32
 *
 *      output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Conditions & Limitations**
 *
 *    The onchip position and scale of input tensor should be calculated by alhpa*(input_data^2).
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] param
 *    Input. A pointer pointing to the struct of the Lrn operator operation parameters.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n, h, w, c], supporting
 *  data of float16 type.
 *  @param[in] output
 *    Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLrnOp(cnmlBaseOp_t *op,
                                          cnmlLrnOpParam_t param,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLrnOpForward_V4 is recommended to use.
 *
 *  Compute the Lrn operator specified by users on the MLU.
 *
 *  After creating a Lrn operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Lrn operator.
 *
 *  **Formula**
 *
 *  1. CNML_LRN_V1,
 *    Yi = Xi / [(alpha * sum(Xj^2) / m + k) ^ beta], m = min(local_size, 2*ci-1)
 *
 *  2. CNML_LRN_V2,
 *    Yi = Xi / [(alpha * sum(Xj^2) + k) ^ beta]
 *
 *  3. CNML_LRN_V3,
 *    Yi = Xi / [(alpha * sum(Xj^2) / local_size + k) ^ beta]
 *
 *    j = i - local_size / 2 ~~ i + local_size / 2, (i and j are in C dimention)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32
 *
 *      compute: float16, float32
 *
 *      output: int8, int16, float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLrnOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the Lrn operator specified by users on the MLU.
 *
 *  After creating a Lrn operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the Lrn operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLrnOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);

/*  lrn operation end  */

/* batch_norm operation start */
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Create a BatchNorm operator according to base operator pointers given by users.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlCreateBatchNormOpForward
 *  is recommended to use.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a BatchNorm operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] -mean[1 c 1 1])* var[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     inputDataType: float16, float32
 *
 *     outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 42000
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n, h, w, c], supporting
 *  data of float16 type.
 *  @param[in] output
 *    Input. A four-dimensional MLU output tensor, the shape of which is [n, h, w, c], supporting
 *  data of float16 type.
 *  @param[in] mean
 *    Input. A four-dimensional mean value tensor of MLU, the shape of which is [1, 1, 1, c],
 *  supporting data of float16 type.
 *  @param[in] var
 *    Input. A four-dimensional variance tensor of MLU, the shape of which is [1, 1, 1, c],
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *    - The mean value tensor is null.
 *    - The variance value is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBatchNormOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t mean_tensor,
                                                cnmlTensor_t var_tensor);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Create a NdBatchNorm operator according to base operator pointers given by users.
 *
 *  Deprecated. This interface will be deleted in next version.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a NdBatchNorm operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input
 *    Input. A multi-dimensional MLU input tensor, supporting data of float16 type.
 *  @param[in] output
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] mean
 *    Input. A multi-dimensional MLU mean tensor, supporting data of float16 type.
 *  @param[in] var
 *    Input. A multi-dimensional MLU var tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *    - The mean value tensor is null.
 *    - The variance value is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdBatchNormOp(cnmlBaseOp_t *op,
                                                  int dim,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor,
                                                  cnmlTensor_t mean_tensor,
                                                  cnmlTensor_t var_tensor);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Create a BatchNorm operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a BatchNorm operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] -mean[1 c 1 1])* var[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     - inputDataType: float16, float32
 *
 *     - computeDataType: computeDataType = inputDataType
 *
 *     - outputDataType: float16, float32, int16, int8
 *
 *  **Scale limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A multi-dimensional MLU input tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] mean_tensor
 *    Input. A multi-dimensional MLU mean tensor, supporting data of float16 type.
 *  @param[in] var_tensor
 *    Input. A multi-dimensional MLU var tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 *    - The mean value tensor is null.
 *    - The variance value is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBatchNormOpForward(cnmlBaseOp_t *op,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor,
                                                       cnmlTensor_t mean_tensor,
                                                       cnmlTensor_t var_tensor);

/*!
 *  @brief A function.
 *
 * **Description**
 *
 *  Compute the BatchNorm operator specified by users on the MLU.
 *
 *  After creating a Mult operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the BatchNorm operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] -mean[1 c 1 1])* var[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType: float16, float32
 *
 *      outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     c < 42000
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeBatchNormOpForward_V4
 *  is recommended to use.
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBatchNormOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 * **Description**
 *
 *  Compute the BatchNorm operator specified by users on the MLU.
 *
 *  After creating a Mult operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the BatchNorm operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] -mean[1 c 1 1])* var[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     - inputDataType: float16, float32
 *
 *     - computeDataType: computeDataType = inputDataType
 *
 *     - outputDataType: float16, float32, int16, int8
 *
 *  **Scale limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBatchNormOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Compute the NdBatchNorm operator specified by users on the MLU.
 *
 *  After creating a Mult operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the NdBatchNorm operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdBatchNormOpForward(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/* batch_norm operation end */

/* max operation start */
/*!
 *  @brief A function.
 *
 *  Create a max operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address,  pass them into the fucntion to
 *  create a max operator.
 *
 *  This operator compares all the input data, outputs the maximum value, and gives the index of the
 *  maximum value. Assuming the position of the maximum value is input[n, c, h, w], then index = n *
 *  H * W * C + h * W * C + w * C + c.
 *
 *  **Formula**
 *
 *    max = MAX(a[n c h w])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 131008
 *
 *      DataType = float32 : c <= 65504
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape of which is [1, 1, 1, 1], supporting
 *  data of float16 type.
 *  @param[in] index_tensor
 *    Input. A four-dimensional MLU index vector the shape of which is [1, 1, 1, 1], supporting data
 *  of unit32 and float16 types.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMaxOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor,
                                          cnmlTensor_t index_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMaxOpForward_V4 is recommended to use.
 *
 *  Compute the max operator specified by users on the MLU.
 *
 *  After creating a max operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the max operator.
 *
 *  **Formula**
 *
 *    max = MAX(a[n c h w])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 131008
 *
 *      DataType = float32 : c <= 65504
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[out] index
 *    Output. An MLU address pointing to the index position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaxOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     void *index,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the max operator specified by users on the MLU.
 *
 *  After creating a max operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the max operator.
 *
 *  **Formula**
 *
 *    max = MAX(a[n c h w])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 131008
 *
 *      DataType = float32 : c <= 65504
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[in] output
 *    Input. MLU address pointing to output data.
 *  @param[in] index_tensor
 *    Input.  Index MLU tensor pointer. Pass NULL if not used.
 *  @param[out] index
 *    Output. An MLU address pointing to index position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaxOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnmlTensor_t index_tensor,
                                                     void *index,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* max operation end */

/* reduce max operation start */
/*!
 *  @brief A function.
 *
 *  Create a Reduce Max operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output tensor,  pass
 *  them into the fucntion to create a Reduce Max operator.
 *
 *  The Reduce Max loads data continuously, therefore, if the direction of reduce is n and the size
 *  of seg*H*W is too large to load two Ns, the maximum value cannot be obtained.
 *
 *  **Summary**
 *
 *   input[n, c, h, w],and compute the max value of given direction.
 *
 *   such as direction is n, output[1, c, h, w]
 *
 *   such as direction is c, output[n, 1, h, w]
 *
 *   ...
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      value_data_type = input_data_type:float16, float32, int32
 *
 *      index_data_type:
 *
 *       if direction is c, index_data_type = int32
 *
 *       else if input_data_type = float16 then index_data_type = int16
 *
 *       else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *      align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *      input_dt == float16: ct_line_num = 32
 *
 *      input_dt == float32: ct_line_num = 64
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] mode
 *    Input. An enumeration variable, a dimension that users will reduce, supporting N, C, H, and W.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, and the size of dimensions of which the shape is
 *  reduced must be 1. The size of other dimenisions is consistent with that of input Tensor,
 *  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReduceMaxOp(cnmlBaseOp_t *op,
                                                cnmlDimension_t reduce_max_mode,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReduceMaxOpForward_V4 is recommended to use.
 *
 *  Compute the Reduce Max operator given by users on the MLU.
 *
 *  After creating Reduce Max operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute Reduce Max operator.
 *
 *  **Summary**
 *
 *   input[n, c, h, w],and compute the max value of given direction.
 *
 *   such as direction is n, output[1, c, h, w]
 *
 *   such as direction is c, output[n, 1, h, w]
 *
 *   ...
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      value_data_type = input_data_type:float16, float32, int32
 *
 *      index_data_type:
 *
 *       if direction is c, index_data_type = int32
 *
 *       else if input_data_type = float16 then index_data_type = int16
 *
 *       else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *      align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *      input_dt == float16: ct_line_num = 32
 *
 *      input_dt == float32: ct_line_num = 64
 *
 *       at least process one full line c at a time
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeReduceMaxOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the Reduce Max operator given by users on the MLU.
 *
 *  After creating Reduce Max operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute Reduce Max operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReduceMaxOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* reduce max operation end */

/* nd reduce max operation start */
/*!
 *  @brief A function.
 *
 *  Create a Reduce Max operator supporting arbitrary dimension tensor according to base operator
 * pointers
 *  given by users.
 *
 *  This operator extens to support arbitrary dimension tensor based on the Reduce Max operator.
 *
 *  After creating a pointer pointing to base operator address, dimension of reduce operation
 *  operation, and input and output Tensor,  pass them into the fucntion to create a Reduce Max
 *  operator supporting multi-dimension.
 *
 *  Before creating a reduce max operator, declare a pointer pointing to the struct address of
 *  operation parameters of the operator, and pass the pointer and operator parameters required into
 *  the function to set operator parameters.
 *
 *  Compute the maximum value along the dimension that users will reduce.
 *
 *  The reduce_max loads data continuously, therefore, if the direction of reduce is n and the size
 *  of seg*H*W is too large to load two Ns, the maximum value cannot be obtained.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] dim
 *    Input. A variable of int type, specifying dimensions of the reduce operation.
 *  @param[in] input
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] output
 *    Input. A multi-dimensional MLU weight tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdReduceMaxOp(cnmlBaseOp_t *op,
                                                  int dim,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdReduceMaxOpForward_V2 is recommended to use.
 *
 *  Compute the Reduce Max operator supporting multi-dimension on the MLU.
 *
 *  After creating a Reduce Max operator supporting multi-dimension, input, output, and computation
 *  stream, pass them into the function to compute the Reduce Max operator supporting
 *  multi-dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval  CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdReduceMaxOpForward(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the Reduce Max operator supporting multi-dimension on the MLU.
 *
 *  After creating a Reduce Max operator supporting multi-dimension, input, output, and computation
 *  stream, pass them into the function to compute the Reduce Max operator supporting
 *  multi-dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdReduceMaxOpForward_V2(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);

/* nd reduce max operation end */

/* min operation start */
/*!
 *  @brief A function.
 *
 *  Create a min operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, input and output tensor, and index
 *  tensor, pass them into the fucntion to create min operator.
 *
 *  This operator compares all the input data, outputs the minimum value, and gives the index of the
 *  minimum value. Assuming that the position of the minimum value is input[n, c, h, w], then index
 *  = n * H * W * C + h * W * C + w * C + c.
 *
 *  **Formula**
 *
 *    min = MIN(a[n c h w])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 131008
 *
 *      DataType = float32 : c <= 65504
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi], supporting
 *  data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape of which is [1, 1, 1, 1], supporting
 *  data of float16 type.
 *  @param[in] index_tensor
 *    Input. A four-dimensional MLU index tensor, the shape of which is [1, 1, 1, 1], supporting
 *  data of unit32 and float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMinOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor,
                                          cnmlTensor_t index_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMinOpForward_V4 is recommended to use.
 *
 *  Compute the min operator specified by users on the MLU.
 *
 *  After creating a min operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the min operator.
 *
 *  **Formula**
 *
 *    min = MIN(a[n c h w])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 131008
 *
 *      DataType = float32 : c <= 65504
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[out] index
 *    Output. An MLU address pointing to the index position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     void *index,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the min operator specified by users on the MLU.
 *
 *  After creating a min operator, input, output, runtime parameters, and computation queue, pass
 *  them into the function to compute the min operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] output
 *    Input. MLU address pointing to output data.
 *  @param[in] index_tensor
 *    Input.  Index MLU tensor pointer. Pass NULL if not used.
 *  @param[out] index
 *    Output. An MLU address pointing to index position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnmlTensor_t index_tensor,
                                                     void *index,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* min operation end */

/* reverse operation start*/
/*!
 *  @brief A function.
 *
 *  Create a reverse operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and
 *  output tensor, pass them into the fucntion to create a reverse operator.
 *
 *  The shape of input tensor and output tensor should be the same.
 *
 *  **Formula**
 *
 *   if input data shape: NHWC are 2,2,2,2
 *
 *      input data: [[[0, 1], [2, 3]], [[4, 5], [6, 7]]],
 *               [[[8, 9], [10, 11]], [[12, 13], [14, 15]]]
 *
 *   Reverse in dim N
 *
 *   output data: [[[8, 9], [10, 11]], [[12, 13], [14, 15]]],
 *                [[[0, 1], [2, 3]], [[4, 5], [6, 7]]]
 *
 *   Reverse in dim H
 *
 *   output data: [[[4, 5], [6, 7]], [[0, 1], [2, 3]]],
 *                [[[12, 13], [14, 15]], [[8, 9], [10, 11]]]
 *
 *   Reverse in dim W:
 *
 *   output data: [[[2, 3], [0, 1]], [[6, 7], [4, 5]]],
 *                [[[10, 11], [8, 9]], [[14, 15], [12, 13]]]
 *
 *   Reverse in dim C:
 *
 *   output data: [[[1, 0], [3, 2]], [[5, 4], [7, 6]]],
 *                [[[9, 8], [11, 10]], [[13, 12], [15, 14]]]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType: float16, float32, int16, int8
 *
 *      outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input.  A four-dimensional MLU input tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A four-dimensional MLU output tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type.
 *  @param[in] reverse_axis
 *    Input.  An enumeration variable, supporting reversing along the dimension N, C, H, W, and HW
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReverseOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t output_tensor,
                                              cnmlDimension_t reverse_axis);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReverseOpForward_V4 is recommended to use.
 *
 *  Compute the reverse operator specified by users on the MLU.
 *
 *  After creating a reverse operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the reverse operator.
 *
 *  **Formula**
 *
 *   if input data shape: NHWC are 2,2,2,2
 *
 *      input data: [[[0, 1], [2, 3]], [[4, 5], [6, 7]]],
 *               [[[8, 9], [10, 11]], [[12, 13], [14, 15]]]
 *
 *   Reverse in dim N
 *
 *   output data: [[[8, 9], [10, 11]], [[12, 13], [14, 15]]],
 *                [[[0, 1], [2, 3]], [[4, 5], [6, 7]]]
 *
 *   Reverse in dim H
 *
 *   output data: [[[4, 5], [6, 7]], [[0, 1], [2, 3]]],
 *                [[[12, 13], [14, 15]], [[8, 9], [10, 11]]]
 *
 *   Reverse in dim W:
 *
 *   output data: [[[2, 3], [0, 1]], [[6, 7], [4, 5]]],
 *                [[[10, 11], [8, 9]], [[14, 15], [12, 13]]]
 *
 *   Reverse in dim C:
 *
 *   output data: [[[1, 0], [3, 2]], [[5, 4], [7, 6]]],
 *                [[[9, 8], [11, 10]], [[13, 12], [15, 14]]]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType: float16, float32, int16, int8
 *
 *      outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input.  A pointer which points to base operators.
 *  @param[in] input
 *    Input.  An MLU address which points to input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of
 *    data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input.   A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReverseOpForward_V3(cnmlBaseOp_t op,
                                                         void *input,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the reverse operator specified by users on the MLU.
 *
 *  After creating a reverse operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the reverse operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReverseOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor,
                                                         void *input,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* reverse operation end */

/* interp operation start */
/*!
 *  @struct cnmlInterpOpParam
 *  @brief A struct.
 *
 *  cnmlInterpOpParam is a structure describing the param parameter of interp operation, used to
 *  create interp operation. cnmlCreateInterpOpParam() and cnmlCreateInterpOpParamByRatio() is used
 *  to create an instance of cnmlInterpOpParam_t. cnmlDestroyInterpOpParam() is used to destroy an
 *  instance of cnmlInterpOpParam_t. */
struct cnmlInterpOpParam;
/*! ``cnmlInterpOpParam_t`` is a pointer to ``cnmlInterpOpParam`` which is a
    structure holding the description of a interp operation param. */
typedef struct cnmlInterpOpParam *cnmlInterpOpParam_t;

/*!
 *  @brief A function.
 *
 *  Create a struct of parameters required by the interpolation operator.
 *
 *  **Summary**
 *
 *    For input[ni, ci, hi, wi] and output[no, co, ho, wo], if ni = no and ci = co:
 *
 *    The hi / ho, wi / wo are used to find interp location.
 *
 *    index_h = floor(hi / ho * h_iter)
 *
 *    index_w = floor(wi / wo *w_iter)
 *
 *    ho[h_iter] = (hi / ho * h_iter - index_h) * (hi[index_h] + 1) +
 *    (index_h + 1 - hi / ho * h_iter) * hi[index_h]
 *
 *    wo[w_iter] = (wi / wo * w_iter - index_w) * (wi[index_w] + 1) +
 *    (index_w + 1 - wi / wo * w_iter) * wi[index_w]
 *
 *    where inde_h represents the y-coordinates of data points, index_w represents the x-coordinates
 *    of data points, h_iter and w_iter represent the number of iteration, ho[h_iter] represents
 *    the ouput grid in y direction, wo[h_iter] represents the ouput grid in x direction
 *
 *    The value of wo is the same as the value of ho. The value of h_iter should be
 *    less than the value of ho. The value of w_iter should be less than the value of wo.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The smaller the size of hi, wi, ho, and wo, the better performance.
 *  @param[out] param
 *    Output.  A pointer executing the operator struct.
 *  @param[in] output_width
 *    Input.  Specifying the width of input.
 *  @param[in] output_height
 *    Input.  Specifying the height of input.
 *  @param[in] align_corner
 *    Input.  When set to True, the values on the four corners of the output are the
 *    same as those on the four corners of the input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateInterpOpParam(cnmlInterpOpParam_t *param,
                                                  int output_width,
                                                  int output_height,
                                                  bool align_corners);

/*!
 *  @brief A function.
 *
 *  Use the zoom coefficients to create a struct of interpolation operator parameters.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input.  A pointer pointing to the operator struct.
 *  @param[in] zoom
 *    Input.  Coefficients.
 *  @param[in] align_corner
 *    Input.  When set to True, the values on the four corners of the output are the
 *    same as those on the four corners of the input.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateInterpOpParamByRatio(cnmlInterpOpParam_t *param,
                                                         float zoom,
                                                         bool align_corners);

/*!
 *  @brief A function.
 *
 *  Release the struct of parameters required by the interpolation operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input.  A pointer of the operator parameter struct to be released.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyInterpOpParam(cnmlInterpOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create an interpolation operator according to input and parameters of interpolation operator.
 *
 *  **Summary**
 *
 *    For input[ni, ci, hi, wi] and output[no, co, ho, wo], if ni = no and ci = co:
 *
 *    The hi / ho, wi / wo are used to find interp location.
 *
 *    index_h = floor(hi / ho * h_iter)
 *
 *    index_w = floor(wi / wo *w_iter)
 *
 *    ho[h_iter] = (hi / ho * h_iter - index_h) * (hi[index_h] + 1) +
 *    (index_h + 1 - hi / ho * h_iter) * hi[index_h]
 *
 *    wo[w_iter] = (wi / wo * w_iter - index_w) * (wi[index_w] + 1) +
 *    (index_w + 1 - wi / wo * w_iter) * wi[index_w]
 *
 *    where inde_h represents the y-coordinates of data points, index_w represents the x-coordinates
 *    of data points, h_iter and w_iter represent the number of iteration, ho[h_iter] represents
 *    the ouput grid in y direction, wo[h_iter] represents the ouput grid in x direction
 *
 *    The value of wo is the same as the value of ho. The value of h_iter should be
 *    less than the value of ho. The value of w_iter should be less than the value of wo.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_dt = output_dt
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *
 *  **Performance Optimization**
 *
 *    The smaller the size of hi, wi, ho, and wo, the better performance.
 *  @param[in] op
 *    Input.  A pointer pointing to base operators address.
 *  @param[in] input
 *    Input.  A four-dimensional input tensor([n, h, w, c]).
 *  @param[in] output
 *    Input.  A four-dimensional output tensor([n, output_height, output_width, c]).
 *  @param[in] param
 *    Input.  A pointer of the operator parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateInterpOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor,
                                             cnmlInterpOpParam_t param);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeInterpOpForward_V4 is recommended to use.
 *
 *  Compute the interpolation operator.
 *
 *  **Summary**
 *
 *    For input[ni, ci, hi, wi] and output[no, co, ho, wo], if ni = no and ci = co:
 *
 *    The hi / ho, wi / wo are used to find interp location.
 *
 *    index_h = floor(hi / ho * h_iter)
 *
 *    index_w = floor(wi / wo *w_iter)
 *
 *    ho[h_iter] = (hi / ho * h_iter - index_h) * (hi[index_h] + 1) +
 *    (index_h + 1 - hi / ho * h_iter) * hi[index_h]
 *
 *    wo[w_iter] = (wi / wo * w_iter - index_w) * (wi[index_w] + 1) +
 *    (index_w + 1 - wi / wo * w_iter) * wi[index_w]
 *
 *    where inde_h represents the y-coordinates of data points, index_w represents the x-coordinates
 *    of data points, h_iter and w_iter represent the number of iteration, ho[h_iter] represents
 *    the ouput grid in y direction, wo[h_iter] represents the ouput grid in x direction
 *
 *    The value of wo is the same as the value of ho. The value of h_iter should be
 *    less than the value of ho. The value of w_iter should be less than the value of wo.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_dt = output_dt
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The smaller the size of hi, wi, ho, and wo, the better performance.
 *  @param[in] op
 *    Input.  A pointer pointing to the operator.
 *  @param[in] input
 *    Input.  Pointing to input data address.
 *  @param[in] output
 *    Input.  Pointing to output data address.
 *  @param[in] compute_forw_param
 *    Input.  Pointing to the address of parameter structs such as runtime data and device affinity.
 *  @param[in] queue
 *    Input.  A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeInterpOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the interpolation operator.
 *
 *  **Summary**
 *
 *    For input[ni, ci, hi, wi] and output[no, co, ho, wo], if ni = no and ci = co:
 *
 *    The hi / ho, wi / wo are used to find interp location.
 *
 *    index_h = floor(hi / ho * h_iter)
 *
 *    index_w = floor(wi / wo *w_iter)
 *
 *    ho[h_iter] = (hi / ho * h_iter - index_h) * (hi[index_h] + 1) +
 *    (index_h + 1 - hi / ho * h_iter) * hi[index_h]
 *
 *    wo[w_iter] = (wi / wo * w_iter - index_w) * (wi[index_w] + 1) +
 *    (index_w + 1 - wi / wo * w_iter) * wi[index_w]
 *
 *    where inde_h represents the y-coordinates of data points, index_w represents the x-coordinates
 *    of data points, h_iter and w_iter represent the number of iteration, ho[h_iter] represents
 *    the ouput grid in y direction, wo[h_iter] represents the ouput grid in x direction
 *
 *    The value of wo is the same as the value of ho. The value of h_iter should be
 *    less than the value of ho. The value of w_iter should be less than the value of wo.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_dt = output_dt
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The smaller the size of hi, wi, ho, and wo, the better performance.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeInterpOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* interp operation end */

/* scale operation start */
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateScaleOpForward is recommended to use.
 *
 *  Create a linear transformation operator, which can perform linear transformation
 *  on the input.(out = alpha * in + beta).
 *
 *  **Formula**
 *
 *    alpha can be (1 c 1 1) or (1 1 1 1)
 *
 *    beta can be (1 c 1 1) or (1 1 1 1)
 *
 *    output[n c h w] = alpha[1 c 1 1] * input[n c h w] + beta[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType: float16, float32
 *
 *      outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      if (alpha(1 c 1 1) && beta (1 1 1 1)) or (alpha(1 1 1 1) && beta(1 c 1 1))
 *
 *      then c < 65000
 *
 *      else if (alpha(1 c 1 1)&& beta(1 c 1 1)
 *
 *      then c < 43000
 *
 *      else if (alpha(1 1 1 1)&& beta(1 1 1 1)
 *
 *      then c < 130400
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to the operator.
 *  @param[in] input
 *    Input.  A four-dimensional input tensor([n, h, w, c]).
 *  @param[in] output
 *    Input.  A four-dimensional output tensor([n, h, w, c]).
 *  @param[in] alpha
 *    Input.  Coefficients of linear transformation(out = alpha * in + beta).
 *  @param[in] beta
 *    Input.  Bias of linear transformation(out = alpha * in + beta).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.

 */
CNML_DLL_API cnmlStatus_t cnmlCreateScaleOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor,
                                            cnmlTensor_t alpha_tensor,
                                            cnmlTensor_t beta_tensor);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Deprecated. This interface will be deleted in next version.
 *
 *  Create a linear transformation operator, which can perform linear transformation
 *  on the input.(out = alpha * in + beta).
 *
 *  **Formula**
 *
 *    alpha can be (1 c 1 1) or (1 1 1 1)
 *
 *    beta can be (1 c 1 1) or (1 1 1 1)
 *
 *    output[n c h w] = alpha[1 c 1 1] * input[n c h w] + beta[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      - inputDataType: float16, float32
 *
 *      - computeDataType: computeDataType = inputDataType
 *
 *      - outputDataType: float16, float32, int16, int8
 *
 *  **Scale Limitation**:
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[out] op
 *    Output.  A pointer pointing to the operator.
 *  @param[in] dim
 *    Input.  Int num which marks operating dim.
 *  @param[in] input
 *    Input. A multi-dimensional MLU input tensor, supporting data of float16 type.
 *  @param[in] output
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] alpha
 *    Input. A multi-dimensional MLU tensor, supporting data of float16 type.
 *    Coefficients of linear transformation(out = alpha * in + beta).
 *  @param[in] beta
 *    Input. A multi-dimensional MLU tensor, supporting data of float16 type.
 *    Bias of linear transformation(out = alpha * in + beta).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdScaleOp(cnmlBaseOp_t *op,
                                              int dim,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t output_tensor,
                                              cnmlTensor_t alpha_tensor,
                                              cnmlTensor_t beta_tensor);

/*!
 *  @brief A function.
 *
 *  Create a linear transformation operator, which can perform linear transformation
 *  on the input.(out = alpha * in + beta).
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to the operator.
 *  @param[in] input_tensor
 *    Input.  A four-dimensional input tensor([n, h, w, c]).
 *  @param[in] output_tensor
 *    Input.  A four-dimensional output tensor([n, h, w, c]).
 *  @param[in] alpha_tensor
 *    Input.  Coefficients of linear transformation(out = alpha * in + beta).
 *  @param[in] beta_tensor
 *    Input.  Bias of linear transformation(out = alpha * in + beta).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScaleOpForward(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor,
                                                   cnmlTensor_t alpha_tensor,
                                                   cnmlTensor_t beta_tensor);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Compute the linear transformation operator.
 *
 *  **Formula**
 *
 *    alpha can be (1 c 1 1) or (1 1 1 1)
 *
 *    beta can be (1 c 1 1) or (1 1 1 1)
 *
 *    output[n c h w] = alpha[1 c 1 1] * input[n c h w] + beta[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      - inputDataType: float16, float32
 *
 *      - computeDataType: computeDataType = inputDataType
 *
 *      - outputDataType: float16, float32, int16, int8

 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  @param[in] op
 *    Input.  An operator pointer.
 *  @param[in] input
 *    Input.  Pointing to input tensor.
 *  @param[in] output
 *    Input.  Pointing to output tensor.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of
 *    data parallelism and device affinity of runtime.
 *  @param[in] stream
 *    Input.  Pointing to computation stream.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    For more information, see "Error Codes" section in this guide.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeScaleOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeScaleOpForward_V4 is recommended to use.
 *
 *  Compute the linear transformation operator.
 *
 *  **Supports both MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeScaleOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdScaleOpForward is recommended to use.
 *
 *  Compute the linear transformation operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdScaleOpForward(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Compute the linear transformation operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] alpha_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] alpha
 *    Input. An MLU address pointing to input data.
 *  @param[in] beta_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] beta
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
cnmlStatus_t cnmlComputeNdScaleOpForward_V2(cnmlBaseOp_t op,
                                            cnmlTensor_t input_tensor,
                                            void *input,
                                            cnmlTensor_t alpha_tensor,
                                            void *alpha,
                                            cnmlTensor_t beta_tensor,
                                            void *beta,
                                            cnmlTensor_t output_tensor,
                                            void *output,
                                            cnrtQueue_t queue,
                                            void *extra);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeScaleOpForwardUltra_V4 is recommended to use.
 *
 *  Compute the linear transformation operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  An operator pointer.
 *  @param[in] input
 *    Input.  Pointing to input tensor.
 *  @param[in] alpha
 *    Input.  Coefficients of linear transformation.
 *  @param[in] beta
 *    Input.   Bias of linear transformation.
 *  @param[in] output
 *    Input.  Pointing to output tensor.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree
 *    of data parallelism and device affinity of runtime.
 *  @param[in] stream
 *    Input.  Pointing to computation stream.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeScaleOpForwardUltra_V3(cnmlBaseOp_t op,
                                  void *input,
                                  void *alpha,
                                  void *beta,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  **Description**
 *
 *  Compute the linear transformation operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] alpha_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] alpha
 *    Input. An MLU address pointing to input data.
 *  @param[in] beta_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] beta
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeScaleOpForwardUltra_V4(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor,
                                                            void *input,
                                                            cnmlTensor_t alpha_tensor,
                                                            void *alpha,
                                                            cnmlTensor_t beta_tensor,
                                                            void *beta,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/*  scale operation end  */

/* concat operation start */
/*!
 *  @struct cnmlConcatOpParam
 *  @brief A struct.
 *
 *  cnmlConcatOpParam is a structure describing the param parameter of concat operation, used to
 *  create concat operation. cnmlCreateConcatOpParam() is used to create an instance of
 *  cnmlConcatOpParam_t. cnmlDestroyConcatOpParam() is used to destroy an instance of
 *  cnmlConcatOpParam_t. */
struct cnmlConcatOpParam;
/*! ``cnmlConcatOpParam_t`` is a pointer to ``cnmlConcatOpParam`` which is a
    structure holding the description of a concat operation param. */
typedef struct cnmlConcatOpParam *cnmlConcatOpParam_t;

/*!
 *  @brief A function.
 *
 *  Create parameters of the splice operator, which include the number of input tensor and
 *  output tensor, but the number of output tensor must be 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input and output.  Pointing to a struct of splice operator parameters.
 *  @param[in] input_num
 *    Input.  The number of input tensor.
 *  @param[in] output_num
 *    Input.  The number of output tensor must be 1.
 *  @param[in] mode
 *    Input.  Specifying the splicing dimensions, and the value can be: CNML_CONCAT_FEAT,
 *    CNML_CONCAT_BATCH, CNML_CONCAT_HEIGHT, and CNML_CONCAT_WIDTH.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConcatOpParam(cnmlConcatOpParam_t *param,
                                                  int input_num,
                                                  int output_num,
                                                  cnmlDimension_t concat_mode);
/*!
 *  @brief A function.
 *
 *  Release the struct of splice operator parameters.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input.  Pointing to a struct of splice operator parameters.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyConcatOpParam(cnmlConcatOpParam_t *param);
/*!
 *  @brief A function.
 *
 *  Create a splice operator, which can splice multiple tensors into one tensor.
 *
 *  **Formula**
 *
 *    if dim =N:
 *
 *    Output[sum(n1, n2, ..., nn), h, w, c] = input([n1, h, w, c], [n2, h, w, c], ..., [nn, h, w,
 *    c])
 *
 *    if dim = C:
 *
 *    Output[n, h, w, sum(c1, c2, ..., cn)] = input([n, h, w, c1], [n, h, w, c2], ..., [n, h, w,
 *    cn])
 *
 *    if dim = H:
 *
 *    Output[n, sum(h1, h2, ..., hh), w, c] = input([n, h1, w, c], [n, h2, w, c], ..., [n, hn, w,
 *    c])
 *
 *    if dim = W:
 *
 *    Output[n, h, sum(w1, w2, ..., wn), c] = input([n, h1, w1, c], [n, h2, w2, c], ..., [n, hn, wn,
 *    c])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *   For best practices and higher performance, it is recommended that you set
 *   either the N dimension or C dimension of the input and output tensors with
 *   the following conditions:
 *
 *    - All of the following conditions are met in N dimension:
 *
 *    1. The input and output data is in the middle layer of the network.
 *
 *    2. data_size_input = ni * hi*wI *ci
 *
 *    3. data_size_out = no * ho * wo *co
 *
 *    4. The value of ``data_size_out`` and ``data_size_input`` are multiple of 64.
 *
 *    - Set the size of the C-dimension is greater than 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] outputs_ptr
 *    Output. A 4-dimensional MLU tensor.
 *  @param[in] op
 *    Input.  Pointing to an operator address.
 *  @param[in] param
 *    Input.  Pointing to a struct address of operator parameters.
 *  @param[in] inputs_ptr
 *    Input.  A 4-dimensional MLU tensor.
 *  @param[in] intput_num
 *    Input.  The number of input tensor.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateConcatOp(cnmlBaseOp_t *op,
                                             cnmlConcatOpParam_t param,
                                             cnmlTensor_t *input_tensors,
                                             int input_num,
                                             cnmlTensor_t *output_tensors,
                                             int output_num);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeConcatOpForward_V4 is recommended to use.
 *
 *  Compute the splice operator.
 *
 *  **Formula**
 *
 *    if dim =N:
 *
 *    Output[sum(n1, n2, ..., nn), h, w, c] = input([n1, h, w, c], [n2, h, w, c], ..., [nn, h, w,
 *    c])
 *
 *    if dim = C:
 *    Output[n, h, w, sum(c1, c2, ..., cn)] = input([n, h, w, c1], [n, h, w, c2], ..., [n, h, w,
 *    cn])
 *
 *    if dim = H:
 *
 *    Output[n, sum(h1, h2, ..., hh), w, c] = input([n, h1, w, c], [n, h2, w, c], ..., [n, hn, w,
 *    c])
 *
 *    if dim = W:
 *
 *    Output[n, h, sum(w1, w2, ..., wn), c] = input([n, h1, w1, c], [n, h2, w2, c], ..., [n, hn, wn,
 *    c])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  Pointing to an operator address.
 *  @param[in] inputs
 *    Input.  The address of input tensor data.
 *  @param[in] intput_num
 *    Input.  The number of input tensor.
 *  @param[in] outputs
 *    Input.  The address of output tensor data.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of
 *    data parallelism and device affinity of runtime.
 *  @param[in] stream
 *    Input.  A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConcatOpForward_V3(cnmlBaseOp_t op,
                                                        void *inputs[],
                                                        int input_num,
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the splice operator.
 *
 *  **Formula**
 *
 *    if dim =N:
 *
 *    Output[sum(n1, n2, ..., nn), h, w, c] = input([n1, h, w, c], [n2, h, w, c], ..., [nn, h, w,
 *    c])
 *
 *    if dim = C:
 *
 *    Output[n, h, w, sum(c1, c2, ..., cn)] = input([n, h, w, c1], [n, h, w, c2], ..., [n, h, w,
 *    cn])
 *
 *    if dim = H:
 *
 *    Output[n, sum(h1, h2, ..., hh), w, c] = input([n, h1, w, c], [n, h2, w, c], ..., [n, hn, w,
 *    c])
 *
 *    if dim = W:
 *
 *    Output[n, h, sum(w1, w2, ..., wn), c] = input([n, h1, w1, c], [n, h2, w2, c], ..., [n, hn, wn,
 *    c])
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *   For best practices and higher performance, it is recommended that you set
 *   either the N dimension or C dimension of the input and output tensors with
 *   the following conditions:
 *
 *    - All of the following conditions are met in N dimension:
 *
 *    1. The input and output data is in the middle layer of the network.
 *
 *    2. data_size_input = ni * hi*wI *ci
 *
 *    3. data_size_out = no * ho * wo *co
 *
 *    4. The value of ``data_size_out`` and ``data_size_input`` are multiple of 64.
 *
 *    - Set the size of the C-dimension is greater than 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  Pointing to an operator address.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input.  The address of input tensor data.
 *  @param[in] intput_num
 *    Input.  The number of input tensor.
 *  @param[in] output_tensors
 *    Input. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[in] outputs
 *    Input.  The address of output tensor data.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConcatOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensors[],
                                                        void *inputs[],
                                                        int input_num,
                                                        cnmlTensor_t output_tensors[],
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/*!
 *  @brief A function.
 *
 *  Create an NdConcat operator according to base operator pointers given by users.
 *  After creating a pointer pointing to base operator address, operation parameters
 *  of the NdConcat operator, input and output Tensor,  pass them into the fucntion
 *  to create an NdConcat operator.
 *
 *  Dim starts from 0.
 *
 *  Output_num must be 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] dim
 *    Input.  Specifying the dimension of concat operation.
 *  @param[in] inputs
 *    Input.  A tensor array, each element is a n-dimensional MLU tensor, supporting data of float16
 * type.
 *  @param[in] intput_num
 *    Input.  The size of inputs array.
 *  @param[in] outputs
 *    Input.  A tensor array, each element is a n-dimensional MLU tensor, supporting data of float16
 * type.
 *  @param[in] output_num
 *    Input.  The size of outputs array.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdConcatOp(cnmlBaseOp_t *op,
                                               int dim,
                                               cnmlTensor_t *input_tensors,
                                               int input_num,
                                               cnmlTensor_t *output_tensors,
                                               int output_num);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdConcatOpForward_V2 is recommended to use.
 *
 *  Compute the operator specified by users on the MLU.
 *  After creating an Ndconcat operator, input, output, and computation stream,
 *  pass them into the function to compute the Ndconcat operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] outputs
 *    Output. A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] intput_num
 *    Input.  The number of elements in the inputs array.
 *  @param[in] output_num
 *    Input.  The number of elements in the outputs array.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of data
 *    parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input.  A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdConcatOpForward(cnmlBaseOp_t op,
                                                       void *inputs[],
                                                       int input_num,
                                                       void *outputs[],
                                                       int output_num,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the operator specified by users on the MLU.
 *  After creating an Ndconcat operator, input, output, and computation stream,
 *  pass them into the function to compute the Ndconcat operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] intput_num
 *    Input.  The number of elements in the inputs array.
 *  @param[in] output_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] outputs
 *    Output. A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] output_num
 *    Input.  The number of elements in the outputs array.
 *  @param[in] queue
 *    Input.  A computation stream pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdConcatOpForward_V2(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensors[],
                                                          void *inputs[],
                                                          int input_num,
                                                          cnmlTensor_t output_tensors[],
                                                          void *outputs[],
                                                          int output_num,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/*  concat operation end  */

/* split operation start */
/*!
 *  @struct cnmlSplitOpParam
 *  @brief A struct.
 *
 *  cnmlSplitOpParam is a structure describing the param parameter of split operation, used to
 *  create split operation. cnmlCreateSplitOpParam() is used to create an instance of
 *  cnmlSplitOpParam_t. cnmlDestroySplitOpParam() is used to destroy an instance of
 *  cnmlSplitOpParam_t. */
struct cnmlSplitOpParam;
/*! ``cnmlSplitOpParam_t`` is a pointer to ``cnmlSplitOpParam`` which is a
    structure holding the description of a split operation param. */
typedef struct cnmlSplitOpParam *cnmlSplitOpParam_t;
/*!
 *  @brief A function.
 *
 *  Create a parameter struct of the split operator, and the number of input tensor in the parameter
 *  must be 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the parameter struct.
 *  @param[in] intput_num
 *    Input.  The number of input tensor must be 1.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @param[in] mode
 *    Input.  Specifying the splitting mode: CNML_SPLIT_FEAT, CNML_SPLIT_BATCH, CNML_SPLIT_HEIGHT,
 *    and CNML_SPLIT_WIDTH.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSplitOpParam(cnmlSplitOpParam_t *param,
                                                 int input_num,
                                                 int output_num,
                                                 cnmlDimension_t split_mode);

/*!
 *  @brief A function.
 *
 *  Release the parameter struct of the split operators.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroySplitOpParam(cnmlSplitOpParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create a split operator.
 *
 *  **Formula**
 *
 *    if dim =N:
 *
 *    Output split_num * [n / split_num, h, w, c] = input[n, h, w, c]
 *
 *    if dim = C:
 *
 *    Output split_num * [n, h, w, c / split_num] = input[n, h, w, c]
 *
 *    if dim = H:
 *
 *    Output split_num * [n, h / split_num, w, c] = input[n, h, w, c]
 *
 *    if dim = W:
 *
 *    Output split_num * [n, h, w / split_num, c] = input[n, h, w, c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *   For best practices and higher performance, it is recommended that you set
 *   either the N dimension or C dimension of the input and output tensors with
 *   the following conditions:
 *
 *    - All of the following conditions are met in N dimension:
 *
 *    1. The input and output data is in the middle layer of the network.
 *
 *    2. data_size_input = ni * hi*wI *ci
 *
 *    3. data_size_out = no * ho * wo *co
 *
 *    4. The value of ``data_size_out`` and ``data_size_input`` are multiple of 64.
 *
 *    - Set the size of the C-dimension is greater than 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. Pointing to the split operator.
 *  @param[in] param
 *    Input. Parameters of the split operator.
 *  @param[in] input_ptr
 *    Input.  A 4-dimensional Tensor, supporting data type od float16.
 *  @param[in] input_num
 *    Input.  The number of input tensor must be 1.
 *  @param[in] output_ptr
 *    Input.  A 4-dimensional Tensor, supporting data type od float16.
 *  @param[in] output_num
 *    Input.  The number of output tensor must be 1.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSplitOp(cnmlBaseOp_t *op,
                                            cnmlSplitOpParam_t param,
                                            cnmlTensor_t *input_tensors,
                                            int input_num,
                                            cnmlTensor_t *output_tensors,
                                            int output_num);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSplitOpForward_V4 is recommended to use.
 *
 *  Compute the split operator.
 *
 *  **Formula**
 *
 *    if dim =N:
 *
 *    Output split_num * [n / split_num, h, w, c] = input[n, h, w, c]
 *
 *    if dim = C:
 *
 *    Output split_num * [n, h, w, c / split_num] = input[n, h, w, c]
 *
 *    if dim = H:
 *
 *    Output split_num * [n, h / split_num, w, c] = input[n, h, w, c]
 *
 *    if dim = W:
 *
 *    Output split_num * [n, h, w / split_num, c] = input[n, h, w, c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32, int32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. Pointing to an operator address.
 *  @param[in] inputs
 *    Input. The address of input tensor data.
 *  @param[in] intput_num
 *    Input.  The number of input tensor.
 *  @param[in] outputs
 *    Input. The address of output tensor data.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of data parallelism
 *    and device affinity of runtime.
 *  @param[in] stream
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSplitOpForward_V3(cnmlBaseOp_t op,
                                                       void *inputs[],
                                                       int input_num,
                                                       void *outputs[],
                                                       int output_num,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the split operator.
 *
 *  **Formula**
 *
 *    if dim = N:
 *
 *    Output split_num * [n / split_num, h, w, c] = input[n, h, w, c]
 *
 *    if dim = C:
 *
 *    Output split_num * [n, h, w, c / split_num] = input[n, h, w, c]
 *
 *    if dim = H:
 *
 *    Output split_num * [n, h / split_num, w, c] = input[n, h, w, c]
 *
 *    if dim = W:
 *
 *    Output split_num * [n, h, w / split_num, c] = input[n, h, w, c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     input: int8, int16, float16, float32, int32
 *
 *     output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     Unlimited
 *
 *  **Performance Optimization**
 *
 *   For best practices and higher performance, it is recommended that you set
 *   either the N dimension or C dimension of the input and output tensors with
 *   the following conditions:
 *
 *    - All of the following conditions are met in N dimension:
 *
 *    1. The input and output data is in the middle layer of the network.
 *
 *    2. data_size_input = ni * hi*wI *ci
 *
 *    3. data_size_out = no * ho * wo *co
 *
 *    4. The value of ``data_size_out`` and ``data_size_input`` are multiple of 64.
 *
 *    - Set the size of the C-dimension is greater than 64.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input. MLU addresses pointing to inputs data.
 *  @param[in] intput_num
 *    Input.  The number of input tensor.
 *  @param[in] output_tensors
 *    Input.  Output MLU tensors pointer. Pass NULL if not used.
 *  @param[out] outputs
 *    Output. MLU addresses pointing to output position.
 *  @param[in] output_num
 *    Input.  The number of output tensor.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSplitOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensors[],
                                                       void *inputs[],
                                                       int input_num,
                                                       cnmlTensor_t output_tensors[],
                                                       void *outputs[],
                                                       int output_num,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/*!
 *  @brief A function.
 *
 *  Create an NdSplit operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, NdSplit operator
 *  operation parameters, and input and output Tensor, pass them into the fucntion
 *  to create an NdSplit operator.
 *
 *  dim starts from 0.
 *
 *  input_num must be 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to base operators address.
 *  @param[out] outputs
 *    Output.  A tensor array, and each element is a n-dimensional MLU tensor,
 *    supporting data of float16 type.
 *  @param[in] dim
 *    Input.  Specifying dimensions of Split operation.
 *  @param[in] inputs
 *    Input.  A tensor array, and each element is a n-dimensional MLU tensor,
 *    supporting data of float16 type.
 *  @param[in] intput_num
 *    Input.  The size of inputs array.
 *  @param[in] output_num
 *    Input.  The size of outputs array.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdSplitOp(cnmlBaseOp_t *op,
                                              int dim,
                                              cnmlTensor_t *input_tensors,
                                              int input_num,
                                              cnmlTensor_t *output_tensors,
                                              int output_num);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdSplitOpForward_V2 is recommended to use.
 *
 *  Compute the operator specified by users on the MLU.
 *
 *  After creating an NdSplit operator, input, output, and computation stream, pass them into
 *  the function to compute the NdSplit operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  A pointer which points to base operators.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] intput_num
 *    Input.  The number of elements in the inputs array.
 *  @param[in] outputs
 *    Input.  A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] output_num
 *    Input.  The number of elements in the outputs array.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of data
 *    parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdSplitOpForward(cnmlBaseOp_t op,
                                                      void *inputs[],
                                                      int input_num,
                                                      void *outputs[],
                                                      int output_num,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the operator specified by users on the MLU.
 *
 *  After creating an NdSplit operator, input, output, and computation stream, pass them into
 *  the function to compute the NdSplit operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] intput_num
 *    Input.  The number of elements in the inputs array.
 *  @param[in] output_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] outputs
 *    Output. A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] output_num
 *    Input.  The number of elements in the outputs array.
 *  @param[in] queue
 *    Input.  A computation stream pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdSplitOpForward_V2(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensors[],
                                                         void *inputs[],
                                                         int input_num,
                                                         cnmlTensor_t output_tensors[],
                                                         void *outputs[],
                                                         int output_num,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* slice operation end  */

/* shuffle channel start */
/*!
 *  @brief A function.
 *
 *  Create a shuffle operator to adjust data on channel c to the data evenly distribute on channel
 *  c.
 *
 *  **Formula**
 *
 *    Shuffle the channels according to the input param Group:
 *
 *    N = C / Group
 *
 *    C_out[id] = C_in[id % N * Group + id / N], id in {0, 1, 2, ..., C-1}
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input and output DataType are same
 *
 *      input: float16, float32
 *
 *      compute: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  Pointing to the operator.
 *  @param[in] inputs_ptr
 *    Input.  Input data address.
 *  @param[in] outputs_ptr
 *    Input.  Output data address.
 *  @param[in] group
 *    Input.  A shuffle parameter, and the parameter should be able to be divided by the width
 *    of channel c (c_size%group == 0).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateShuffleChannelOp(cnmlBaseOp_t *op,
                                                     cnmlTensor_t *input_tensors,
                                                     cnmlTensor_t *output_tensors,
                                                     int group);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeShuffleChannelOpForward_V4 is recommended to use.
 *
 *  Compute the shuffle operator.
 *
 *  **Formula**
 *
 *    Shuffle the channels according to the input param Group:
 *
 *    N = C / Group
 *
 *    C_out[id] = C_in[id % N * Group + id / N], id in {0, 1, 2, ..., C-1}
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input and output DataType are same
 *
 *      input: float16, float32
 *
 *      compute: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  Pointing to an operator address.
 *  @param[in] inputs
 *    Input.  An address of input data
 *  @param[in] outputs
 *    Input.  An address of output data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to a struct address of runtime parameters.
 *  @param[in] stream
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeShuffleChannelOpForward_V3(cnmlBaseOp_t op,
                                      void *inputs[],
                                      void *outputs[],
                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the shuffle operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] output_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] outputs
 *    Output. A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] queue
 *    Input.  A computation stream pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeShuffleChannelOpForward_V4(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);
/* shuffle channel operation end  */

/* not operation start */
/*!
 *  @brief A function.
 *
 *  Perform element-wise not operation on input tensor.
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Formula**
 *
 *    output[n c h w] = ! input[n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, bool
 *
 *
 *    **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to the operator.
 *  @param[in] input_Tensor
 *    Input.  Input tensor.
 *  @param[in] output_tensor
 *    Input.  Output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNotOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNotOpForward_V4 is recommended to use.
 *
 *  Compute the not operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input.  A pointer pointing to the operator.
 *  @param[in] input
 *    Input.  Pointing to a pointer of input data.
 *  @param[in] output
 *    Input.  A pointer pointing to output data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to a struct address of runtime parameters.
 *  @param[in] stream
 *    Input.  A computation queue  pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNotOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the not operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNotOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* not operation end */

/* and operation start */
/*!
 *  @brief A function.
 *
 *  Perform element-wise And operation on the two Tensors.
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0 && (b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAndOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor_1,
                                          cnmlTensor_t input_tensor_2,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Compute the And operator specified by users on the MLU.
 *
 *  After creating an And operator, input, output, and computation stream,
 *  pass them into the function to compute the And operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0 && (b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAndOpForward_V4
 *  is recommended to use.
 *
 *  @param[out] output
 *    Output.  An MLU address pointing to output position.
 *  @param[in] op
 *    Input.  A pointer which points to base operators.
 *  @param[in] input_1
 *    Input.  An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input.  An MLU address pointing to input data 2.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of
 *    data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAndOpForward_V3(cnmlBaseOp_t op,
                                                     void *input_1,
                                                     void *input_2,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the And operator specified by users on the MLU.
 *
 *  After creating an And operator, input, output, and computation stream,
 *  pass them into the function to compute the And operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. First MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. Second MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAndOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor1,
                                                     void *input_1,
                                                     cnmlTensor_t input_tensor2,
                                                     void *input_2,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* and operation end */

/* cycleand operation start */
/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as input_tensor_1
 *  and then perform element-wise And operation.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0 && (b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input.  A four-dimensional MLU input tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input.  A four-dimensional MLU input tensor, the shape of which is [1, c, 1, 1],
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A four-dimensional MLU output tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCycleAndOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as input_tensor_1
 *  and then perform element-wise And operation.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleAndOp(cnmlBaseOp_t *op,
                                                 int dim,
                                                 cnmlTensor_t input_tensor_1,
                                                 cnmlTensor_t input_tensor_2,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleAndOpForward_V4 is recommended to use.
 *
 *  Compute the CycleAnd operator specified by users on the MLU.
 *
 *  After creating a CycleAnd operator, input, output, and computation stream, pass them into the
 *  function to compute the CycleAnd operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0 && (b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output.  An MLU address pointing to output position.
 *  @param[in] op
 *    Input.  A pointer which points to base operators.
 *  @param[in] input_1
 *    Input.  An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input.  An MLU address pointing to input data 2.
 *  @param[in] compute_forw_param
 *    Input.  A pointer pointing to the struct address, which records the degree of data
 *    parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator  pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCycleAndOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleAnd operator specified by users on the MLU.
 *
 *  After creating a CycleAnd operator, input, output, and computation queue, pass them into the
 *  function to compute the CycleAnd operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCycleAndOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleAnd operator specified by users on the MLU.
 *
 *  After creating a NdCycleAnd operator, input, output, and computation queue, pass them into the
 *  function to compute the NdCycleAnd operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleAndOpForward(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* cycleand operation end */

/* cyclexor operation start */

/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as
 *  input_tensor_1 and then perform element-wise Xor operation.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] != 0 && b[1 c 1 1] == 0) || (a[n c h w] == 0 && b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape
 *    of which is [n, c, h, w], supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of
 *    which is [1, c, 1, 1], supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor,
 *    the shape of which is [n, c, h, w], supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCycleXorOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as
 *  input_tensor_1 and then perform element-wise Xor operation.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleXorOp(cnmlBaseOp_t *op,
                                                 int dim,
                                                 cnmlTensor_t input_tensor_1,
                                                 cnmlTensor_t input_tensor_2,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleXorOpForward_V4 is recommended to use.
 *
 *  Compute the CycleXor operator specified by users on the MLU.
 *
 *  After creating a CycleXor operator, input, output, and computation stream,
 *  pass them into the function to compute the CycleXor operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] != 0 && b[1 c 1 1] == 0) || (a[n c h w] == 0 && b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleXorOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleXor operator specified by users on the MLU.
 *
 *  After creating a CycleXor operator, input, output, and computation stream,
 *  pass them into the function to compute the CycleXor operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleXorOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the CycleXor operator specified by users on the MLU.
 *
 *  After creating a CycleXor operator, input, output, and computation stream,
 *  pass them into the function to compute the CycleXor operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleXorOpForward(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* cyclexor operation end */

/* xor operation start */
/*!
 *  @brief A function.
 *
 *  Perform element-wise xor operation on two Tensors.
 *
 *  The shapes of two input and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = ((a[n c h w] !=0 && b[n c h w] == 0) || (a[n c h w] == 0 && b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address..
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateXorOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor_1,
                                          cnmlTensor_t input_tensor_2,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeXorOpForward_V4 is recommended to use.
 *
 *  Compute the Xor operator specified by users on the MLU.
 *
 *  After creating an  Xor operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the Xor operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = ((a[n c h w] !=0 && b[n c h w] == 0) || (a[n c h w] == 0 && b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeXorOpForward_V3(cnmlBaseOp_t op,
                                                     void *input_1,
                                                     void *input_2,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/* xor operation end */
/* DivSqrtDim operation start */
/*!
 *  @brief A function.
 *
 *  Compute the Xor operator specified by users on the MLU.
 *
 *  **Supports MLU270.**
 *
 *  **Formula**
 *
 *    output[n c h w] = input[n c h w] / sqrt(C)    (C is channel dimension size)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType float16, float32
 *
 *      outputDataType float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 130400
 *
 *  After creating an  Xor operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the Xor operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeXorOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor1,
                                                     void *input_1,
                                                     cnmlTensor_t input_tensor2,
                                                     void *input_2,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* xor operation end */

/* DivSqrtDim operation start */
/*!
 *  @brief A function.
 *
 *  Creates a DivSqrtDim operator that rescales the input tensor by
 *  taking the square root of the C dimension size of the input tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the DivSqrtDim operator you have created.
 *  @param[in] input
 *    Input.  A 4-D MLU input tensor. The shape of the tensor is [n, h, w, c].
 *    You need to declare a tensor using the cnmlTensor_t datatype and
 *    create the tensor using the cnmlCreateTensor() API.
 *  @param[in] output
 *    Input.  The descriptor of the 4-D output tensor.
 *    The shape of the tensor is [n, h, w, c]. You need to declare a tensor
 *    using the cnmlTensor_t datatype and create the tensor using the
 *    cnmlCreateTensor() API.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The size of C dimension should be greater than 0.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDivSqrtDimOp(cnmlBaseOp_t *op,
                                                 cnmlTensor_t input_tensor,
                                                 cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeDivSqrtDimOpForward_V2 is recommended to use.
 *
 *  Rescales the input tensor by taking the square root of the C
 *  dimension size of the input tensor on MLU.
 *
 *  **Supports MLU270.**
 *
 *  **Formula**
 *
 *    output[n c h w] = input[n c h w] / sqrt(C)    (C is channel dimension size)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      inputDataType float16, float32
 *
 *      outputDataType float16, float32, int16, int8
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 130400
 *
 *  @param[out] output
 *    Output. A pointer to output data after the DivSqrtDim operator is applied.
 *  @param[in] op
 *    Input. A pointer to the DivSqrtDim operator you have created.
 *  @param[in] input
 *    Input. A pointer to the input data you want to rescale.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address that records the data parallelism
 *    and device affinity for runtime.
 *  @param[in] queue
 *    Input. A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDARG
 *    One of the following conditions are met:
 *    - Operator pointer is NULL.
 *    - Output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDivSqrtDimOpForward(cnmlBaseOp_t op,
                                                         void *input,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Rescales the input tensor by taking the square root of the C
 *  dimension size of the input tensor on MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDivSqrtDimOpForward_V2(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor,
                                                            void *input,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/*  DivSqrtDim operation end  */

/* cycleor operation start */

/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as input_tensor_1,
 *  and then perform element-wise or operation.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0  || (b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape of which is [1, c, 1, 1],
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape of which is [n, c, h, w],
 *    supporting data of float16 type
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleOrOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input_tensor_1,
                                              cnmlTensor_t input_tensor_2,
                                              cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Extend the shape of input_tensor_2 to the same shape as input_tensor_1,
 *  and then perform element-wise or operation.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleOrOp(cnmlBaseOp_t *op,
                                                int dim,
                                                cnmlTensor_t input_tensor_1,
                                                cnmlTensor_t input_tensor_2,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleOrOpForward_V4 is recommended to use.
 *
 *  Compute the CycleOr operator specified by users on the MLU.
 *
 *  After creating a CycleOr operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the CycleOr operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0  || (b[1 c 1 1] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleOrOpForward_V3(cnmlBaseOp_t op,
                                                         void *input_1,
                                                         void *input_2,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleOr operator specified by users on the MLU.
 *
 *  After creating a CycleOr operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the CycleOr operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleOrOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleOr operator specified by users on the MLU.
 *
 *  After creating a NdCycleOr operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the NdCycleOr operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleOrOpForward(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor1,
                                                        void *input_1,
                                                        cnmlTensor_t input_tensor2,
                                                        void *input_2,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);

/* cycleor operation end */

/* or operation start */
/*!
 *  @brief A function.
 *
 *  Perform element-wise Or operation on two Tensors.
 *
 *  The shapes of two input tensor should be the same;
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0  || (b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateOrOp(cnmlBaseOp_t *op,
                                         cnmlTensor_t input_tensor_1,
                                         cnmlTensor_t input_tensor_2,
                                         cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeOrOpForward_V4 is recommended to use.
 *
 *  Compute the Or operator specified by users on the MLU.
 *
 *  After creating an Or operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the Or operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = (a[n c h w] !=0  || (b[n c h w] != 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeOrOpForward_V3(cnmlBaseOp_t op,
                                                    void *input_1,
                                                    void *input_2,
                                                    void *output,
                                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the Or operator specified by users on the MLU.
 *
 *  After creating an Or operator, input, output, runtime parameters,
 *  and computation queue, pass them into the function to compute the Or operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeOrOpForward_V4(cnmlBaseOp_t op,
                                                    cnmlTensor_t input_tensor1,
                                                    void *input_1,
                                                    cnmlTensor_t input_tensor2,
                                                    void *input_2,
                                                    cnmlTensor_t output_tensor,
                                                    void *output,
                                                    cnrtQueue_t queue,
                                                    void *extra);
/* or operation end */

/* cycleadd operation start */
/*!
 *  @brief A function.
 *
 *   Create a CycleAdd operator according to base operator pointers given by users.
 *
 *   Transmit two input tensors and one output tensor into the function
 *   to create a CycleAdd operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] + b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w] .
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleAddOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/* ndcycleadd operation start */
/*!
 *  @brief A function.
 *
 *   Create a NdCycleAdd operator according to base operator pointers given by users.
 *
 *   Transmit two input tensors and one output tensor into the function
 *   to create a NdCycleAdd operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleAddOp(cnmlBaseOp_t *op,
                                                 int dim,
                                                 cnmlTensor_t input_tensor_1,
                                                 cnmlTensor_t input_tensor_2,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleAddOpForward_V4 is recommended to use.
 *
 *  Compute the CycleAdd operator on the CPU.
 *
 *  Transmit the created CycleAdd operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleAdd operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] + b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleAddOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleAdd operator on the MLU.
 *
 *  Transmit the created CycleAdd operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleAdd operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleAddOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleAdd operator on the MLU.
 *
 *  Transmit the created CycleAdd operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleAdd operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleAddOpForward(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* cycleadd operation end */

/* cyclesub operation start */
/*!
 *  @brief A function.
 *
 *  Create a CycleSub operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a CycleSub operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] - b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleSubOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Create a NdCycleSub operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a NdCycleSub operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleSubOp(cnmlBaseOp_t *op,
                                                 int dim,
                                                 cnmlTensor_t input_tensor_1,
                                                 cnmlTensor_t input_tensor_2,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleSubOpForward_V4 is recommended to use.
 *
 *  Compute the CycleSub operator on the MLU.
 *
 *  Transmit the created CycleSub operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleSub operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] - b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleSubOpForward_V3(cnmlBaseOp_t op,
                                                          void *input_1,
                                                          void *input_2,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the CycleSub operator on the MLU.
 *
 *  Transmit the created CycleSub operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleSub operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleSubOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleSub operator on the MLU.
 *
 *  Transmit the created NdCycleSub operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the NdCycleSub operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleSubOpForward(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* cyclesub operation end */

/* cyclemult operation start */
/*!
 *  @brief A function.
 *
 *  Create a CycleMult operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the
 *  function to create a CycleMult operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] * b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleMultOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor_1,
                                                cnmlTensor_t input_tensor_2,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create a NdCycleMult operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the
 *  function to create a NdCycleMult operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleMultOp(cnmlBaseOp_t *op,
                                                  int dim,
                                                  cnmlTensor_t input_tensor_1,
                                                  cnmlTensor_t input_tensor_2,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleMultOpForward_V4 is recommended to use.
 *
 *  Compute the CycleMult operator on the MLU.
 *
 *  Transmit the created CycleMult operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleMult operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] * b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleMultOpForward_V3(cnmlBaseOp_t op,
                                 void *input_1,
                                 void *input_2,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the CycleMult operator on the MLU.
 *
 *  Transmit the created CycleMult operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleMult operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] * b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      DataType = float16 : c <= 65536
 *
 *      DataType = float32 : c <= 32768
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleMultOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor1,
                                                           void *input_1,
                                                           cnmlTensor_t input_tensor2,
                                                           void *input_2,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleMult operator on the MLU.
 *
 *  Transmit the created NdCycleMult operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleMult operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleMultOpForward(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/* cyclemult operation end */

/* cycle equal operation start */
/*!
 *  @brief A function.
 *
 *  Create a CycleEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a CycleEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] == b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleEqualOp(cnmlBaseOp_t *op,
                                                 cnmlTensor_t input_tensor_1,
                                                 cnmlTensor_t input_tensor_2,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create a NdCycleEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a NdCycleEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleEqualOp(cnmlBaseOp_t *op,
                                                   int dim,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleEqualOpForward_V4 is recommended to use.
 *
 *  Compute the CycleEqual operator on the CPU.
 *
 *  Transmit the created CycleEqual operator, input tensor,
 *  input address, output tensor, and output address to the
 *  function to compute the CycleEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] == b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleEqualOpForward_V3(cnmlBaseOp_t op,
                                  void *input_1,
                                  void *input_2,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleEqual operator on the MLU.
 *
 *  Transmit the created CycleEqual operator, input tensor,
 *  input address, output tensor, and output address to the
 *  function to compute the CycleEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] == b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleEqualOpForward_V4(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor1,
                                                            void *input_1,
                                                            cnmlTensor_t input_tensor2,
                                                            void *input_2,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleEqual operator on the MLU.
 *
 *  Transmit the created NdCycleEqual operator, input tensor,
 *  input address, output tensor, and output address to the
 *  function to compute the NdCycleEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleEqualOpForward(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor1,
                                                           void *input_1,
                                                           cnmlTensor_t input_tensor2,
                                                           void *input_2,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/* cycle equal operation end */

/* cycle n equal operation start */
/*!
 *  @brief A function.
 *
 *  Create a CycleNEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a CycleNEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] != b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleNEqualOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t input_tensor_1,
                                                  cnmlTensor_t input_tensor_2,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create a NdCycleNEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function
 *  to create a NdCycleNEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleNEqualOp(cnmlBaseOp_t *op,
                                                    int dim,
                                                    cnmlTensor_t input_tensor_1,
                                                    cnmlTensor_t input_tensor_2,
                                                    cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleNEqualOpForward_V4 is recommended to use.
 *
 *  Compute the CycleNEqual operator on the MLU.
 *
 *  Transmit the created CycleNEqual operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleNEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] != b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleNEqualOpForward_V3(cnmlBaseOp_t op,
                                   void *input_1,
                                   void *input_2,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the CycleNEqual operator on the MLU.
 *
 *  Transmit the created CycleNEqual operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the CycleNEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCycleNEqualOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor1,
                                                             void *input_1,
                                                             cnmlTensor_t input_tensor2,
                                                             void *input_2,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleNEqual operator on the MLU.
 *
 *  Transmit the created NdCycleNEqual operator, input tensor,
 *  input address, output tensor, and output address to
 *  the function to compute the NdCycleNEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleNEqualOpForward(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor1,
                                                            void *input_1,
                                                            cnmlTensor_t input_tensor2,
                                                            void *input_2,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/* cycle n equal operation end */

/* cycle less equal operation start */
/*!
 *  @brief A function.
 *
 *  Create a CycleLessEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function to
 *  create a CycleLessEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] <= b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. The input_tensor_1 is four-dimensional tensors,
 *    in which the shape of input_tensor_1 is [n, c, h, w].
 *  @param[in] input_tensor_2
 *    Input. The input_tensor_2 is four-dimensional tensors,
 *    in which the shape of input_tensor_2 is [1, c, 1, 1].
 *  @param[in] output_tensor
 *    Input. The output_tensor is a four-dimensional tensor,
 *    the shape of which is [n, c, h, w].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleLessEqualOp(cnmlBaseOp_t *op,
                                                     cnmlTensor_t input_tensor_1,
                                                     cnmlTensor_t input_tensor_2,
                                                     cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Create a NdCycleLessEqual operator according to base operator pointers given by users.
 *
 *  Transmit two input tensors and one output tensor into the function to
 *  create a NdCycleLessEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleLessEqualOp(cnmlBaseOp_t *op,
                                                       int dim,
                                                       cnmlTensor_t input_tensor_1,
                                                       cnmlTensor_t input_tensor_2,
                                                       cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleLessEqualOpForward_V4 is recommended to use.
 *
 *  Compute the CycleLessEqual operator on the MLU.
 *
 *  Transmit the created CycleLessEqual operator, input tensor, input address,
 *  output tensor, and output address to the function to compute
 *  the CycleLessEqual operator.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] <= b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 the operator pointer is null.
 *    - Reason2 the output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleLessEqualOpForward_V3(cnmlBaseOp_t op,
                                      void *input_1,
                                      void *input_2,
                                      void *output,
                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                      cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the CycleLessEqual operator on the MLU.
 *
 *  Transmit the created CycleLessEqual operator, input tensor, input address,
 *  output tensor, and output address to the function to compute
 *  the CycleLessEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleLessEqualOpForward_V4(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor1,
                                                                void *input_1,
                                                                cnmlTensor_t input_tensor2,
                                                                void *input_2,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the NdCycleLessEqual operator on the MLU.
 *
 *  Transmit the created NdCycleLessEqual operator, input tensor, input address,
 *  output tensor, and output address to the function to compute
 *  the NdCycleLessEqual operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleLessEqualOpForward(cnmlBaseOp_t op,
                                                               cnmlTensor_t input_tensor1,
                                                               void *input_1,
                                                               cnmlTensor_t input_tensor2,
                                                               void *input_2,
                                                               cnmlTensor_t output_tensor,
                                                               void *output,
                                                               cnrtQueue_t queue,
                                                               void *extra);

/* cycle less equal operation end */

/* cycle less operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is less than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] < B[1][1][1][ci] )? 1:0
 *
 *  The shape of the four-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] < b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape is [n, h, w, c],
 *    supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, c],
 *    That is, the channel dimension of B is the same as that of A,
 *    and the remaining dimensions are 1, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional tensor, the shape is the same as that
 *    of the input tensor A, the data type is float16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleLessOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor_1,
                                                cnmlTensor_t input_tensor_2,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is less than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] < B[1][1][1][ci] )? 1:0
 *
 *  The shape of the four-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *    The channel dimension of input_2 is the same as that of input_1,
 *    and the remaining dimensions are 1.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *    Input. A four-dimensional tensor, the shape is the same as that
 *    of the input tensor A, the data type is float16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleLessOp(cnmlBaseOp_t *op,
                                                  int dim,
                                                  cnmlTensor_t input_tensor_1,
                                                  cnmlTensor_t input_tensor_2,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleLessOpForward_V4 is recommended to use.
 *
 *  Compare the size of the user-specified vector B and tensor A in each dimension.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] < b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleLessOpForward_V3(cnmlBaseOp_t op,
                                 void *input_1,
                                 void *input_2,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compare the size of the user-specified vector B and tensor A in each dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleLessOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor1,
                                                           void *input_1,
                                                           cnmlTensor_t input_tensor2,
                                                           void *input_2,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *  @brief A function.
 *
 *  Compare the size of the user-specified vector B and tensor A in each dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleLessOpForward(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor1,
                                                          void *input_1,
                                                          cnmlTensor_t input_tensor2,
                                                          void *input_2,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);

/* cycle less operation end */

/* cycle greater equal operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is greater than or equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] >= B[1][1][1][ci] )? 1: 0.
 *
 *  The shape of the four-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] >= b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor,
 *    the shape is [n, c, h, w], supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, c],
 *    That is, the channel dimension of B is the same as that of A,
 *    and the remaining dimensions are 1, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional tensor, the shape is the same as
 *    that of the input tensor A, the data type is float16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCycleGreaterEqualOp(cnmlBaseOp_t *op,
                                                        cnmlTensor_t input_tensor_1,
                                                        cnmlTensor_t input_tensor_2,
                                                        cnmlTensor_t output_tensor);

/* cycle nd greater equal operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is nd greater than or equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] >= B[1][1][1][ci] )? 1: 0.
 *
 *  The shape of the four-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *    The channel dimension of B is the same as that of A,
 *    and the remaining dimensions are 1.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleGreaterEqualOp(cnmlBaseOp_t *op,
                                                          int dim,
                                                          cnmlTensor_t input_tensor_1,
                                                          cnmlTensor_t input_tensor_2,
                                                          cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleGreaterEqualOpForward_V4 is recommended to use.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is greater than or equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] >= b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleGreaterEqualOpForward_V3(cnmlBaseOp_t op,
                                         void *input_1,
                                         void *input_2,
                                         void *output,
                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is greater than or equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleGreaterEqualOpForward_V4(cnmlBaseOp_t op,
                                                                   cnmlTensor_t input_tensor1,
                                                                   void *input_1,
                                                                   cnmlTensor_t input_tensor2,
                                                                   void *input_2,
                                                                   cnmlTensor_t output_tensor,
                                                                   void *output,
                                                                   cnrtQueue_t queue,
                                                                   void *extra);

/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is nd greater than or equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleGreaterEqualOpForward(cnmlBaseOp_t op,
                                                                  cnmlTensor_t input_tensor1,
                                                                  void *input_1,
                                                                  cnmlTensor_t input_tensor2,
                                                                  void *input_2,
                                                                  cnmlTensor_t output_tensor,
                                                                  void *output,
                                                                  cnrtQueue_t queue,
                                                                  void *extra);

/* cycle greater equal operation end */

/* cycle greater operation start */

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is greater than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] > B[1][1][1][ci] )? 1: 0.
 *
 *  The shape of the four-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] > b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor,
 *    the shape is [n, c, h, w], supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, c],
 *    That is, the channel dimension of B is the same as that of A,
 *    and the remaining dimensions are 1, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional tensor, the shape is the same as
 *    that of the input tensor A, the data type is float16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCycleGreaterOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the vector B and the tensor A in each dimension
 *  to find whether one is greater than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] > B[1][1][1][ci] )? 1: 0.
 *
 *  The shape of the n-dimensional tensor B must be [1, 1, 1, c].
 *
 *  That is, the channel dimension of B is the same as that of A,
 *  and the remaining dimensions are 1.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A multi-dimensional MLU input_1 tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A multi-dimensional MLU input_2 tensor, supporting data of float16 type.
 *    The channel dimension of B is the same as that of A,
 *    and the remaining dimensions are 1.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdCycleGreaterOp(cnmlBaseOp_t *op,
                                                     int dim,
                                                     cnmlTensor_t input_tensor_1,
                                                     cnmlTensor_t input_tensor_2,
                                                     cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCycleGreaterOpForward_V4 is recommended to use.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is greater than the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] > b[1 c 1 1]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c <= 131072
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeCycleGreaterOpForward_V3(cnmlBaseOp_t op,
                                    void *input_1,
                                    void *input_2,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is greater than the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeCycleGreaterOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified multi-dimensional tensor A and
 *  one-dimensional tensor B to find whether one is greater than the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdCycleGreaterOpForward(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor1,
                                                             void *input_1,
                                                             cnmlTensor_t input_tensor2,
                                                             void *input_2,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);

/* cycle greater operation end */

/* equal operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the tensor B and the tensor A in each position
 *  to find whether one is equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] == B[ni][hi][wi][ci] )? 1: 0.
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] == b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *    supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateEqualOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor_1,
                                            cnmlTensor_t input_tensor_2,
                                            cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeEqualOpForward_V4 is recommended to use.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] == b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] inputA
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] inputB
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeEqualOpForward_V3(cnmlBaseOp_t op,
                                                       void *inputA,
                                                       void *inputB,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_A
 *    Input. Input MLU tensor pointerA. Pass NULL if not used.
 *  @param[in] inputA
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor_B
 *    Input. Input MLU tensor pointerB. Pass NULL if not used.
 *  @param[in] inputB
 *    Input. MLU address pointing to inputB data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeEqualOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor_A,
                                                       void *inputA,
                                                       cnmlTensor_t input_tensor_B,
                                                       void *inputB,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* equal operation end */

/* not equal operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the tensor B and the tensor A in each position
 *  to find whether one is not equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] != B[ni][hi][wi][ci] )? 1: 0.
 *
 *  The shapes of two inputs and output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] != b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNEqualOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor_1,
                                             cnmlTensor_t input_tensor_2,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNEqualOpForward_V4 is recommended to use.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is not equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] != b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNEqualOpForward_V3(cnmlBaseOp_t op,
                                                        void *input_1,
                                                        void *input_2,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is not equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNEqualOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor1,
                                                        void *input_1,
                                                        cnmlTensor_t input_tensor2,
                                                        void *input_2,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* not equal operation end */

/* less equal operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an operator,
 *  and perform a comparison on the tensor B and the tensor A in each position
 *  to find whether one is less than or equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] <= B[ni][hi][wi][ci] )? 1: 0.
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] <= b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input and  output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLessEqualOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor_1,
                                                cnmlTensor_t input_tensor_2,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLessEqualOpForward_V4 is recommended to use.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is less than or equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] <= b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeLessEqualOpForward_V3(cnmlBaseOp_t op,
                                 void *input_1,
                                 void *input_2,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform a comparison on the user-specified four-dimensional tensor A and
 *  B to find whether one is less than or equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLessEqualOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor1,
                                                           void *input_1,
                                                           cnmlTensor_t input_tensor2,
                                                           void *input_2,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* less equal operation end */

/* less operation start */
/*!
 *  @brief A function.
 *
 *  Call after the tensor is created, and according to the base operator pointer
 *  given by the user, create an operator for comparing whether tensor 1 is
 *  smaller than tensor 2. Perform an element-wise comparison on the two
 *  tensors to find whether one is less than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] < B[ni][hi][wi][ci] )? 1:0
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] < b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU tensor, supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The input tensor type is not CNML_TENSOR or CNML_CONST.
 *    - Reason2 The CPU tensor bound by the bias tensor is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLessOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor_1,
                                           cnmlTensor_t input_tensor_2,
                                           cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLessOpForward_V4 is recommended to use.
 *
 *  Perform an element-wise comparison on the two four-dimensional tensors on
 *  the MLU to find whether one is less than the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] < b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLessOpForward_V3(cnmlBaseOp_t op,
                                                      void *inputA,
                                                      void *inputB,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform an element-wise comparison on the two four-dimensional tensors on
 *  the MLU to find whether one is less than the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_A
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_A
 *    Input. MLU address pointing to inputA data.
 *  @param[in] input_tensor_B
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_B
 *    Input. MLU address pointing to inputB data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLessOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor_A,
                                                      void *inputA,
                                                      cnmlTensor_t input_tensor_B,
                                                      void *inputB,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* less operation end */

/* greater equal operation start */
/*!
 *  @brief A function.
 *
 *  Call after the tensor is created, and according to the base operator pointer
 *  given by the user, create an operator for performing an element-wise comparison
 *  on two four-dimensional tensors to find whether one is greater than or equal
 *  to the other.
 *
 *  The shapes of two inputs and one output should be exactly the same.
 *
 *  Algorithm explanation: perform an element-wise comparison on the four-dimensional
 *  tensors A and B to find whether one is greater than or equal to the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] >= B[ni][hi][wi][ci] )? 1:0
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] >= b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type..
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The CPU tensor bound by the bias tensor is null.
 *    - Reason2 The input tensor type is not CNML_TENSOR or CNML_CONST.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateGreaterEqualOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGreaterEqualOpForward_V4 is recommended to use.
 *
 *  Call after the operation is created.
 *
 *  Perform an element-wise comparison
 *  on the two four-dimensional tensors on the MLU to find whether one is greater
 *  than or equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] >= b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeGreaterEqualOpForward_V3(cnmlBaseOp_t op,
                                    void *inputA,
                                    void *inputB,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Call after the operation is created.
 *
 *  Perform an element-wise comparison
 *  on the two four-dimensional tensors on the MLU to find whether one is greater
 *  than or equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_A
 *    Input. Input MLU tensor pointerA. Pass NULL if not used.
 *  @param[in] input_A
 *    Input. MLU address pointing to inputA data.
 *  @param[in] input_tensor_B
 *    Input. Input MLU tensor pointerB. Pass NULL if not used.
 *  @param[in] input_B
 *    Input. MLU address pointing to inputB data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeGreaterEqualOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor_A,
                                                              void *inputA,
                                                              cnmlTensor_t input_tensor_B,
                                                              void *inputB,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* greater equal operation end */

/* greater operation start */
/*!
 *  @brief A function.
 *
 *  Call after the tensor is created, and according to the base operator pointer
 *  given by the user, create an operator for performing an element-wise comparison
 *  on two tensors to find whether one is greater than the other.
 *
 *  The shapes of two inputs and one output must be exactly the same.
 *
 *  Algorithm explanation: perform an element-wise comparison on the A and B to find
 *  whether one is greater than the other.
 *
 *  I.e., C[ni][hi][wi][ci] = ( A[ni][hi][wi][ci] > B[ni][hi][wi][ci] )? 1:0
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] > b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor_1
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Throw exceptions when the function fails to execute.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    - Reason1 The input tensor type is not CNML_TENSOR or CNML_CONST.
 *    - Reason2 The input and  output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateGreaterOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input_tensor_1,
                                              cnmlTensor_t input_tensor_2,
                                              cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGreaterOpForward_V4 is recommended to use.
 *
 *  Call after the operation is created.
 *
 *  Perform an element-wise comparison on the two four-dimensional tensors
 *  on the MLU to find whether one is greater than or equal to the other.
 *
 *  **Formula**
 *
 *    c[n c h w] = a[n c h w] > b[n c h w] ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input or bool
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data 1.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data 2.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeGreaterOpForward_V3(cnmlBaseOp_t op,
                                                         void *input_1,
                                                         void *input_2,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Call after the operation is created.
 *
 *  Perform an element-wise comparison on the two four-dimensional tensors
 *  on the MLU to find whether one is greater than or equal to the other.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeGreaterOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* greater operation end */

/* clip operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a clip operation operator.
 *
 *  The operator crops an input
 *  tensor and intercepts the upper and lower boundaries.
 *  The operator can be seen as a combination of maxtc and mintc,
 *  which inputs a tensor and two constants. Perform an upper clipping
 *  and a lower clipping on the tensor to obtain a clipped tensor.
 *
 *  The scale of input and output must be the same.
 *
 *  **Formula**
 *
 *    y = x < lower_bound ? lower_bound : (x < upper_bound ? x : upper_bound)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor,
 *    the shape is [ni, ci, hi, wi], supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor,
 *    the shape is [no, co, ho, wo] (no = ni), supports data of float16 type.
 *  @param[in] lower_bound
 *    Input. Lower boundary of interception, supports data of float16 type..
 *  @param[in] upper_bound
 *    Input. Upper boundary of interception, supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    Successfully created a clipping operation.
 *    Return the corresponding error code when execution is failed.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateClipOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor,
                                           double lower_bound,
                                           double upper_bound);
/*!
 *  @brief A function.
 *
 *  Perform the user-specified clipping operation on the MLU.
 *
 *  After creating Clip operator, input, output and computation stream,
 *  introduce them to the function to compute the Clip operator.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeClipOpForward_V4 is recommended to use.
 *
 *  **Formula**
 *
 *    y = x < lower_bound ? lower_bound : (x < upper_bound ? x : upper_bound)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeClipOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Perform the user-specified clipping operation on the MLU.
 *
 *  After creating Clip operator, input, output and computation queue,
 *  introduce them to the function to compute the Clip operator.
 *
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeClipOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* clip operation end */

/* lstm pro operation start */
struct cnmlRNNOpParam;
/*! ``cnmlRNNOpParam_t`` is a pointer to ``cnmlRNNOpParam`` which is a
    structure holding the description of a RNN operation param. */
typedef struct cnmlRNNOpParam *cnmlRNNOpParam_t;

CNML_DLL_API cnmlStatus_t cnmlSetRnnDataMode(cnmlTensor_t tensor, cnmlRnnDataMode_t dtype);
/*!
 *  @struct cnmlLSTMClipParam
 *  @brief A struct.
 *
 *  cnmlLSTMClipParam is a structure describing the param parameter of LSTM operation, used to
 *  create LSTM operation. cnmlCreateLSTMClipParam() is used to create an instance of
 *  cnmlLSTMClipParam_t. cnmlDestroyLSTMClipParam() is used to destroy an instance of
 *  cnmlLSTMClipParam_t. */
struct cnmlLSTMClipParam;
/*! ``cnmlLSTMClipParam_t`` is a pointer to ``cnmlLSTMClipParam`` which is a
    structure holding the descriptiomln of a LSTM operation param. */
typedef struct cnmlLSTMClipParam *cnmlLSTMClipParam_t;

/*!
 *  @struct cnmlLSTMProjectionParam
 *  @brief A struct.
 *
 *  cnmlLSTMProjectionParam is a structure describing the param parameter of LSTM operation, used to
 *  create LSTM operation. cnmlCreateLSTMProjectionParam() is used to create an instance of
 *  cnmlLSTMProjectionParam_t. cnmlDestroyLSTMProjectionParam() is used to destroy an instance of
 *  cnmlLSTMProjectionParam_t. */
struct cnmlLSTMProjectionParam;
/*! ``cnmlLSTMProjectionParam_t`` is a pointer to ``cnmlLSTMProjectionParam`` which is a
    structure holding the description of a LSTM operation param. */
typedef struct cnmlLSTMProjectionParam *cnmlLSTMProjectionParam_t;

/*!
 *  @struct cnmlLSTMPeepholeParam
 *  @brief A struct.
 *
 *  cnmlLSTMPeepholeParam is a structure describing the param parameter of LSTM operation, used to
 *  create LSTM operation. cnmlCreateLSTMPeepholeParam() is used to create an instance of
 *  cnmlLSTMPeepholeParam_t. cnmlDestroyLSTMPeepholeParam() is used to destroy an instance of
 *  cnmlLSTMPeepholeParam_t. */
struct cnmlLSTMPeepholeParam;
/*! ``cnmlLSTMPeepholeParam_t`` is a pointer to ``cnmlLSTMPeepholeParam`` which is a
    structure holding the description of a LSTM operation param. */
typedef struct cnmlLSTMPeepholeParam *cnmlLSTMPeepholeParam_t;

/*!
 *  @struct cnmlLSTMProParam
 *  @brief A struct.
 *
 *  cnmlLSTMProParam is a structure describing the param parameter of LSTM operation, used to create
 *  LSTM operation. cnmlCreateLSTMProParam() is used to create an instance of cnmlLSTMProParam_t.
 *  cnmlDestroyLSTMProParam() is used to destroy an instance of cnmlLSTMProParam_t. */
struct cnmlLSTMProParam;
/*! ``cnmlLSTMProParam_t`` is a pointer to ``cnmlLSTMProParam`` which is a
    structure holding the description of a LSTM operation param. */
typedef struct cnmlLSTMProParam *cnmlLSTMProParam_t;

/*!
 *  @brief A function.
 *
 *  Create a parameter for describing LSTM intercepts cellState.
 *
 *  input [N, C] , [N, T, C] or [T, N, C]
 *
 *  output [N, C] , [N, T, C] or [T, N, C]
 *
 *  **Formula**
 *
 *    design formulas of Standard
 *
 *     f = sigmoid(w1*x + w2*h + b1 + b2)
 *
 *     i = sigmoid(w4*x + w5*h + b4 + b5)
 *
 *     c = f (*) ct-1 + i (*) tanh(w7*x + w8*h + b7 + b8)
 *
 *     o = sigmoid(w9*x + w10*h + b9 + b10)
 *
 *    design formulas of Clip
 *
 *     f = sigmoid(w1*x + w2*h + b1 + b2)
 *
 *     i = sigmoid(w4*x + w5*h + b4 + b5)
 *
 *     c = f (*) ct-1 + i (*) tanh(w7*x + w8*h + b7 + b8)
 *
 *     c = c.clip(min, max)
 *
 *     o= sigmoid(w9*x + w10*h + w11(*)c + b9 + b10)
 *
 *    design formulas of Projection
 *
 *     f = sigmoid(w1*x + w2*h + b1 + b2)
 *
 *     i = sigmoid(w4*x + w5*h + b4 + b5)
 *
 *     c = f (*) ct-1 + i (*) tanh(w7*x + w8*h + b7 + b8)
 *
 *     o = sigmoid(w9*x + w10*h + b9 + b10)
 *
 *     h = o * tanh(ct)
 *
 *     h = tanh(w12*h + b12)
 *
 *    design formulas of Peephole
 *
 *     f = sigmoid(w1*x + w2*h + w3(*)c + b1 + b2)
 *
 *     i = sigmoid(w4*x + w5*h + w6(*)c + b4 + b5)
 *
 *     c = f (*) ct-1 + i (*) tanh(w7*x + w8*h + b7 + b8)
 *
 *     o = sigmoid(w9*x + w10*h + w11(*)c + b9 + b10)
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to pointer, the pointer that is pointed points to
 *    a struct. The struct is used for describing how to intercept cell_state,
 *    the interception range is [min, max]. Namely: if cell_state<min,
 *    then cell_state = min; if cell_state > max, cell_sate = max.
 *  @param[in] min
 *    Input. The minimum value in the interception range.
 *  @param[in] max
 *    Input. The maximum value in the interception range.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLSTMClipParam(cnmlLSTMClipParam_t *param,
                                                  double min,
                                                  double max);
/*!
 *  @brief A function.
 *
 *  Destroy the parameter for describing LSTM intercepts cellState.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    A pointer to pointer, the pointer that is pointed points to a parameter struct.
 */

CNML_DLL_API cnmlStatus_t cnmlDestroyLSTMClipParam(cnmlLSTMClipParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create a parameter for describing LSTM for recurrent projection and
 *  output projection.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Input. A pointer to pointer, the pointer that is pointed points
 *    to a parameter struct.
 *  @param[in] is_rec_proj
 *    Input. Whether to enable recurrent projection.
 *  @param[in] rec_proj_size
 *    Input. Size after projection.
 *  @param[in] rec_act_fun
 *    Input. An activation function used on the projection result after
 *    recurrent projection.
 *  @param[in] is_out_proj
 *    Input. Not supported yet.
 *  @param[in] out_proj_size
 *    Input. Not supported yet.
 *  @param[in] out_act_fun
 *    Input. Not supported yet.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLSTMProjectionParam(cnmlLSTMProjectionParam_t *param,
                                                        bool is_rec_proj,
                                                        int rec_proj_size,
                                                        cnmlActiveFunction_t rec_active_func,
                                                        bool is_out_proj,
                                                        int out_proj_size,
                                                        cnmlActiveFunction_t out_active_func);

/*!
 *  @brief A function.
 *
 *  Destroy the parameter for describing LSTM for recurrent projection
 *  and output projection.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to pointer, the pointer that is pointed points
 *    to a parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    Successfully created a clipping operation.
 *    Return the corresponding error code when execution is failed.
 */

CNML_DLL_API cnmlStatus_t cnmlDestroyLSTMProjectionParam(cnmlLSTMProjectionParam_t *param);
/*!
 *  @brief A function.
 *
 *  Create a parameter for describing LSTM for peephole.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to pointer, the pointer that is pointed points to
 *    a parameter struct.
 *  @param[in] peephole
 *    Input. Whether to enable peephole.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLSTMPeepholeParam(cnmlLSTMPeepholeParam_t *param,
                                                      bool enable_peephole);
/*!
 *  @brief A function.
 *
 *  Destroy the parameter of describing LSTM for peephole.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to pointer, the pointer that is pointed points
 *    to a parameter struct.
 */

CNML_DLL_API cnmlStatus_t cnmlDestroyLSTMPeepholeParam(cnmlLSTMPeepholeParam_t *param);

/*!
 *  @brief A function.
 *
 *  Create parameters for describing LSTMPro operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Input. A pointer to pointer, the pointer that is pointed points to
 *    a parameter struct that describes LSTMPro operator.
 *  @param[in] rnn_param
 *    Input. A previously created pointer to the recurrent neural network
 *    parameter struct.
 *  @param[in] clip_param
 *    Input. Parameter for describing LSTM intercepts cellState.
 *  @param[in] proj_param
 *    Input. Parameter for describing LSTM recurrent projection
 *    and output projection.
 *  @param[in] peephole_param
 *    Input. Parameter for describing whether LSTM enables peephol.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLSTMProParam(cnmlLSTMProParam_t *param,
                                                 cnmlRNNOpParam_t rnn_param,
                                                 cnmlLSTMClipParam_t clip_param,
                                                 cnmlLSTMProjectionParam_t proj_param,
                                                 cnmlLSTMPeepholeParam_t peephole_param);
/*!
 *  @brief A function.
 *
 *  Destroy the parameters of LSTMPro operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to pointer, the pointer that is pointed points
 *    to a parameter struct.
 */

CNML_DLL_API cnmlStatus_t cnmlDestroyLSTMProParam(cnmlLSTMProParam_t *param);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, lstm's mask tensor array has been add
 * into.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of the base operator.
 *  @param[in] mask
 *    Input. A 2-dimensional MLU tensor, the shape is [t, n], supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *    - The CPU tensor bound by the bias tensor is null.
 */

cnmlStatus_t cnmlAddLSTMMask(cnmlBaseOp_t op, cnmlTensor_t mask[]);

/*!
 *  @brief A function.
 *
 *  The interface is used for creating a LSTMPro operator.
 *
 *  If all the parameters in the interface are arrays, the length of
 *  the arrays is num_layers, and the array element with the subscript
 *  being 0 indicates the initial value of the hidden state of the first
 *  layer, the subscript being 1 indicates the second layer, and so on.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] lstm_pro_param
 *    Input. Describes the struct pointer of all parameters of LSTM.
 *  @param[in] x
 *    Input. A three-dimensional tensor,
 *    the shape is [seqLength,batchSize,vectorSize].
 *  @param[in] hx
 *    Input. A four-dimensional tensor array, the hiddenState input of LSTM.
 *    The shape is [batchSize,hiddenSize,1,1]. If there is recurrent projection,
 *    the shape is [batchSize,recProjSize,1,1].
 *  @param[in] cx
 *    Input. A four-dimensional tensor array, the cellState input of LSTM.
 *    The shape is [batchSize,hiddenSize,1,1].
 *  @param[in] y
 *    Input. A three-dimensional tensor, the shape is [seqLength,batchSize,hiddenSize].
 *    If there is recurrent projection, the shape is [seqLength,batchSize,recProjSize].
 *  @param[in] hy
 *    Input. A four-dimensional tensor array, the hiddenState output of LSTM.
 *    The shape is [batchSize,hiddenSize,1,1]. If there is recurrent projection,
 *    the shape is [batchSize,recProjSize,1,1].
 *  @param[in] cy
 *    Input. A four-dimensional tensor array, the cellState output of LSTM.
 *    The shape is [batchSize,hiddenSize,1,1].
 *  @param[in] filter_forget_x
 *    Input. A four-dimensional tensor array, the weight of x in the forget gate.
 *  @param[in] filter_forget_h
 *    Input. A four-dimensional tensor array, the weight of hiddenState in
 *    the forget gate.
 *  @param[in] filter_forget_c
 *    Input. A four-dimensional tensor array, the weight of cellState in
 *    the forget gate.
 *  @param[in] bias_forget_x
 *    Input. A four-dimensional tensor array, the bias of x in the forget gate.
 *  @param[in] bias_forget_h
 *    Input. A four-dimensional tensor array, the bias of hiddenState
 *    in the forget gate.
 *  @param[in] filter_input_x
 *    Input. A four-dimensional tensor array, the weight of x in the input gate.
 *  @param[in] filter_input_h
 *    Input. A four-dimensional tensor array, the weight of hiddenState
 *    in the input gate .
 *  @param[in] filter_input_c
 *    Input. A four-dimensional tensor array, the weight of cellState in the input gate.
 *  @param[in] bias_input_x
 *    Input. A four-dimensional tensor array, the bias of x in the input gate..
 *  @param[in] bias_input_h
 *    Input. A four-dimensional tensor array, the bias of hiddenState in the input gate
 *  @param[in] filter_update_x
 *    Input. A four-dimensional tensor array, the weight of x in the update gate.
 *  @param[in] filter_update_h
 *    Input. A four-dimensional tensor array, the weight of hiddenState
 *    in the update gate.
 *  @param[in] bias_update_x
 *    Input. A four-dimensional tensor array, the bias of x in the update gate. .
 *  @param[in] bias_update_h
 *    Input. A four-dimensional tensor array, the bias of hiddenState
 *    in the update gate.
 *  @param[in] filter_output_x
 *    Input. A four-dimensional tensor array, the weight of x in the output gate.
 *  @param[in] filter_output_h
 *    Input. A four-dimensional tensor array, the weight of hiddenState
 *    in the output gate.
 *  @param[in] filter_output_c
 *    Input. A four-dimensional tensor array, the weight of cellState
 *    in the output gate.
 *  @param[in] bias_output_x
 *    Input. A four-dimensional tensor array, the bias of x in the output gate.
 *  @param[in] bias_output_h
 *    Input. A four-dimensional tensor array, the bias of hiddenState
 *    in the output gate.
 *  @param[in] filter_rec_proj
 *    Input. A four-dimensional tensor array, the weight of recurrent projection.
 *  @param[in] bias_rec_proj
 *    Input. A four-dimensional tensor array, the bias of recurrent projection.
 *  @param[in] filter_out_proj
 *    Input. Retain, not supported yet.
 *  @param[in] bias_out_proj
 *    Input. Retain, not supported yet.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLSTMProOp(cnmlBaseOp_t *op,
                                              cnmlLSTMProParam_t lstm_pro_param,
                                              cnmlTensor_t x,
                                              cnmlTensor_t hx[],
                                              cnmlTensor_t cx[],
                                              cnmlTensor_t y,
                                              cnmlTensor_t hy[],
                                              cnmlTensor_t cy[],
                                              cnmlTensor_t filter_forget_x[],  // forget
                                              cnmlTensor_t filter_forget_h[],
                                              cnmlTensor_t filter_forget_c[],
                                              cnmlTensor_t bias_forget_x[],
                                              cnmlTensor_t bias_forget_h[],
                                              cnmlTensor_t filter_input_x[],  // input
                                              cnmlTensor_t filter_input_h[],
                                              cnmlTensor_t filter_input_c[],
                                              cnmlTensor_t bias_input_x[],
                                              cnmlTensor_t bias_input_h[],
                                              cnmlTensor_t filter_update_x[],  // update
                                              cnmlTensor_t filter_update_h[],
                                              cnmlTensor_t bias_update_x[],
                                              cnmlTensor_t bias_update_h[],
                                              cnmlTensor_t filter_output_x[],  // output
                                              cnmlTensor_t filter_output_h[],
                                              cnmlTensor_t filter_output_c[],
                                              cnmlTensor_t bias_output_x[],
                                              cnmlTensor_t bias_output_h[],
                                              cnmlTensor_t filter_rec_proj[],  // rec_proj
                                              cnmlTensor_t bias_rec_proj[],
                                              cnmlTensor_t filter_out_proj[],  // out_proj
                                              cnmlTensor_t bias_out_proj[]);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLSTMProOpForward_V2 is recommended to use.
 *
 *  Compute the previously created LSTM operator on the MLU.
 *
 *  If all the parameters in the interface are arrays, the length of
 *  the arrays is num_layers, and the array element with the subscript
 *  being 0 indicates the initial value of the hidden state of the
 *  first layer, the subscript being 1 indicates the second layer, and so on.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] y
 *    Output. Points to the output data initial address of LSTM.
 *  @param[out] hy
 *    Output. A pointer array, points to the hiddenState output data initial
 *    address of LSTM.
 *  @param[out] cy
 *    Output. A pointer array, points to the cellState output data initial
 *    address of LSTM.
 *  @param[in]  x
 *    Input. Points to the input data initial address of LSTM.
 *  @param[in] hx
 *    Input. A pointer array, points to the hiddenState input data
 *    initial address of LSTM.
 *  @param[in] cx
 *    Input. A pointer array, points to the cellState input data
 *    initial address of LSTM.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address, which records runtime
 *    degree of data parallelism and equipment affinity.
 *  @param[in] queue
 *    Input. A computation queue pointer..
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
cnmlStatus_t cnmlComputeLSTMProOpForward(cnmlBaseOp_t op,
                                         void *x,
                                         void *hx[],
                                         void *cx[],
                                         void *y,
                                         void *hy[],
                                         void *cy[],
                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the previously created LSTM operator on the MLU.
 *
 *  If all the parameters in the interface are arrays, the length of
 *  the arrays is num_layers, and the array element with the subscript
 *  being 0 indicates the initial value of the hidden state of the
 *  first layer, the subscript being 1 indicates the second layer, and so on.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] y
 *    Output. Points to the output data initial address of LSTM.
 *  @param[out] hy
 *    Output. A pointer array, points to the hiddenState output data initial
 *    address of LSTM.
 *  @param[out] cy
 *    Output. A pointer array, points to the cellState output data initial
 *    address of LSTM.
 *  @param[in]  x
 *    Input. Points to the input data initial address of LSTM.
 *  @param[in] hx
 *    Input. A pointer array, points to the hiddenState input data
 *    initial address of LSTM.
 *  @param[in] cx
 *    Input. A pointer array, points to the cellState input data
 *    initial address of LSTM.
 *  @param[in] mask
 *    Input. A pointer array, points to the mask input data
 *    initial address of LSTM.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address, which records runtime
 *    degree of data parallelism and equipment affinity.
 *  @param[in] queue
 *    Input. A computation queue pointer..
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
cnmlStatus_t cnmlComputeLSTMMaskProOpForward(cnmlBaseOp_t op,
                                             void *x,
                                             void *hx[],
                                             void *cx[],
                                             void *mask[],
                                             void *y,
                                             void *hy[],
                                             void *cy[],
                                             cnrtInvokeFuncParam_t *compute_forw_param,
                                             cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the previously created LSTM operator on the MLU.
 *
 *  If all the parameters in the interface are arrays, the length of
 *  the arrays is num_layers, and the array element with the subscript
 *  being 0 indicates the initial value of the hidden state of the
 *  first layer, the subscript being 1 indicates the second layer, and so on.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] x_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] x
 *    Input. MLU address pointing to x data.
 *  @param[in] hx_tensor
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] hx
 *    Input. MLU address pointing to hx data.
 *  @param[in] cx_tensor
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] cx
 *    Input. MLU address pointing to cx data.
 *  @param[in] y_tensor
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] y
 *    Input. MLU address pointing to y data.
 *  @param[in] hy_tensor
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] hy
 *    Input. MLU address pointing to hy data.
 *  @param[in] cy_tensor
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] cy
 *    Input. MLU address pointing to cy data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

cnmlStatus_t cnmlComputeLSTMProOpForward_V2(cnmlBaseOp_t op,
                                            cnmlTensor_t x_tensor,
                                            void *x,
                                            cnmlTensor_t hx_tensors[],
                                            void *hx[],
                                            cnmlTensor_t cx_tensors[],
                                            void *cx[],
                                            cnmlTensor_t y_tensor,
                                            void *y,
                                            cnmlTensor_t hy_tensors[],
                                            void *hy[],
                                            cnmlTensor_t cy_tensors[],
                                            void *cy[],
                                            cnrtQueue_t queue,
                                            void *extra);
/* lstm pro operation end */

/* control flow operation begin */

/*!
 *  @brief A function.
 *
 *  The interface is used for creating a ControlFlow operator.
 *
 *  According to the base operator pointer given by the user, create a controlflow
 *  operator.
 *
 *  The controlflow operator is used to build a operator that could realize the condition/while
 *  and other control flow functions.
 *
 *  The controlflow operator consists of five sub-operators, enter, merge, switch, next
 *  iteration and exit.
 *
 *  This operator provides a way to build a operator that could realize different functions
 *  according to the need of the users, by combining the five sub-operators in different way.
 *
 *  **Supports both MLU220 and  MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateControlFlowOp(cnmlBaseOp_t *op);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding an enter operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Enter operators should be used to transfer input tensors into the controlflow loop body.
 *
 *  All the enter operators should be added into the controlflow operator by this interface.
 *
 *  **Formula**
 *
 *    output = input
 *
 *  **DataType**
 *
 *
 *    input: int8, int16, float16, float32
 *
 *    output: same as input
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *    2.input.shape = output.shape
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor.
 *  @param[in] output
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddEnter(cnmlBaseOp_t op, cnmlTensor_t input, cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding a merge operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Merge operators are used to merge different input tensors into one.
 *
 *  All the merge operators should be added into the controlflow operator by this interface.
 *
 *  **Formula**
 *
 *    output = merge(inputs[0], inputs[1], ... inputs[n - 1]) when inputs[i] is ready.
 *
 *  **DataType**
 *
 *    inputs: int8, int16, float16, float32
 *
 *    in_num: int
 *
 *    outputs: same as input
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *
 *    2.all the inputs and output shape should be the same
 *
 *      inputs[i - 1].shape = inputs[i].shape
 *
 *      inputs[i].shape = output.shape
 *
 *    3.the in_num only support 2 now
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] inputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] output
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddMerge(cnmlBaseOp_t op,
                                       cnmlTensor_t inputs[],
                                       int in_num,
                                       cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding a switch operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Switch operators are used to choose which branch to run according to the conditon tensor.
 *
 *  There are two input tensors for the function, while the first is the input tensor, and the
 *  second is the condition tensor.
 *
 *  All the switch operators should be added into the controlflow operator by this interface.
 *
 *  **Formula**
 *
 *    output[0] = input if condition == true; else output[1] = input.
 *
 *  **DataType**
 *
 *    input: int8, int16, float16, float32
 *
 *    cond: int
 *
 *    outputs: same as input
 *
 *    out_num: int
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *
 *    2.all the input and outputs shape should be the same
 *
 *      outputs[i - 1].shape = outputs[i].shape
 *
 *      outputs[i].shape = input.shape
 *
 *    3.out_num only support 2 now
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensors.
 *  @param[in] cond
 *    Input. A four-dimensional MLU input tensors.
 *  @param[in] outputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddSwitch(cnmlBaseOp_t op,
                                        cnmlTensor_t input,
                                        cnmlTensor_t cond,
                                        cnmlTensor_t outputs[],
                                        int out_num);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding an exit operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Exit operators should be used to transfer output tensors out of the controlflow loop body.
 *
 *  All the exit operators should be added into the controlflow operator by this interface.
 *
 *  **Formula**
 *
 *    output = input.
 *
 *  **DataType**
 *
 *    input: int8, int16, float16, float32
 *
 *    output: same as input
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *    2.input and output shape should be the same
 *      input.shape = output.shape
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor.
 *  @param[in] output
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddExit(cnmlBaseOp_t op, cnmlTensor_t input, cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding a next iteration operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Next iteration operators transfer the tensor from the loop body into a next iteration.
 *
 *  All the next iteration operators should be added into the controlflow operator by this
 *  interface.
 *
 *  **Formula**
 *
 *    output = input.
 *
 *  **DataType**
 *
 *    input: int8, int16, float16, float32
 *
 *    output: same as input
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *    2.input and output shape should be the same
 *      input.shape = output.shape
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor.
 *  @param[in] output
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddNextIteration(cnmlBaseOp_t op,
                                               cnmlTensor_t input,
                                               cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the loop body operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Body operators are the operators created by the users and need to be used in the controlflow
 *  operator.
 *
 *  All the loop body operators should be added into the controlflow operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] body_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */

CNML_DLL_API cnmlStatus_t cnmlAddBody(cnmlBaseOp_t op, cnmlBaseOp_t body_op);
/*!
 *  @brief A function.
 *
 *  The interface is used for adding the condition operator to a controlflow operator, and the
 *  controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  Condition operators are the operators that decide whether to enter a loop branch(True/False).
 *
 *  All the condition operators should be added into the controlflow operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] condition_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddCondition(cnmlBaseOp_t op, cnmlBaseOp_t condition_op);

/*!
 *  @brief A function.
 *
 *  The interface is used for setting the input and output tensors to a controlflow operator, and
 *  the controlflow operator should be already created by cnmlCreateControlFlowOp function.
 *
 *  **DataType**
 *
 *    inputs: int8, int16, float16, float32
 *
 *    in_num: int
 *
 *    outputs: same as input
 *
 *    out_num: same as in_num
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operators address.
 *  @param[in] inputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] outputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlSetControlFlowIO(cnmlBaseOp_t op,
                                               cnmlTensor_t inputs[],
                                               int in_num,
                                               cnmlTensor_t outputs[],
                                               int out_num);

/*!
 *  @brief A function.
 *
 *  For computing the controlflow operator on the MLU.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] outputs
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operator.
 *  @param[in] inputs
 *    Input. An MLU address pointing to input data.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @param[in] stream
 *    Input. A computation stream pointer.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeControlFlowOpForward_V3(cnmlBaseOp_t op,
                                   void *inputs[],
                                   int in_num,
                                   void *outputs[],
                                   int out_num,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);

/* control flow operation end */

/* while_loop operation begin */

/*!
 *  @brief A function.
 *
 *  The interface is used for creating a while operator.
 *
 *  According to the base operator pointer given by the user, create a while loop operator.
 *
 *  The while operator is used to build a operator that could realize the while control
 *  flow function.
 *
 *  The while operator should receive a tensor as the while condition, and would loop when
 *  the condition tensor is satisified with the loop requirement(True/False). Each while loop
 *  operator should only have one condition input tensor.
 *
 *  **DataType**
 *
 *    cond_input_var: int8, int16
 *
 *    input datatype is not need to be set
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Supports only MLU270.**
 *
 *    Output. A pointer pointing to base operator address.
 *  @param[in] cond_input_var
 *    Input. A four-dimensional MLU tensor, the shape is [n, c, h, w] (n = 1, h = 1, w = 1, c = 1),
 *    supporting the data of int type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateWhileLoopOp(cnmlBaseOp_t *while_op,
                                                cnmlTensor_t cond_input_var);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the condition operator to a while loop operator, and the
 *  while loop operator should be already created by cnmlCreateWhileLoopOp function.
 *
 *  Condition operators are the operators that could determine the computation of the loop
 *  requirement, which decide whether to enter a loop branch.
 *
 *  All the condition operators should be added into the controlflow operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] loop_cond_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddLoopCondOp(cnmlBaseOp_t while_op, cnmlBaseOp_t loop_cond_op);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the loop body operator to a while loop operator, and the
 *  while loop operator should be already created by cnmlCreateWhileLoopOp function.
 *
 *  Body operators are the operators created by the users and need to be used in the while loop
 *  operator.
 *
 *  All the loop body operators should be added into the while loop operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] loop_body_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddLoopBodyOp(cnmlBaseOp_t while_op, cnmlBaseOp_t loop_body_op);

/*!
 *  @brief A function.
 *
 *  The interface is used for linking the tensors in a while loop operator, and the
 *  while loop operator should be already created by cnmlCreateWhileLoopOp function.
 *
 *  The tensor pairs include the initial input tensor out of a loop, input tensor in a loop,
 *  the tensor for next iteration in a loop, and output tensor in a loop. Theses tensors construct
 *  a circulation in a loop.
 *
 *  All the tensor pairs in a loop should be added into the while loop operator by this interface.
 *
 *  **Formula**
 *
 *    loop_val_init = loop_var_in = loop_next_in = exit_out.
 *
 *  **DataType**
 *
 *    loop_var_init: int8, int16, float16, float32
 *
 *    loop_var_in: same as loop_var_init
 *
 *    loop_next_in: same as loop_var_init
 *
 *    exit_out: same as loop_var_init
 *
 *    input onchip datatype is not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.all the input tensors datatype should be the same
 *
 *    2.all the input tenosrs shape should be the same
 *
 *  **Supports only MLU270.**
 *
 *  The tensor pairs include the initial input tensor out of a loop, input tensor in a loop,
 *  the tensor for next iteration in a loop, and output tensor in a loop. Theses tensors construct
 *  a circulation in a loop.
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] loop_var_init
 *    Input. A four-dimensional MLU tensor. It's initial input tensor out of a loop.
 *  @param[in] loop_var_in
 *    Input. A four-dimensional MLU tensor. It's input tensor in a loop.
 *  @param[in] loop_next_in
 *    Input. A four-dimensional MLU tensor. This tensor is the intermediate result of a loop.
 *  @param[in] exit_out
 *    Input. A four-dimensional MLU output tensor. This tensor is the final result of the loop,
 *    it's input node of successor neural network.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddLoopTensorPair(cnmlBaseOp_t while_op,
                                                cnmlTensor_t loop_var_init,
                                                cnmlTensor_t loop_var_in,
                                                cnmlTensor_t loop_next_in,
                                                cnmlTensor_t exit_out);

/*!
 *  @brief A function.
 *
 *  The interface is used for setting the input and output tensors to a while_loop operator, and the
 *  while_loop operator should be already created by cnmlCreateWhileLoopOp function.
 *
 *  **DataType**
 *
 *    inputs: int8, int16, float16, float32
 *
 *    in_num: int
 *
 *    outputs: same as inputs
 *
 *    out_num: same as in_num
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to while_loop operator address.
 *  @param[in] inputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] outputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlSetWhileLoopIO(cnmlBaseOp_t op,
                                             cnmlTensor_t inputs[],
                                             int in_num,
                                             cnmlTensor_t outputs[],
                                             int out_num);

/*!
 *  @brief A function.
 *
 *  For computing the while loop operator on the MLU.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] outputs
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operator.
 *  @param[in] inputs
 *    Input. An MLU address pointing to input data.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @param[in] stream
 *    Input. A computation stream pointer.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeWhileLoopOpForward_V3(cnmlBaseOp_t while_op,
                                 void *inputs[],
                                 int in_num,
                                 void *outputs[],
                                 int out_num,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);

/* while_loop operation end */

/* cond operation start */
/*!
 *  @brief A function.
 *
 *  The interface is used for creating a cond operator.
 *
 *  According to the base operator pointer given by the user, create a condition operator.
 *
 *  The cond operator is used to build a operator that could realize the if/else condition
 *  function.
 *
 *  The cond operator should receive a tensor as the condition, and would switch into different
 *  branches according to the condition tensor value(True/False). Each cond operator should
 *  only have one condition input tensor.
 *
 *  **DataType**
 *
 *    cond_input_val: int8, int16
 *
 *    input datatype is not need to be set
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operator address.
 *  @param[in] cond_input_var
 *    Input. A four-dimensional MLU tensor, the shape is [n, c, h, w] (n = 1, h = 1, w = 1, c = 1),
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCondOp(cnmlBaseOp_t *op, cnmlTensor_t cond_input_val);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the merge operator to a cond operator, and the cond
 *  operator should be already created by cnmlCreateCondOp function.
 *
 *  Cond merge operators are the operators that could merge different inputs into a output, which
 *  realize transfering the ready tensor from input to output.
 *
 *  **Formula**
 *
 *    output = merge(inputs[0], inputs[1], ... inputs[n - 1]) when inputs[i] is ready.
 *
 *  **DataType**
 *
 *    inputs: int8, int16, float16, float32
 *
 *    in_num: int
 *
 *    output: same as inputs
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    1.input_datatype = output_datatype
 *
 *    2.input and output shape should be the same
 *
 *      input.shape = output.shape
 *
 *    3.in_num only support 2 now
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] inputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] output
 *    Input. A four-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddCondMerge(cnmlBaseOp_t op,
                                           cnmlTensor_t inputs[],
                                           int in_num,
                                           cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the operator in a true condition branch to the cond operator,
 *  and the cond operator should be already created by cnmlCreateCondOp function.
 *
 *  True condition operators are the operators created by the users and need to be used in the true
 *  branch in a cond operator.
 *
 *  All the true condition operators should be added into the cond operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] branch_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddTrueCondOperation(cnmlBaseOp_t op, cnmlBaseOp_t branch_op);

/*!
 *  @brief A function.
 *
 *  The interface is used for adding the operator in a false condition branch to the cond operator,
 *  and the cond operator should be already created by cnmlCreateCondOp function.
 *
 *  True condition operators are the operators created by the users and need to be used in the false
 *  branch in a cond operator.
 *
 *  All the false condition operators should be added into the cond operator by this interface.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] branch_op
 *    Input. A pointer pointing to base operator address.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlAddFalseCondOperation(cnmlBaseOp_t op, cnmlBaseOp_t branch_op);

/*!
 *  @brief A function.
 *
 *  The interface is used for setting the input and output tensors to a cond operator, and the
 *  cond operator should be already created by cnmlCreateCondOp function.
 *
 *  **DataType**
 *
 *    inputs: int8, int16, float16, float32
 *
 *    in_num: int
 *
 *    outputs: same as inputs
 *
 *    out_num: same as in_num
 *
 *    input and output onchip datatypes are not need to be set
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer pointing to base controlflow operator address.
 *  @param[in] inputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] outputs
 *    Input. A array of four-dimensional MLU input tensors.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Op pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Task type is invalid at runtime.
 */
CNML_DLL_API cnmlStatus_t cnmlSetCondIO(cnmlBaseOp_t op,
                                        cnmlTensor_t inputs[],
                                        int in_num,
                                        cnmlTensor_t outputs[],
                                        int out_num);

/*!
 *  @brief A function.
 *
 *  For computing the cond operator on the MLU.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operator.
 *  @param[in] inputs
 *    Input. An MLU address pointing to input data.
 *  @param[in] in_num
 *    Input. The number of inputs.
 *  @param[in] out_num
 *    Input. The number of outputs.
 *  @param[in] stream
 *    Input. A computation stream pointer.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCondOpForward_V3(cnmlBaseOp_t op,
                                                      void **input,
                                                      int in_num,
                                                      void **output,
                                                      int out_num,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t stream);
/* cond operation end */

/* nearest_neighbor operation start */
/*!
 *  @struct cnmlNearestNeighborOpParam
 *  @brief A struct.
 *
 *  cnmlNearestNeighborOpParam is a structure describing the param parameter of nearest neighbor
 *  operation, used to create nearest neighbor operation. cnmlCreateNearestNeighborOpParam() and
 *  cnmlCreateNearestNeighborOpParamByRatio() is used to create an instance of
 *  cnmlNearestNeighborOpParam_t. cnmlDestroyNearestNeighborOpParam() is used to destroy an instance
 *  of cnmlNearestNeighborOpParam_t. */
struct cnmlNearestNeighborOpParam;
/*! ``cnmlNearestNeighborOpParam_t`` is a pointer to ``cnmlNearestNeighborOpParam`` which is a
    structure holding the description of a nearest neighbor operation param. */
typedef struct cnmlNearestNeighborOpParam *cnmlNearestNeighborOpParam_t;

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates
 *  a struct for the computation parameters of pixel approximation
 *  point operator, and sets the operator parameter struct through
 *  the width and height of the output image.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the struct for the computation
 *    parameters of pixel approximation point operator.
 *  @param[in] output_width
 *    Input. The width of the output image.
 *  @param[in] output_height
 *    Input. The height of the output image.
 *  @retval CNML_STATUS_SUCCESS
 *    Successfully created a clipping operation.
 *    Return the corresponding error code when execution is failed.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNearestNeighborOpParam(cnmlNearestNeighborOpParam_t *param,
                                                           int output_width,
                                                           int output_height);
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function creates a struct
 *  for the computation parameters of pixel approximation point operator, and
 *  sets the operator parameter struct through the zoom multiple.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the struct for the computation
 *    parameters of pixel approximation point operator.
 *  @param[in] zoom
 *    Input. Zoom multiple.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    Param is a null pointer.
 */

CNML_DLL_API cnmlStatus_t
cnmlCreateNearestNeighborOpParamByRatio(cnmlNearestNeighborOpParam_t *param, int zoom);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the function set align_corner for
 *  the operator parameter struct.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the struct for the computation
 *    parameters of pixel approximation point operator.
 *  @param[in] align_corner
 *    Input. align_corner.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    Param is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlSetNearestNeighborAlignCorner(cnmlNearestNeighborOpParam_t *param,
                                                            bool align_corners);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, free the pointer of the struct
 *  for the computation parameters of pixel approximation point operator.
 *
 *  After the convolution operator finishes operation, free the previously
 *  created pointer of the struct for the computation parameters of pixel
 *  approximation point operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to the address of the struct for the computation
 *    parameters of pixel approximation point operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions is not met:
 *   - Param is a null pointer.
 *   - The pointer content pointed by param is already freed.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlDestroyNearestNeighborOpParam(cnmlNearestNeighborOpParam_t *param);
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a pixel
 *  approximation point operator.
 *
 *  When zooming the image, select the pixel that
 *  is the most approximate to the input image position as the projection output.
 *
 *  First, determine the respective zoom factors of the width and height:
 *
 *    alpha_height = (hi- 1) / (ho- 1);
 *
 *    alpha_width = (wi- 1) / (wo- 1);
 *
 *  let the output pixel be on (w,h), then the source image pixel obtained by
 *  approximation projection is on:
 *
 *    src_h = round(h * alpha_height);
 *
 *    src_w = round(w * alpha_width);
 *
 *  copy the value of the coordinate of input(n,c, src_w,src_h) to output (n,c,w,h).
 *
 *  When zooming an image, ni = no, ci = co;
 *
 *  i.e., the input and output must have the same n dimension and the c dimension,
 *  but may have different h and w (namely, the size of the image),
 *  the computation mode of output width and height can be obtained according to
 *  the above-mentioned parameter type either-or principle:
 *
 *  if (_output_h> 0 && _output_w> 0)
 *
 *    ho = _output_h, wo =_output_w;
 *  //after ho and wo are specified, there is no need to specify zoomelas if (zoom > 0)
 *
 *    ho = zoom * hi; //ho and wo can be inferred after zoom is specified
 *
 *    wo = zoom * wi;
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],
 *    supports data of float16 type.
 *  @param[in] output
 *    Input. A four-dimensional MLU output tensor, the shape is
 *    [no, co, ho, wo](no = ni), supports data of float16 type.
 *  @param[in] param
 *    Input. A pixel approximation point computation struct pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *  At least one of the following conditions is not met:
 *  - The input tensor type is not CNML_TENSOR or CNML_CONST.
 *  - The CPU tensor bound by the bias tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNearestNeighborOp(cnmlBaseOp_t *op,
                                                      cnmlTensor_t input_tensor,
                                                      cnmlTensor_t output_tensor,
                                                      cnmlNearestNeighborOpParam_t param);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNearestNeighborOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified pixel approximation point operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeNearestNeighborOpForward_V3(cnmlBaseOp_t op,
                                       void *input,
                                       void *output,
                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNearestNeighborOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified pixel approximation point operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNearestNeighborOpForward_V4(cnmlBaseOp_t op,
                                                                 cnmlTensor_t input_tensor,
                                                                 void *input,
                                                                 cnmlTensor_t output_tensor,
                                                                 void *output,
                                                                 cnrtQueue_t queue,
                                                                 void *extra);
/* nearest_neighbor operation end */

/* prelu operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,create a Prelu operator.
 *  Prelu is a variation of relu operator.
 *
 *  The operator multiplies the negative part by a coefficient to create a
 *  rectification effect which is similar to breaking. By contrast, relu
 *  operator directly zeroes the negative part directly. The parameter of
 *  prelu controls the slope of rectification. When p=0.1, the operator is leaky
 *  relu operator.
 *
 *  The shapes of input and output must be the same.
 *
 *  **Formula**
 *
 *    if prelu_param.shape == [1,1,1,1]
 *
 *      out[n c h w] = in[n c h w] > 0 ? in[n c h w] : prelu_param[1,1,1,1] * in[n,c,h,w];
 *
 *    else
 *
 *      out[n c h w] = in[n c h w] > 0 ? in[n c h w] : prelu_param[1,c,1,1] * in[n,c,h,w];
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],
 *    supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor,
 *    the shape is [no, co, ho, wo](no = ni), supports data of float16 type.
 *  @param[in] prelu_param
 *    Input. A four-dimensional MLU tensor, the shape is [1, 1, 1, 1]
 *    or [1,c,1,1], supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Otherwise, return the corresponding error.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreatePreluOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor,
                                            cnmlTensor_t prelu_param);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,create a NdPrelu operator.
 *  NdPrelu is a variation of relu operator.
 *
 *  The operator multiplies the negative part by a coefficient to create a
 *  rectification effect which is similar to breaking. By contrast, relu
 *  operator directly zeroes the negative part directly. The parameter of
 *  Ndprelu controls the slope of rectification. When p=0.1, the operator is leaky
 *  relu operator.
 *
 *  The shapes of input and output must be the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A multi-dimensional MLU input tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in] nd_prelu_param
 *    Input. A multi-dimensional MLU prelu tensor, supporting data of float16 type.
 *    The channel dim is same to input or set value 1.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *    Otherwise, return the corresponding error.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdPreluOp(cnmlBaseOp_t *op,
                                              int dim,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t output_tensor,
                                              cnmlTensor_t prelu_param);

/*!
 *  @brief A function.
 *
 *  Compute the user-specified Prelu operator on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputePreluOpForward_V4 is recommended to use.
 *
 *  After creating Prelu operator, input, output and computation queue,
 *  introduce them to the function to compute the Prelu operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputePreluOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified Prelu operator on the MLU.
 *
 *  After creating Prelu operator, input, output and computation queue,
 *  introduce them to the function to compute the Prelu operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputePreluOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);

/*!
 *  @brief A function.
 *
 *  Compute the user-specified Nd Prelu operator on the MLU.
 *
 *  After creating Nd Prelu operator, input, output and computation queue,
 *  introduce them to the function to compute the Nd Prelu operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdPreluOpForward(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);

/* prelu operation end */

/* sqrt operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a square root operation operator. Perform a square
 *  root operation on the input tensor.
 *
 *  The shapes of input and output should be exactly the same.
 *  The input data must be positive.
 *
 *  **Formula**
 *
 *  output[n c h w] = input[n c h w] ^ (1 / 2);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    input_dt = output_dt
 *
 *    input[n c h w] > 0
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The input tensor type is not CNML_TENSOR or CNML_CONST.
 *    - Reason2 The CPU tensor bound by the bias tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateSqrtOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSqrtOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified square root operator on the MLU.
 *
 *  **Formula**
 *
 *  output[n c h w] = input[n c h w] ^ (1 / 2);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    input_dt = output_dt
 *
 *    input[n c h w] > 0
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlComputeSqrtOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified square root operator on the MLU.
 *
 *  **Formula**
 *
 *  output[n c h w] = input[n c h w] ^ (1 / 2);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    input_dt = output_dt
 *
 *    input[n c h w] > 0
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeSqrtOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* sqrt operation end */

/* Rsqrt operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a square root reciprocal operator.
 *
 *  The shapes of input and output shoul be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor,  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The shape of output tensor is different from that of input tensor.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateRsqrtOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeRsqrtOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified square root reciprocal operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeRsqrtOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified square root reciprocal operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeRsqrtOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* rsqrt operation end */

/* exp operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create an exponent operator with the base being e.
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateExpOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeExpOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified exponent operator with the base being e.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeExpOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified exponent operator with the base being e.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeExpOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* exp operation end */

/* reduce or operation start  */

/*!
 *  @brief cnmlCreateReduceOrOp.
 *
 *  Create a Reduce Or operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create a Reduce Or operator.
 *
 *  Performs the logic OR operation on the specified dimension of a tensor.
 *
 *  **Formula:**
 *
 *    DIM_N: out[1 c 1 1] = logic or(in[n c 1 1], DIM_N)
 *
 *    DIM_C: out[n 1 1 1] = logic or(in[n c 1 1], DIM_C)
 *
 *  **DataType:**
 *
 *    MLU270:
 *
 *      input: float16, float32, bool
 *
 *      output: float16, float32, bool
 *
 *  **Scale limitation:**
 *
 *    MLU270:
 *
 *      in FP16 and bool:
 *
 *         1. the max supported C is 65472 (8192 * 32 / 4 -64)
 *
 *      in FP32:
 *
 *         1. the max supported C is 32736 (8192 * 16 / 4 -32)
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  dim
 *    Input. A number, the dimension to be reduced by the user,
 *    supporting N, C.
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, 1, 1], supporting
 *    data of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional tensor, the size of dimensions of which the shape is reduced must be 1;
 *    the size of other dimenisions is consistent with that of input, h and w must be 1.
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReduceOrOp(cnmlBaseOp_t *op,
                                               cnmlReduce_orDim_t dim,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t output_tensor);
/*!
 *  @brief cnmlComputeReduceOrOpForward.
 *
 *  It is used to compute the user-specified Reduce Or operator on the MLU.
 *
 *  After creating the Reduce Or operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Reduce Or operator.
 *
 *  **Formula:**
 *
 *    DIM_N: out[1 c 1 1] = logic or(in[n c 1 1], DIM_N)
 *
 *    DIM_C: out[n 1 1 1] = logic or(in[n c 1 1], DIM_C)
 *
 *  **DataType:**
 *
 *    MLU270:
 *
 *      input: float16, float32, bool
 *
 *      output: float16, float32, bool
 *
 *  **Scale limitation:**
 *
 *    MLU270:
 *
 *      in FP16 and bool:
 *
 *         1. the max supported C is 65472 (8192 * 32 / 4 -64)
 *
 *      in FP32:
 *
 *         1. the max supported C is 32736 (8192 * 16 / 4 -32)
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReduceOrOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* reduce or operation end */

/* reduce and operation start */
/*!
 *
 *  @brief cnmlCreateReduceAndOp.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateReduceAndOpForward is recommended to use.
 *
 *  Create a Reduce And operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create a Reduce And operator.
 *
 *  Performs the logic AND operation on the specified dimension of a tensor.
 *
 *  **Formula:**
 *
 *    DIM_N: out[1 c 1 1] = logic and(in[n c 1 1], DIM_N)
 *
 *    DIM_C: out[n 1 1 1] = logic and(in[n c 1 1], DIM_C)
 *
 *  DataType:
 *
 *    MLU270:
 *
 *      input: float16, float32, bool
 *
 *      output: float16, float32, bool
 *
 *  Scale limitation:
 *
 *    MLU270:
 *
 *      in FP16 and bool:
 *
 *         1. the max supported C is 65472 (8192 * 32 / 4 -64)
 *
 *      in FP32:
 *
 *         1. the max supported C is 32736 (8192 * 16 / 4 -32)
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  dim
 *    Input. A number, the dimension to be reduced by the user,
 *    supporting N, C.
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, 1, 1], supporting
 *    data of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional tensor, the size of dimensions of which the shape is reduced must be 1;
 *    the size of other dimenisions is consistent with that of input, h and w must be 1.
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReduceAndOp(cnmlBaseOp_t *op,
                                                cnmlReduce_andDim_t dim,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeReduceAndOpForward.
 *
 *  It is used to compute the user-specified Reduce And operator on the MLU.
 *
 *  After creating the Reduce And operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Reduce And operator.
 *
 *  **Formula:**
 *
 *    DIM_N: out[1 c 1 1] = logic and(in[n c 1 1], DIM_N)
 *
 *    DIM_C: out[n 1 1 1] = logic and(in[n c 1 1], DIM_C)
 *
 *  **DataType:**
 *
 *    MLU270:
 *
 *      input: float16, float32, bool
 *
 *      output: float16, float32, bool
 *
 *  **Scale limitation:**
 *
 *    MLU270:
 *
 *      in FP16 and bool:
 *
 *         1. the max supported C is 65472 (8192 * 32 / 4 -64)
 *
 *      in FP32:
 *
 *         1. the max supported C is 32736 (8192 * 16 / 4 -32)
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeReduceAndOpForward(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* reduce and operation end */

/* softmax operation start */
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateSoftmaxOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user, create a probabilistic activation
 *  function operator.
 *
 *  **Summary**
 *
 *  Such as when ``input[ni, ci, hi, wi]``, ``output[no, co, ho, wo]`` and `d` direction is `c`,
 *  then
 *    ``output[n, c, h, w] = softmax(n, c, h, w) = exp(input[n, c, h, w]) / sum_i(exp(input[n, i, h,
 *     w]))``
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *  For better performance, all of the following conditions are met:
 *
 *  - when 'd' direction is 'c'
 *
 *  - The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] dim
 *    Input. An input tensor that specifies a different dimensional direction to compute softmax.
 *  All of the four dimensions N,C,H,W can be specified.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci], supports data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co], the shape of
 *  output is the same as that of input. supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The shape of output tensor is different from that of input tensor.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSoftmaxOp(cnmlBaseOp_t *op,
                                              cnmlDimension_t dim,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a probabilistic activation
 *  function operator.
 *
 *  **Summary**
 *
 *  Such as when ``input[ni, ci, hi, wi]``, ``output[no, co, ho, wo]`` and `d` direction is `c`,
 *  then
 *    ``output[n, c, h, w] = softmax(n, c, h, w) = exp(input[n, c, h, w]) / sum_i(exp(input[n, i, h,
 *   w]))``
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  For better performance, all of the following conditions are met:
 *
 *  - when 'd' direction is 'c'
 *
 *  - The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] dim
 *    Input. An input tensor that specifies a different dimensional direction to compute softmax.
 *  All of the four dimensions N,C,H,W can be specified.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci], supports data of
 *  float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co], the shape of
 *  output is the same as that of input. supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSoftmaxOpForward(cnmlBaseOp_t *op,
                                                     cnmlDimension_t dim,
                                                     cnmlTensor_t input_tensor,
                                                     cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSoftmaxOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified probabilistic activation function operator.
 *
 *  **Summary**
 *
 *  Such as when ``input[ni, ci, hi, wi]``, ``output[no, co, ho, wo]`` and `d` direction is `c`,
 *  then
 *  ``output[n, c, h, w] = softmax(n, c, h, w) = exp(input[n, c, h, w]) / sum_i(exp(input[n, i, h,
 *  w]))``
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output position.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address, which records runtime degree of data parallelism
 *  and equipment affinity.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.

 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftmaxOpForward_V3(cnmlBaseOp_t op,
                                                         void *input,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified probabilistic activation function operator.
 *
 *  **Summary**
 *
 *  Such as when ``input[ni, ci, hi, wi]``, ``output[no, co, ho, wo]`` and `d` direction is `c`,
 *  then
 *  ``output[n, c, h, w] = softmax(n, c, h, w) = exp(input[n, c, h, w]) / sum_i(exp(input[n, i, h,
 *  w]))``
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type = output_type : float16 or float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  For better performance, all of the following conditions are met:
 *
 *  - when 'd' direction is 'c'
 *
 *  - The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftmaxOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor,
                                                         void *input,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* softmax operation end */

/* nd softmax operation begin */
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateNdSoftmaxOpForward is recommended to use.
 *
 *  According to the base operator pointer given by the user,
 *  create a multi-dimensional probabilistic activation function.
 *
 *  Input and output should have the same shape.
 *
 *  Support 1 to n-dimensional Tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] dim
 *    Input. Specify a different dimensional direction to compute softmax.
 *    All of the four dimensions N,C,H,W can be specified.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdSoftmaxOp(cnmlBaseOp_t *op,
                                                int dim,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a multi-dimensional probabilistic activation function.
 *
 *  Input and output should have the same shape.
 *
 *  Support 1 to n-dimensional Tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] dim
 *    Input. Specify a different dimensional direction to compute softmax.
 *    All of the four dimensions N,C,H,W can be specified.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateNdSoftmaxOpForward(cnmlBaseOp_t *op,
                                                       int dim,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdSoftmaxOpForward_V2 is recommended to use.
 *
 *  For computing a multi-dimensional probabilistic activation function.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] type
 *    Input. An enumeration constant, representing a task type of runtime.
 *  @param[in] stream
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeNdSoftmaxOpForward(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing a multi-dimensional probabilistic activation function.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdSoftmaxOpForward_V2(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* softmax pro operation end */

/* log operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a logarithm operator with the base being e.
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor. supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *  The shape of output tensor is different from that of input tensor.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateLogOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLogOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified logarithmic operator with the base being e.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and
 *    device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeLogOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified exponent operator with the base being e.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeLogOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* log operation end */

/* floor operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a floor operator.
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateFloorOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeFloorOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified rounding down operator.
 *
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and
 *    device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeFloorOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified rounding down operator.
 *
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeFloorOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* floor operation end */

/* power operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a power operator.
 *
 *  Then creates a pointer to the base operator address, input output tensor,
 *  and introduce them into the function to create a function operator.
 *
 *  Input and output should have the same shape.
 *
 *  The maximum value of power_c: it must be ensured that output is the representable
 *  range of float16, which is [-65504,65504], e.g., when input is 3, the maximum
 *  value of power_c is 10.09.
 *
 *  The minimum value of inputs: because 2^-24 is the representable minimum value of float16,
 *  the minimum of value of input should be greater than pow(2^-24, 1/power_c). If the input
 *  is lower than that, the output will be approximated to 0.
 *
 *  The value of inputs can be negative if the power_c is a integer. If the power_c is not a
 *  integer, for example 2.5, the value of input should be positive.
 *
 *  **Formula**
 *
 *    output[n c h w] = in[n c h w] ^ power_c;
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     input_dt = output_dt
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    -65504 < power_c < 65504
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] power_c
 *    Input. A float type data, the maximum value of power_c
 *    must ensure that output is the representable range of float16,
 *    which is [-65504,65504].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input pointer is null.
 *    - Reason3 The output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreatePowerOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor,
                                            float power_c);
/*!
 *  @brief A function.
 *
 *  According to the power operator given by the user, enable high precision mode.
 *
 *  If the high precision mode is set, the precision will be improved when input interval
 *  is [0,1].
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer to the base operator address.
 *  @param[in] high_precision_flag
 *    Input. The flag for setting high precision mode.
 *    True flag set the high precision mode.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    Op is a null pointer.
 */

CNML_DLL_API cnmlStatus_t cnmlSetPowerHighPrecision(cnmlBaseOp_t *op, bool high_precision_flag);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputePowerOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified power operator on the MLU.
 *
 *  After creating power operator, input, output and computation stream,
 *  introduce them to the function to compute the power operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = in[n c h w] ^ power_c;
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     input_dt = output_dt
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    -65504 < power_c < 65504
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and
 *    device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputePowerOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified power operator on the MLU.
 *
 *  After creating power operator, input, output and computation stream,
 *  introduce them to the function to compute the power operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = in[n c h w] ^ power_c;
 *
 *  **Datatype**
 *
 *    MLU270:
 *
 *     input_dt = output_dt
 *
 *     float16, float32
 *
 *  **Scale Limitation**
 *
 *    -65504 < power_c < 65504
 *
 *  **Performance Optimization**
 *
 *    The value of C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputePowerOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* power operation end */

/* unarySelect operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create an unitary select operator.
 *
 *  Then creates a pointer to the base operator address, input output tensor,
 *  and introduce them into the function to create an unitary select operator.
 *
 *  2 input and output should have the same shape, input1 is data to be selected,
 *  input2 is an option, the value of input2 can only be filled with 1 or 0,
 *  or true or false.
 *
 *  **Formula**
 *
 *    count_output: seleted num
 *
 *    output[i] = select(input[k], index[k])
 *
 *    input= [1, 2, 3, 4], [5, 6, 7, 8]
 *
 *    index= [0, 1, 1, 0], [0, 1, 0, 0]
 *
 *    output= [2, 3, 6]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      input: 1 c 1 1
 *
 *      index: 1 c 1 1
 *
 *      output:1 c 1 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape is [1, ci, 1, 1],
 *    only supports data of float16 type.
 *  @param[in] input_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape is [1, ci, 1, 1],
 *    only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [1, ci, 1, 1],
 *    only supports data of float16 type.
 *  @param[in] count_cnml
 *    Input. A four-dimensional MLU tensor, the shape is [1, 1, 1, 1],
 *    only supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input pointer is null.
 *    - Reason3 The output pointer is null.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateUnarySelectOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t input_tensor_1,
                                                  cnmlTensor_t input_tensor_2,
                                                  cnmlTensor_t output_tensor,
                                                  cnmlTensor_t count_cnml);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeUnarySelectOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified unary select operator on the MLU.
 *
 *  After creating unary select operator, input, output and computation stream,
 *  introduce them to the function to compute the unary select operator.
 *
 *  **Formula**
 *
 *    output[i] = select(input[k], index[k])
 *
 *    input= [1, 2, 3, 4], [5, 6, 7, 8]
 *
 *    index= [0, 1, 1, 0], [0, 1, 0, 0]
 *
 *    output= [2, 3, 6]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      input: 1 c 1 1
 *
 *      index: 1 c 1 1
 *
 *      output:1 c 1 1
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] count
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and
 *    device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The runtime task type is invalid.
 *
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeUnarySelectOpForward_V3(cnmlBaseOp_t op,
                                   void *input_1,
                                   void *input_2,
                                   void *output,
                                   void *count,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified unary select operator on the MLU.
 *
 *  After creating unary select operator, input, output and computation queue,
 *  introduce them to the function to compute the unary select operator.
 *
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] count_tensor
 *    Input.  Count MLU tensor pointer. Pass NULL if not used.
 *  @param[out] count
 *    Output. An MLU address pointing to count position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeUnarySelectOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor1,
                                                             void *input_1,
                                                             cnmlTensor_t input_tensor2,
                                                             void *input_2,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnmlTensor_t count_tensor,
                                                             void *count,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* unarySelect operation end */

/* dyadicSelect operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a binary select operator.
 *
 *  Then creates a pointer to the base operator address and input output tensor,
 *  and introduce them into the function to create a binary select operator.
 *
 *  Three inputs and one output should have the same shape, input1 and input2 are
 *  two portions of data to be selected, input3 is an option, the value of
 *  Input3 can only be filled with 1 or 0.
 *
 *  **Formula**
 *
 *    batch_index = false:
 *
 *      for (int i = 0;i < n * h * w * c;i++) {
 *
 *        if (in3[i] == 0) out[i] = in1[i];
 *
 *        if (in3[i] != 0) out[i] = in2[i];
 *
 *      }
 *
 *    batch_index = true:
 *
 *      for (int i = 0;i < n;i++) {
 *
 *        if (in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in1[i * h * w * c + j];
 *
 *          }
 *
 *        }
 *
 *         if (!in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in2[i * h * w * c + j];
 *
 *          }
 *        }
 *      }
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input1,input2: float16, float32
 *
 *      input3: uint32, bool
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor_1
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],
 *    only supports data of float16 type.
 *  @param[in] output_tensor_2
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],
 *    only supports data of float16 type..
 *  @param[in] input_tensor_3
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, ci, hi, wi],
 *    only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [ni, ci, hi, wi],
 *    only supports data of float16 type..
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input pointer is null.
 *    - Reason3 The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDyadicSelectOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor_1,
                                                   cnmlTensor_t input_tensor_2,
                                                   cnmlTensor_t input_tensor_3,
                                                   cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, set the attribut of cnmlBaseOp_t;
 *
 *  **Formula**
 *
 *    batch_index = false:
 *
 *      for (int i = 0;i < n * h * w * c;i++) {
 *
 *        if (in3[i] == 0) out[i] = in1[i];
 *
 *        if (in3[i] != 0) out[i] = in2[i];
 *
 *      }
 *
 *    batch_index = true:
 *
 *      for (int i = 0;i < n;i++) {
 *
 *        if (in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in1[i * h * w * c + j];
 *
 *          }
 *
 *        }
 *
 *         if (!in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in2[i * h * w * c + j];
 *
 *          }
 *        }
 *      }
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input1,input2: float16, float32
 *
 *      input3: uint32, bool
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to the address of struct of cnmlBaseOp_t.
 *  @param[in] bool_index
 *    Input. If bool_index is flase, the value of tensor_c can be arbitrary number,
 *    if bool_index is true, the value of tensor_c is only 0 or 1;
 *  @param[in] batch_index
 *    Input. If batch_index is false, the shape of tensor_c is [n, c, h, w];
 *    if batch_index is true, the shape of tensor_c is [n, 1, 1, 1]
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */

CNML_DLL_API cnmlStatus_t cnmlDyadicSelectOpSetParam(cnmlBaseOp_t op,
                                                     bool bool_index,
                                                     bool batch_index);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeDyadicSelectOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified binary select operator on the MLU.
 *
 *  After creating binary select operator, input, output and computation stream,
 *  introduce them to the function to compute the binary  select operator.
 *
 *  **Formula**
 *
 *    batch_index = false:
 *
 *      for (int i = 0;i < n * h * w * c;i++) {
 *
 *        if (in3[i] == 0) out[i] = in1[i];
 *
 *        if (in3[i] != 0) out[i] = in2[i];
 *
 *      }
 *
 *    batch_index = true:
 *
 *      for (int i = 0;i < n;i++) {
 *
 *        if (in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in1[i * h * w * c + j];
 *
 *          }
 *
 *        }
 *
 *         if (!in3[i]) {
 *
 *          for (int j = 0;j < h * w * c;j++) {
 *
 *            out[i * h * w * c + j] = in2[i * h * w * c + j];
 *
 *          }
 *        }
 *      }
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input1,input2: float16, float32
 *
 *      input3: uint32, bool
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_3
 *    Input. An MLU address pointing to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records
 *    the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeDyadicSelectOpForward_V3(cnmlBaseOp_t op,
                                    void *input_1,
                                    void *input_2,
                                    void *input_3,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified binary select operator on the MLU.
 *
 *  After creating binary select operator, input, output and computation queue,
 *  introduce them to the function to compute the binary  select operator.
 *
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer1. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. MLU address pointing to input1 data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer2. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. MLU address pointing to input2 data.
 *  @param[in] input_tensor3
 *    Input. Input MLU tensor pointer3. Pass NULL if not used.
 *  @param[in] input_3
 *    Input. MLU address pointing to input3 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeDyadicSelectOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor1,
                                                              void *input_1,
                                                              cnmlTensor_t input_tensor2,
                                                              void *input_2,
                                                              cnmlTensor_t input_tensor3,
                                                              void *input_3,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* dyadicSelect operation end */

/* abs operation start */
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlCreateAbsOpForward
 *  is recommended to use.
 *
 *  According to the base operator pointer given by the user,
 *  create an absolute value operator.
 *
 *  Then creates a pointer to the base operator address, input output tensor,
 *  and introduce them into the function to create an absolute value operator.
 *
 *  The shapes of Input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input_type : unlimited.
 *
 *      output_type : unlimited.
 *
 *      in_oc_type : float16/float32.
 *
 *      output_oc_type : the same as in_oc_type.
 *
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input pointer is null.
 *    - Reason3 The output pointer is null.
 * */

CNML_DLL_API cnmlStatus_t cnmlCreateAbsOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified absolute value operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *  Then creates a pointer to the base operator address, input output tensor,
 *  and introduce them into the function to create an absolute value operator.
 *
 *  The shapes of Input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor, only supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The input pointer is null.
 *    - Reason3 The output pointer is null.
 * */
CNML_DLL_API cnmlStatus_t cnmlCreateAbsOpForward(cnmlBaseOp_t *op,
                                                 cnmlTensor_t input_tensor,
                                                 cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified absolute value operator on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAbsOpForward_V4
 *  is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records
 *    the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeAbsOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified absolute value operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeAbsOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* abs operation end */

/* softplus operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,create a softplus operator,
 *  then create a pointer to the base operator address and softplus operator input output tensor,
 *  introduce them into the function to create a softplus operator.
 *
 *  SoftPlus can be seen as a smoothed ReLu, it is an analytic function form of a smooth
 *  approximation to ReLu.
 *
 *  log ( exp ( input[ n, c, h, w ] ) + 1.0 ).
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] input_tensor
 *    input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input tensor type is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSoftplusOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSoftplusOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified softplus operator.
 *
 *  After creating softplus operator, input, output and computation stream,
 *  introduce them to the function to compute the softplus operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Input.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the struct address, which records runtime degree of data parallelism
 *    and equipment affinity.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftplusOpForward_V3(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified softplus operator.
 *
 *  After creating softplus operator, input, output and computation stream,
 *  introduce them to the function to compute the softplus operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftplusOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* softplus operation end */

/* minus operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,create a Minus operator.
 *
 *  Then creates a pointer to the base operator address and Minus operator input output tensor,
 *  introduce them into the function to create a Minus operator. The operator can realize negation
 *  on each dimension, output [ n, c, h, w ] = 0.0 - input [ n, c, h, w ].
 *
 *  The shapes of input and output should be exactly the same.
 *
 *  Deprecated.
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] input
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output
 *    Input.  A 1 to n-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input tensor type is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMinusOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified Minus operator.
 *
 *  After creating Minus operator, input, output and computation stream, introduce them
 *  to the function to compute the Minus operator.
 *
 *  Deprecated.
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Input.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the struct address, which records runtime degree of data parallelism
 *    and equipment affinity.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinusOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified Minus operator.
 *
 *  After creating Minus operator, input, output and computation queue, introduce them
 *  to the function to compute the Minus operator.
 *
 *  Deprecated.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinusOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* minus operation end */

/* avg operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create an avg operator.
 *
 *  After creating a pointer to the base operator address and operator input output tensor,
 *  introduce them into the function to create an avg operator. The operator can be used to
 *  find the averages on the H and W dimensions, including an input and output.
 *
 *  Can only be used on the H or W dimension.
 *
 *  Deprecated.
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[out] output
 *    Output.  A four-dimensional MLU input tensor, the shape is [1, 1, 1, 1],
 *    supports data of float16 type.
 *  @param[in] input
 *    Input.  A four-dimensional MLU input tensor, the shape is [1, hi, wi, 1],
 *    supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input tensor type is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAvgOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Computethe user-specified Avg operator.
 *
 *  After creating Avg operator, input, output and computation stream,
 *  introduce them to the function to compute the Avg operator.
 *
 *  Deprecated.
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Output.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the struct address, which records runtime degree of data parallelism
 *    and equipment affinity.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAvgOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computethe user-specified Avg operator.
 *
 *  After creating Avg operator, input, output and computation queue,
 *  introduce them to the function to compute the Avg operator.
 *
 *  Deprecated.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAvgOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* avg operation end */

/* sign opeartion start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user,
 *  create a sign operator. A sign operator is that, y=1 if x>0; y=0 if x=0; y=-1 if x<0.
 *
 *  Then creates a pointer to the base operator address, input output tensor,
 *  and introduce them into the function to create a sign operator.
 *
 *  The shapes of Input and output should be exactly the same.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSignOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  For computing the user-specified sign operator on the MLU.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. An pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records
 *    the degree of data parallelism and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSignOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  For computing the user-specified sign value operator on the MLU.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeSignOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* sign opearetion end */

/* vector2norm operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a Vector2Norm operator.
 *
 *  After creating a pointer to the base operator address and operator input output tensor,
 *  introduce them into the function to create a Vector2Norm operator. The operator can find the L2
 *  norm of input data in channel, height, width dimensions, and each batch will get an output
 *  value.
 *
 *  Output is [ni, 1, 1, 1].
 *
 *  Deprecated.
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] input
 *    Input.  A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    supports data of float16 type.
 *  @param[in] output
 *    Input.  A four-dimensional MLU input tensor, the shape is [batch, 1, 1, 1],
 *    supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input tensor type is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateVector2NormOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeVector2NormOpForward_V4 is recommended to use.
 *
 *  Computethe user-specified Vector2Norm operator.
 *
 *  After creating Vector2Norm operator, input, output and computation stream,
 *  introduce them to the function to compute the Vector2Norm operator.
 *
 *  Deprecated.
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Output.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the struct address, which records runtime degree of data parallelism
 *    and equipment affinity.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeVector2NormOpForward_V3(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Computethe user-specified Vector2Norm operator.
 *
 *  After creating Vector2Norm operator, input, output and computation queue,
 *  introduce them to the function to compute the Vector2Norm operator.
 *
 *  Deprecated.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeVector2NormOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* vector2norm operation end */

/* cast operation start */

/*!
 *  @brief cnmlCreateCastOp.
 *
 *  According to the base operator pointer given by the user, create a cast operator.
 *  After creating a pointer to the base operator address, operator input output tensor, and
 *  CastType, introduce them into the function to create a Cast operator. The operator can be used
 *  to realize data type conversion of tensor. Supports 9 types of data type conversions, which are
 *  float32_to_uint8, uint8_to_float32, float16_to_float32, float32_to_float16, fix8_to_float16,
 *  int8_to_float16, float16_to_fix8, int16_to_float16 and float16_to_int16.
 *  Points for attention different data types correspond to different input restrictions, e.g.,
 *  for float32->uint8, the output should be in [0,255];
 *  When input or output is in int8 format, position value of the corresponding data range
 *  should be set;
 *  The shapes of input and output should be the same.
 *
 *  **Formula**
 *
 *    Change the input data from input's datatype to output's datatype.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float32 uint8 float16 int8 int16
 *
 *      output: float32 uint8 float16 int8 int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      input_shape's c < 63000
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[out]  output
 *    Output. A four-dimensional MLU input tensor, the shape is [batch, height, width, depth],
 *    supports data of the following types: float32 uint8 float16 int8 int16.
 *  @param[in]  cast_type
 *    Input. An enumeration constant that represents the data type conversion method.
 *  @param[in]  input
 *    Input. A four-dimensional MLU input tensor, the shape is [batch, height, width, depth],
 *    supports data of the following types: float32 uint8 float16 int8 int16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - input tensor type is not CNML_TENSOR
 *
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCastOp(cnmlBaseOp_t *op,
                                           cnmlCastType_t cast_type,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);
/*!
 *  @brief cnmlCreateCastOpForward.
 *
 *  According to the base operator pointer given by the user, create a cast operator.
 *  After creating a pointer to the base operator address, operator input output tensor, and
 *  CastType, introduce them into the function to create a Cast operator. The operator can be used
 *  to realize data type conversion of tensor. Supports 9 types of data type conversions, which are
 *  float32_to_uint8, uint8_to_float32, float16_to_float32, float32_to_float16, fix8_to_float16,
 *  int8_to_float16, float16_to_fix8, int16_to_float16 and float16_to_int16.
 *  Points for attention different data types correspond to different input restrictions, e.g.,
 *  for float32->uint8, the output should be in [0,255];
 *  When input or output is in int8 format, position value of the corresponding data range
 *  should be set;
 *  The shapes of input and output should be the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[out]  output
 *    Output. A four-dimensional MLU input tensor, the shape is [batch, height, width, depth],
 *    supports data of the following types: float32 uint8 float16 int8 int16.
 *  @param[in]  cast_type
 *    Input. An enumeration constant that represents the data type conversion method.
 *  @param[in]  input
 *    Input. A four-dimensional MLU input tensor, the shape is [batch, height, width, depth],
 *    supports data of the following types: float32 uint8 float16 int8 int16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - input tensor type is not CNML_TENSOR
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCastOpForward(cnmlBaseOp_t *op,
                                                  cnmlCastType_t cast_type,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeCastOpForward_V3.
 *
 *  Compute the user-specified Cast operator.
 *  After creating Cast operator, input, output and computation stream, introduce them to the
 *  function to compute the Cast operator.
 *
 *  **Formula**
 *
 *    Change the input data from input's datatype to output's datatype
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float32 uint8 float16 int8 int16
 *
 *      output: float32 uint8 float16 int8 int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      input_shape's c < 63000
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCastOpForward_V4 is recommended to use.
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output position.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the struct address, which records runtime degree of data parallelism and
 *    equipment affinity.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCastOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeCastOpForward_V4.
 *
 *  Compute the user-specified Cast operator.
 *  After creating Cast operator, input, output and computation queue, introduce them to the
 *  function to compute the Cast operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCastOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* cast operation end */

/* nms operation start */
/*!
 *  @struct cnmlNmsOpParam
 *  @brief A struct.
 *
 *  cnmlNmsOpParam is a structure describing the param parameter of nms operation, used to create
 *  nms operation. cnmlCreateNmsOpParam() is used to create an instance of cnmlNmsOpParam_t.
 *  cnmlDestroyNmsOpParam() is used to destroy an instance of cnmlNmsOpParam_t. */
struct cnmlNmsOpParam;
/*! ``cnmlNmsOpParam_t`` is a pointer to ``cnmlNmsOpParam`` which is a
    structure holding the description of a nms operation param. */
typedef struct cnmlNmsOpParam *cnmlNmsOpParam_t;

/*!
 *  @brief cnmlCreateNmsOpParam.
 *
 *  According to the pointer given by the user, the function creates a struct of computation
 *  parameters of Nms, and fills the parameters input by the user to the struct.
 *
 *  @param[out]  param
 *    Output. A pointer to the address of the struct of computation parameters for Nms operator.
 *  @param[in]  box_size
 *    Input. An integer tensor, the number of candidate boxes.
 *  @param[in]  out_size
 *    Input. An integer tensor, representing the maximum number of boxes selected through NMS.
 *  @param[in]  nms_thresh
 *    Input. A threshold representing the determination of whether a box has too much overlap with
 *    IoU (Intersection over Union, a standard for gauging the degree of accuracy of
 *    an object in a specific dataset).
 *  @param[in]  nms_scale
 *    Input. A single score corresponding to each box.
 *  @param[in]  score_thresh
 *    Input. score threshold.
 *  @param[in]  filter_scores
 *    Input. bool value, whether to zoom.
 *  @param[in]  normalized_bbox
 *    Input. A candidate box after normalize.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    -param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNmsOpParam(cnmlNmsOpParam_t *param,
                                               int box_size,
                                               int out_size,
                                               float nms_thresh,
                                               float nms_scale,
                                               float score_thresh,
                                               bool filter_scores,
                                               bool normalized_bbox);

/*!
 *  @brief cnmlDestroyNmsOpParam.
 *
 *  The function destroys an Nms computation parameters struct according to the pointer given by the
 *  user.
 *
 *  @param[in]  param
 *    Input. A pointer to the address of the struct of computation parameters for Nms operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    -param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNmsOpParam(cnmlNmsOpParam_t *param);

/*!
 *  @brief cnmlCreateNmsOp.
 *
 *  According to the base operator pointer given by the user, create an Nms operator.
 *
 *  After creating a pointer to the base operator address, Nms operator computation parameters and
 *  input output tensor, introduce them into the function to create an Nms operator.
 *
 *  Before creating the Nms operator, declare a pointer to the address of the struct of computation
 *  parameters for the Nms operator as well as the required operator parameters to the function to
 *  set the operator parameters.
 *
 *  The C dimension of output should be exactly divisible by 16;
 *
 *  N, H, W dimensions of input must be 1, 1, 5.
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  param
 *    Input. An Nms computation struct pointer.
 *  @param[in]  input_tensor
 *    Input. A four-dimensional MLU input tensor, the shape is [1, box_size, 1, 5], supports data of
 *    float16 type.
 *  @param[in]  output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [1, output_size, 1, 5], supports
 *    data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The input tensor type is not CNML_TENSOR or CNML_CONST.
 *    - The CPU tensor bound by the bias tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNmsOp(cnmlBaseOp_t *op,
                                          cnmlNmsOpParam_t param,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeNmsOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNmsOpForward_V4 is recommended to use.
 *
 *  For computing the user-specified Nms operator on the MLU.
 *
 *  After creating Nms operator, related parameters and computation stream, introduce them into the
 *  function to compute the Nms operator.
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output position.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the struct address, which records runtime degree of data parallelism and
 *    equipment affinity.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions is not met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNmsOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeNmsOpForward_V4.
 *
 *  For computing the user-specified Nms operator on the MLU.
 *
 *  After creating Nms operator, related parameters and computation stream, introduce them into the
 *  function to compute the Nms operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNmsOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* nms operation end */

/* grep operation start */
/*!
 *  @struct cnmlGrepOpParam
 *  @brief A struct.
 *
 *  cnmlGrepOpParam is a structure describing the param parameter of grep operation, used to create
 *  grep operation. cnmlCreateGrepOpParam() is used to create an instance of cnmlGrepOpParam_t.
 *  cnmlDestroyGrepOpParam() is used to destroy an instance of cnmlGrepOpParam_t. */
struct cnmlGrepOpParam;
/*! ``cnmlGrepOpParam_t`` is a pointer to ``cnmlGrepOpParam`` which is a
    structure holding the description of a grep operation param. */
typedef struct cnmlGrepOpParam *cnmlGrepOpParam_t;

/*!
 *  @brief cnmlCreateGrepOpParam.
 *
 *  This function creates a Grep operation parameter struct based on the pointer given by the user,
 *  and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  param
 *    Output. A pointer to the address of the Grep operator operation parameter struct.
 *  @param[in]  start_index_N
 *    Input. A starting point of interception in the direction of N, int data type.
 *  @param[in]  start_index_H
 *    Input. A starting point of interception in the direction of H, int data type.
 *  @param[in]  start_index_W
 *    Input. A starting point of interception in the direction of W, int data type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    -param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrepOpParam(cnmlGrepOpParam_t *param,
                                                int start_index_N,
                                                int start_index_H,
                                                int start_index_W,
                                                float space_number);

/*!
 *  @brief cnmlDestroyGrepOpParam.
 *
 *  This function destroys a Grep operator operation parameter struct based on the pointer given by
 *  the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in]  param
 *    Input. A pointer to the address of the Grep operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    -param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyGrepOpParam(cnmlGrepOpParam_t *param);

/*!
 *  @brief cnmlCreateGrepOp.
 *
 *  It creates a Grep operator based on the base operator pointer given by the user.
 *
 *  After a pointer to the base operator address is created and the Grep operator inputs and outputs
 *  the Tensor, they are passed to the function to create a Grep operator.
 *
 *  Before creating the Grep operator, declare a pointer to the address of the Grep operator
 *  operation parameter struct and pass it to the function with the desired operation parameters to
 *  set the operator parameters.
 *
 *  **Formula**
 *
 *    Output [no, ho, wo, co]= input[(start_n : start_n + no) ,(start_h : start_h + ho), (start_w :
 * start_w + wo), c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  param
 *    Input. An ImageDetect operation struct pointer.
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, hi, wi, c], supporting
 *    data of type float16.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU output tensor, of which the shape is [no, ho, wo, c], supporting
 *    data of type float16.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - The input tensor type is either CNML_TENSOR or CNML_CONST.
 *    - The CPU tensor bound to the bias tensor is empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrepOp(cnmlBaseOp_t *op,
                                           cnmlGrepOpParam_t param,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeGrepOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeGrepOpForward_V4 recommended to use.
 *
 *  It is used to compute the user-specified Grep operator on the MLU.
 *
 *  After creating the Grep operator, related parameters and computation stream, pass them to the
 *  function to It is used to compute the Grep operator.
 *
 *  **Formula**
 *
 *    Output [no, ho, wo, co]= input[(start_n : start_n + no) ,(start_h : start_h + ho), (start_w :
 *    start_w + wo), c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGrepOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeGrepOpForward_V4.
 *
 *  It is used to compute the user-specified Grep operator on the MLU.
 *
 *  After creating the Grep operator, related parameters and computation queue, pass them to the
 *  function to It is used to compute the Grep operator.
 *
 *  **Formula**
 *
 *    Output [no, ho, wo, co]= input[(start_n : start_n + no) ,(start_h : start_h + ho), (start_w :
 *    start_w + wo), c]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: int8, int16, float16, float32
 *
 *      output: same as input
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGrepOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* grep operation end */

/* argmax operation start */
/*!
 *  @brief A function.
 *
 *  This function creates an argmax operator based on the base operator pointer given by the user.
 *
 *  The operator contains input, axis and output. The coordinates of the maximum value are found in
 *  the dimension selected by the axis. For the plurality of numbers with the same value in the cpu,
 *  the coordinates are arranged in ascending order, and the mlu is arranged in descending order of
 *  coordinates.
 *
 *  Support four-dimensional tensor. The scale restrictions include:
 *
 *  if axis == D_N, output has the shape of [1,c,h,w];
 *
 *  if axis == D_C, output has the shape of [n,1,h,w];
 *
 *  if axis == D_H, output has the shape of [n,c,1,w];
 *
 *  if axis == D_W, output has the shape of [n,c,h,1].
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute the index of max value of given direction.
 *
 *    such as direction is n, output[1, c, h, w]
 *
 *    such as direction is c, output[n, 1, h, w]
 *
 *    ...
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      value_data_type = input_data_type:float16, float32
 *
 *      index_data_type:
 *
 *       if direction is c, index_data_type = int32
 *
 *       else if input_data_type = float16 then index_data_type = int16
 *
 *       else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *      align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *      input_dt == float16: ct_line_num = 32
 *
 *      input_dt == float32: ct_line_num = 64
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] output_tensor
 *    Input. A four-dimensional tensor, of which the shape is [batch,depth,height,width],
 *    supporting data of type float16.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, of which the shape is [batch,depth,height,width],
 *    supporting data of type float16.
 *  @param[in] argmax_mode
 *    Input. An enumerator representing the dimension in which the Argmax is calculated. It's value
 *  can be taken from these: CNML_ARGMAX_AXIS_N = 0, CNML_ARGMAX_AXIS_C = 1, CNML_ARGMAX_AXIS_H = 2,
 *  CNML_ARGMAX_AXIS_W = 3.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - The operator pointer is empty.
 *    - The input and output is empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateArgmaxOp(cnmlBaseOp_t *op,
                                             cnmlDimension_t argmax_mode,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  It is used to compute the user-specified Argmax operator on the MLU.
 *
 *  After creating the argmax operator, related parameters and computation stream, pass them to the
 *  function to It is used to compute the Argmax operator.
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute the index of max value of given direction.
 *
 *    such as direction is n, output[1, c, h, w]
 *
 *    such as direction is c, output[n, 1, h, w]
 *
 *    ...
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      value_data_type = input_data_type:float16, float32
 *
 *      index_data_type:
 *
 *       if direction is c, index_data_type = int32
 *
 *       else if input_data_type = float16 then index_data_type = int16
 *
 *       else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *      align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *      input_dt == float16: ct_line_num = 32
 *
 *      input_dt == float32: ct_line_num = 64
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeArgmaxOpForward_V4
 *  is recommended to use.
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output data.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data tensor.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeArgmaxOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  It is used to compute the user-specified Argmax operator on the MLU.
 *
 *  After creating the argmax operator, related parameters and computation stream, pass them to the
 *  function to It is used to compute the Argmax operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeArgmaxOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/*!
 *  @brief cnmlCreateNdArgmaxOp.
 *
 *  This function creates an argmax operator based on the base operator pointer given by the user.
 *
 *  The operator contains input, axis and output. The coordinates of the maximum value are found in
 *  the dimension selected by the axis. For the plurality of numbers with the same value in the cpu,
 *  the coordinates are arranged in ascending order, and the mlu is arranged in descending order of
 *  coordinates.
 *
 *  Support non-four-dimensional and four-dimensional tensor.The scale restrictions include:
 *
 *  if axis == D_N, output has the shape of [1,c,h,w];
 *
 *  if axis == D_C, output has the shape of [n,1,h,w];
 *
 *  if axis == D_H, output has the shape of [n,c,1,w];
 *
 *  if axis == D_W, output has the shape of [n,c,h,1].
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] output_tensor
 *    Output. A n-dimensional MLU tensor, supporting data of type float16.
 *  @param[in] input_tensor
 *    Input. A  n-dimensional MLU tensor, supporting data of type float16.
 *  @param[in] dim
 *    Input. specify different dimension directions to compute argmax, where all of four dimensions
 *    N, C, H, W can be specified.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - The operator pointer is empty.
 *    - The input and output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdArgmaxOp(cnmlBaseOp_t *op,
                                               int dim,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeNdArgmaxOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdArgmaxOpForward_V2 is recommended to use.
 *
 *  Compute an argmax function that supports four or more dimensions tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output data.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address pointing to the input data tensor.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdArgmaxOpForward(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeNdArgmaxOpForward.
 *
 *  Compute an argmax function that supports four or more dimensions tensor.
 *
 *  **Supports both MLU220 and MLU270.**
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdArgmaxOpForward_V2(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* argmax operation end */

/* argmin operation begin */
/*!
 *  @brief A function.
 *
 *  This function creates an argmin operator based on the base operator pointer given by the user.
 *
 *  The operator contains input, axis and output. The coordinates of the minimum value are found in
 *  the dimension selected by the axis. For the plurality of numbers with the same value in the cpu,
 *  the coordinates are arranged in ascending order, and the mlu is arranged in descending order of
 *  coordinates.
 *
 *  Support four-dimensional tensor. The scale restrictions include:
 *
 *  if axis == CNML_DIM_N, output has the shape of [1,c,h,w];
 *
 *  if axis == CNML_DIM_C, output has the shape of [n,1,h,w];
 *
 *  if axis == CNML_DIM_H, output has the shape of [n,c,1,w];
 *
 *  if axis == CNML_DIM_W, output has the shape of [n,c,h,1].
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] output_tensor
 *    Input. A four-dimensional tensor, of which the shape is [batch,depth,height,width],
 *    supporting data of type float16.
 *  @param[in] input_tensor
 *    Input. A four-dimensional MLU input tensor, of which the shape is [batch,depth,height,width],
 *    supporting data of type float16.
 *  @param[in] argmin_mode
 *    Input. An enumerator representing the dimension in which the Argmin is calculated. It's value
 *    can be taken from these: CNML_DIM_N = 0, CNML_DIM_C = 1, CNML_DIM_H = 2, CNML_DIM_W = 3
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - The operator pointer is empty.
 *    - The input and output is empty.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateArgminOp(cnmlBaseOp_t *op,
                                             cnmlDimension_t argmin_mode,
                                             cnmlTensor_t input,
                                             cnmlTensor_t output);
/*!
 *  @brief A function.
 *
 *  It is used to compute the user-specified Argmin operator on the MLU.
 *
 *  After creating the Argmin operator, related parameters and computation stream, pass them to the
 *  function to It is used to compute the Argmin operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeArgminOpForward_V3(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* argmin operation end */

/* reorg operation start */
/*!
 *  @struct cnmlReorgOpParam
 *  @brief A struct.
 *
 *  cnmlReorgOpParam is a structure describing the param parameter of reorg operation, used to
 *  create reorg operation. cnmlCreateReorgOpParam() is used to create an instance of
 *  cnmlReorgOpParam_t. cnmlDestroyReorgOpParam() is used to destroy an instance of
 *  cnmlReorgOpParam_t. */
struct cnmlReorgOpParam;
/*! ``cnmlReorgOpParam_t`` is a pointer to ``cnmlReorgOpParam`` which is a
    structure holding the description of a reorg operation param. */
typedef struct cnmlReorgOpParam *cnmlReorgOpParam_t;
/*!
 *  @brief cnmlCreateReorgOpParam.
 *
 *  The function creates a reorg operator operation parameter struct based on the pointer given by
 *  the user, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the reorg operator operation parameter struct.
 *  @param[in] reorg_h
 *    Input. The remodeling coefficient in the direction of h.If reverse is false,
 *    ho = hi / reorg_h, and in this case, hi is required to be divisible by reorg_h;
 *    if reverse is true, ho = hi * reorg_h.
 *  @param[in] reorg_w
 *    Input. The remodeling coefficient in the direction of w. If reverse is false,
 *    wo = wi / reorg_w, which requires wi to be divisible by reorg_w;
 *    if reverse is true, wo = wi * reorg _w.
 *  @param[in] reverse
 *    Input. bool value, false is forward and true is reverse (splitting or merging).
 *    If forward, co = ci * reorg_h * reorg_w. If reverse, co = ci / (reorg_h * reorg_w).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReorgOpParam(cnmlReorgOpParam_t *param,
                                                 int reorg_h,
                                                 int reorg_w,
                                                 bool reverse);

/*!
 *  @brief cnmlDestroyReorgOpParam.
 *
 *  The reorg operator operation parameter struct pointer is released according to the pointer given
 *  by the user.
 *
 *  The created reorg operator operation parameter struct pointer is released after the convolution
 *  operator operation ends.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to the address of the reorg operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyReorgOpParam(cnmlReorgOpParam_t *param);

/*!
 *  @brief cnmlCreateReorgOp.
 *
 *  Create a reorg operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, reorg operator parameters, and input and
 *  output tensors, pass them to the function to create a reorg operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] param
 *    Input. A reorg operation struct pointer.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi] and given by
 *    the user.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor, of which the shape is [no, co, ho, wo] (no = ni) and
 *    computed by cnmlGetReorgOpOutputDim based on the input dimension information.
 *    If reverse = true, co = ci / (reorg_h * reorg_w), ho = hi * reorg_h, wo = wi * reorg_w.
 *    If reverse = false, co = ci * reorg_h * reorg_w, ho = hi / reorg_h, wo = wi / reorg_w.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The input param is empty.
 *    - The input input_tensor and output_tensor are empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReorgOp(cnmlBaseOp_t *op,
                                            cnmlReorgOpParam_t param,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeReorgOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReorgOpForward_V4 is recommended to use.
 *
 *  It is used to compute the reorg operator specified by the user on the MLU.
 *
 *  After creating the reorg operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the reorg operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReorgOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeReorgOpForward_V4.
 *
 *  It is used to compute the reorg operator specified by the user on the MLU.
 *
 *  After creating the reorg operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the reorg operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReorgOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* reorg operation end */

/* yuv_to_rgb operation start */
/*!
 *  @brief cnmlCreateYUVtoRGBProOp.
 *
 *  Create a YUVtoRGB operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, Yuv type, Rgb type, and input and output
 *  tensors, pass them to the function to create a YUVtoRGB operator.
 *
 *  **Summary**
 *
 *    input_y[n, c(1), h, w] + input_uv[n, c(1), h/2, w] compute:
 *
 *    output[n, c(4), h, w] with a certain order(RGB0, BGR0, or ARGB), where
 *
 *      R = 1.164 * Y + 1.596 * V - 222.912
 *
 *      G = 1.164 * Y - 0.392 * U - 0.813 * V + 135.616
 *
 *      B = 1.164 * Y + 2.017 * U - 276.800
 *
 *      A = 0
 *
 *  **DataType**
 *
 *    Support only UINT8 for both Input/Output
 *
 *  **Scale Limitation**
 *
 *    H,W must be even
 *
 *  **Supports MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] y_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, 1, hi, wi] and given by
 *    the user.
 *  @param[in] uv_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, 1, hi/2, wi] and given by
 *    the user.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor with a shape of [no, 4, ho, wo].
 *  @param[in] yuv_type
 *    Input. Yuv type, where CNML_YUV420SP_NV12 and CNML_YUV420SP_NV21 are optional.
 *  @param[in] rgb_type
 *    Input. Rgb type, where CNML_RGB0, CNML_BGR0 and CNML_ARGB are optional.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - The input input_tensor and output_tensor are empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateYUVtoRGBProOp(cnmlBaseOp_t *op,
                                                  cnmlTensor_t y_tensor,
                                                  cnmlTensor_t uv_tensor,
                                                  cnmlTensor_t output_tensor,
                                                  cnmlYuvType_t yuv_type,
                                                  cnmlRgbType_t rgb_type);
/*!
 *  @brief cnmlComputeYUVtoRGBProOpForward_V4.
 *
 *  It is used to compute the user-specified YUVtoRGB operator on the MLU.
 *
 *  After creating the YUVtoRGB operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the YUVtoRGB operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_y_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_y
 *    Input. An MLU address pointing to input_y data.
 *  @param[in] input_uv_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_uv
 *    Input. An MLU address pointing to input_uv data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeYUVtoRGBProOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_y_tensor,
                                                             void *input_y,
                                                             cnmlTensor_t input_uv_tensor,
                                                             void *input_uv,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/*!
 *  @brief cnmlCreateGrayNormalizeForKcfOp.
 *
 *  Create a GrayNormalizeForKcf operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass
 *  them to the function to create a GrayNormalizeForKcf operator.
 *
 *  **Summary**
 *
 *    output[i] = input[i] / 255.0 - 0.5
 *
 *  **DataType**
 *
 *    Support only UINT8 for Input and only FLOAT16 for Output
 *
 *  **Scale Limitation**
 *
 *    H,W must be even
 *
 *  **Supports MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, 1, hi, wi] and given by
 *    the user.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor with a shape of [no, 1, ho, wo].
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - The input input_tensor and output_tensor are empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateGrayNormalizeForKcfOp(cnmlBaseOp_t *op,
                                                          cnmlTensor_t input_tensor,
                                                          cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeGrayNormalizeForKcfOpForward.
 *
 *  It is used to compute the user-specified GrayNormalizeForKcf operator on the MLU.
 *
 *  After creating the GrayNormalizeForKcf operator, Input, Output, runtime parameters, and
 * computation queue,
 *  pass them to the function to It is used to compute the GrayNormalizeForKcf operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeGrayNormalizeForKcfOpForward(cnmlBaseOp_t op,
                                                                  cnmlTensor_t input_tensor,
                                                                  void *input,
                                                                  cnmlTensor_t output_tensor,
                                                                  void *output,
                                                                  cnrtQueue_t queue,
                                                                  void *extra);
/*!
 *  @brief cnmlCreateYUVtoGrayOp.
 *
 *  Create a YUVtoGray operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, Yuv type, input and output tensors, pass
 *  them to the function to create a YUVtoGray operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi] and given by
 *    the user.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU output tensor with a shape of [no, co, ho, wo].
 *  @param[in] yuv_type
 *    Input. Yuv type, where CNML_YUV420SP_NV12 and CNML_YUV420SP_NV21 are optional.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - The input input_tensor and output_tensor are empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateYUVtoGrayOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlYuvType_t yuv_type);

/*!
 *  @brief cnmlComputeYUVtoGrayOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeYUVtoGrayOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified YUVtoGray operator on the MLU.
 *
 *  After creating the YUVtoGray operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the YUVtoGray operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeYUVtoGrayOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeYUVtoGrayOpForward_V4.
 *
 *  It is used to compute the user-specified YUVtoGray operator on the MLU.
 *
 *  After creating the YUVtoGray operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the YUVtoGray operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeYUVtoGrayOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* yuv_to_rgb operation end */

/* reshape operation start */
/*!
 *  @struct cnmlReshapeOpParam
 *  @brief A struct.
 *
 *  cnmlReshapeOpParam is a structure describing the param parameter of reshape operation, used to
 *  create reshape operation. cnmlCreateReshapeOpParam() is used to create an instance of
 *  cnmlReshapeOpParam_t. cnmlDestroyReshapeOpParam() is used to destroy an instance of
 *  cnmlReshapeOpParam_t. */
struct cnmlReshapeOpParam;
/*! ``cnmlReshapeOpParam_t`` is a pointer to ``cnmlReshapeOpParam`` which is a
    structure holding the description of a reshape operation param. */
typedef struct cnmlReshapeOpParam *cnmlReshapeOpParam_t;
/*
 *  when create cpu tensor, the DataOrder is up to you.
 *  when create mlu tensor, the DataOrder always is NHWC.
 *  no, co, ho, wo is the output tensor shape.
 *  df in reshape param is the same as cpu tensor DataOrder.
 */

/*!
 *  @brief cnmlCreateReshapeOpParam.
 *
 *  The function creates a reshape operator operation parameter struct according to the pointer
 *  given by the user, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the reshape operator operation parameter struct.
 *  @param[in] no
 *    Input. The length of the output n dimension.
 *  @param[in] co
 *    Input. The length of the output c dimension.
 *  @param[in] ho
 *    Input. The length of the output h dimension.
 *  @param[in] wo
 *    Input. The length of the output w dimension.
 *  @param[in] df
 *    Input. output data dimension order, which is same as the created cpu tensor dimension order.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReshapeOpParam(cnmlReshapeOpParam_t *param,
                                                   int no,
                                                   int co,
                                                   int ho,
                                                   int wo,
                                                   cnmlDataOrder_t data_order);

/*!
 *  @brief cnmlCreateNdReshapeOpParam.
 *
 *  The function creates a multi-dimension reshape operator operation parameter struct according
 *  to the pointer given by the user, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the reshape operator operation parameter struct.
 *  @param[in] dims[]
 *    Input. The array of the output dimensions.
 *  @param[in] dim_num
 *    Input. The number of the output dimensions.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdReshapeOpParam(cnmlReshapeOpParam_t *param,
                                                     int dims[],
                                                     int dim_num);

/*!
 *  @brief cnmlDestroyReshapeOpParam.
 *
 *  Release the reshape operator operation parameter struct pointer according to the pointer given
 *  by the user.
 *
 *  Release the created reshape operator operation parameter struct pointer after the reshape
 *  operator operation ends.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to the address of the reshape operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Param is a null pointer.
 *    - The pointer content pointed to by param has been released.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyReshapeOpParam(cnmlReshapeOpParam_t *param);

/*!
 *  @brief cnmlCreateReshapeOp.
 *
 *  Create a Reshape operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, reshape operator operation parameters,
 *  input and output tensors, pass them to the function to create a reshape operator.
 *
 *  **Formula**
 *
 *    Change input shape[ni ci hi wi] to output shape [no co ho wo]
 *
 *    Change input DataType to output DataType
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      if input and output DataType are same:
 *
 *         float16, float32, int8, int16, int32, uint8, uint16, uint32, bool
 *
 *      else
 *
 *        input to output:
 *
 *        uint8 to float16, int8 to float16, float16 to int8, float16 to float32,
 *        float32 to float16, int16 to float16, float16 to int16, int8 to float32,
 *        float32 to int8, int16 to float32, float32 to int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      no * co * ho * wo = ni * ci * hi * wi
 *
 *  **Performance Optimization**
 *
 *    The value of Ci and logic_c_ are the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tesor
 *    Output. A pointer to the mlu end Tensor
 *  @param[in] op
 *    Input. A pointer to the base operator
 *  @param[in] input_tensor
 *    Input. A pointer to the mlu end
 *  @param[in] param
 *    Input. A pointer to the address of the reshape operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    Op, input, output, and param are not empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReshapeOp(cnmlBaseOp_t *op,
                                              cnmlReshapeOpParam_t param,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlCreateReshapeOp_V2.
 *
 *  Create a YUVtoRGB operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create a reshape operator.
 *
 *  cnmlBindCpuDataInfo must be called before this interface is called.
 *
 *  **Formula**
 *
 *    Change input shape[ni ci hi wi] to output shape [no co ho wo]
 *
 *    Change input DataType to output DataType
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      if input and output DataType are same:
 *
 *         float16, float32, int8, int16, int32, uint8, uint16, uint32, bool
 *
 *      else
 *
 *        input to output:
 *
 *        uint8 to float16, int8 to float16, float16 to int8, float16 to float32,
 *        float32 to float16, int16 to float16, float16 to int16, int8 to float32,
 *        float32 to int8, int16 to float32, float32 to int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      no * co * ho * wo = ni * ci * hi * wi
 *
 *  **Performance Optimization**
 *
 *    The value of Ci and logic_c_ are the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tesor
 *    Output. A pointer to the mlu end Tensor
 *  @param[in] op
 *    Input. A pointer to the base operator
 *  @param[in] input_tensor
 *    Input. A pointer to the mlu end
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    Op, input, and output are not empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReshapeOp_V2(cnmlBaseOp_t *op,
                                                 cnmlTensor_t input_tensor,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeReshapeOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReshapeOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified reshape operator on the MLU.
 *
 *  After creating the reshape operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the reshape operator.
 *
 *  **Formula**
 *
 *    Change input shape[ni ci hi wi] to output shape [no co ho wo]
 *
 *    Change input DataType to output DataType
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      if input and output DataType are same:
 *
 *         float16, float32, int8, int16, int32, uint8, uint16, uint32, bool
 *
 *      else
 *
 *        input to output:
 *
 *        uint8 to float16, int8 to float16, float16 to int8, float16 to float32,
 *        float32 to float16, int16 to float16, float16 to int16, int8 to float32,
 *        float32 to int8, int16 to float32, float32 to int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      no * co * ho * wo = ni * ci * hi * wi
 *
 *  **Performance Optimization**
 *
 *    The value of Ci and logic_c_ are the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReshapeOpForward_V3(cnmlBaseOp_t op,
                                                         void *input,
                                                         void *output,
                                                         cnrtInvokeFuncParam_t *compute_forw_param,
                                                         cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeReshapeOpForward_V3.
 *
 *  It is used to compute the user-specified reshape operator on the MLU.
 *
 *  After creating the reshape operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the reshape operator.
 *
 *  **Formula**
 *
 *    Change input shape[ni ci hi wi] to output shape [no co ho wo]
 *
 *    Change input DataType to output DataType
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      if input and output DataType are same:
 *
 *         float16, float32, int8, int16, int32, uint8, uint16, uint32, bool
 *
 *      else
 *
 *        input to output:
 *
 *        uint8 to float16, int8 to float16, float16 to int8, float16 to float32,
 *        float32 to float16, int16 to float16, float16 to int16, int8 to float32,
 *        float32 to int8, int16 to float32, float32 to int16
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      no * co * ho * wo = ni * ci * hi * wi
 *
 *  **Performance Optimization**
 *
 *    The value of Ci and logic_c_ are the same.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReshapeOpForward_V4(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor,
                                                         void *input,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* reshape operation end */

/* space2batch operation start */

/*!
 *  @brief cnmlCreateSpace2batchOp.
 *
 *  Create a Space2batch operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, the zoom ratio of the h direction and the
 *  w direction, input and output tensors, pass them to the function to create a Space2batch
 *  operator.
 *
 *  **Formula**
 *
 *    this is a IO function, the idea is to reshape the input to another from,
 *    in order to accelerate the conv operation with dilation bigger than 1.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] output
 *    Output. A pointer to the mlu end Tensor
 *  @param[in] op
 *    Input. A pointer to the base operator
 *  @param[in] input
 *    Input. A pointer to the mlu end
 *  @param[in] w_block_size,
 *    Input. The zoom ratio representing the move from the w direction to the n direction,
 *    wo = wi / w_block_size.
 *  @param[in] h_block_size,
 *    Input. The zoom ratio representing the move from the h direction to the n direction,
 *    ho = hi / h_block_size.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op, input, and output are not empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSpace2batchOp(cnmlBaseOp_t *op,
                                                  int w_block_size,
                                                  int h_block_size,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeSpace2batchOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSpace2batchOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified Space2batch operator on the MLU.
 *
 *  After creating the Space2batch operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Space2batch operator.
 *
 *  **Formula**
 *
 *    this is a IO function, the idea is to reshape the input to another from,
 *    in order to accelerate the conv operation with dilation bigger than 1.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeSpace2batchOpForward_V3(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeSpace2batchOpForward_V4.
 *
 *  It is used to compute the user-specified Space2batch operator on the MLU.
 *
 *  After creating the Space2batch operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Space2batch operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSpace2batchOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* space2batch operation end */

/* batch2space operation start */

/*!
 *  @brief cnmlCreateBatch2spaceOp.
 *
 *  Create a Batch2space operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, the zoom ratio in the h direction and the
 *  w direction, input and output tensors, pass them to the function to create a Batch2space
 *  operator.
 *
 *  **Formula**
 *
 *    this is a IO function, this is the reverse function of the space2batch.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. A pointer to the mlu end Tensor
 *  @param[in] op
 *    Input. A pointer to the base operator
 *  @param[in] input
 *    Input. A pointer to the mlu end
 *  @param[in] w_block_size,
 *    Input. The zoom ratio representing the move from the w direction to the n direction,
 *    wo = wi * w_block_size.
 *  @param[in] h_block_size,
 *    Input. The zoom ratio representing the move from the h direction to the n direction,
 *    ho = hi * h_block_size.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    Op, input, and output are not empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBatch2spaceOp(cnmlBaseOp_t *op,
                                                  int w_block_size,
                                                  int h_block_size,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeBatch2spaceOpForward_V3.
 *
 *  It is used to compute the user-specified Batch2space operator on the MLU.
 *
 *  After creating the Batch2space operator, Input, Output, runtime parameters, and computation
 *  stream, pass them to the function to It is used to compute the Batch2space operator.
 *
 *  **Formula**
 *
 *    this is a IO function, this is the reverse function of the space2batch.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      unlimited
 *
 *  Deprecated. This interface will be deleted in next version and
 * cnmlComputeBatch2spaceOpForward_V4 is recommended to use.
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeBatch2spaceOpForward_V3(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeBatch2spaceOpForward_V4.
 *
 *  It is used to compute the user-specified Batch2space operator on the MLU.
 *
 *  After creating the Batch2space operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Batch2space operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBatch2spaceOpForward_V4(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* batch2space operation end */

/* unpool operation start */
/*!
 *  @struct cnmlUnpoolOpParam
 *  @brief A struct.
 *
 *  cnmlUnpoolOpParam is a structure describing the param parameter of unpooling operation, used to
 *  create unpool operation. cnmlCreateUnpoolOpParam() is used to create an instance of
 *  cnmlUnpoolOpParam_t. cnmlDestroyUnpoolOpParam() is used to destroy an instance of
 *  cnmlUnpoolOpParam_t. */
struct cnmlUnpoolOpParam;
/*! ``cnmlUnpoolOpParam_t`` is a pointer to ``cnmlUnpoolOpParam`` which is a
    structure holding the description of a unpooling operation param. */
typedef struct cnmlUnpoolOpParam *cnmlUnpoolOpParam_t;

/*!
 *  @brief cnmlCreateUnpoolOpParam.
 *
 *  The function creates an unpool operator operation parameter struct according to the pointer
 *  given by the user, and fills in the struct with the parameters input by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer to the address of the unpool operator operation parameter struct.
 *  @param[in] window_height
 *    Input. height of the sliding window.
 *  @param[in] window_width
 *    Input. width of the sliding window.
 *  @param[in] stride_height
 *    Input. step size in column direction.
 *  @param[in] stride_width
 *    Input. step size in row direction.
 *  @param[in] unpool_mode
 *    Input. Anti-pooling mode, including CNML_UNPOOL, CNML_ROWWISE_UNPOOL, CNML_MAXPOOLBP,
 *    CNML_AVGPOOLBP, CNML_MIDUNPOOL, CNML_DIV, and CNML_REP.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateUnpoolOpParam(cnmlUnpoolOpParam_t *param,
                                                  int window_height,
                                                  int window_width,
                                                  int stride_height,
                                                  int stride_width,
                                                  cnmlUnpoolMode_t unpool_mode);

/*!
 *  @brief cnmlCreateUnpoolOpParam_V2.
 *
 *  The function creates an unpool operator operation parameter struct according to the pointer
 *  given by the user, and fills in the struct with the parameters input by the user.
 *
 *  @param[out] param
 *    Output. A pointer to the address of the unpool operator operation parameter struct.
 *  @param[in] window_height
 *    Input. height of the sliding window.
 *  @param[in] window_width
 *    Input. width of the sliding window.
 *  @param[in] stride_height
 *    Input. step size in column direction.
 *  @param[in] stride_width
 *    Input. step size in row direction.
 *  @param[in] pad_left
 *    Input. padding size in left row direction.
 *  @param[in] pad_right
 *    Input. padding size in right row direction.
 *  @param[in] pad_up
 *    Input. padding size in up column direction.
 *  @param[in] pad_down
 *    Input. padding size in down column direction.
 *  @param[in] unpool_mode
 *    Input. Anti-pooling mode, including CNML_UNPOOL, CNML_ROWWISE_UNPOOL, CNML_MAXPOOLBP,
 *    CNML_AVGPOOLBP, CNML_MIDUNPOOL, CNML_DIV, CNML_REP, and DILATION_UNPOOL.
 *  @param[in] padding_mode
 *    Input. including SAME, VALID
 *  @param[in] count_include_pad
 *    Input. judge while pad part join calculate of CNML_AVGPOOLBP
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Param is a null pointer.
 *
 *  **Scale Limitation**
 *  DILATION_UNPOOL set param : padding_mode = CNML_UNPOOL_KSAME
 *                              count_include_pad = false
 */
CNML_DLL_API cnmlStatus_t cnmlCreateUnpoolOpParam_V2(cnmlUnpoolOpParam_t *param,
                                                     int window_height,
                                                     int window_width,
                                                     int stride_height,
                                                     int stride_width,
                                                     int pad_left,
                                                     int pad_right,
                                                     int pad_up,
                                                     int pad_down,
                                                     cnmlUnpoolMode_t unpool_mode,
                                                     cnmlUnPoolStrategyMode_t padding_mode,
                                                     bool count_include_pad);

/*!
 *  @brief cnmlDestroyUnpoolOpParam.
 *
 *  Release the unpool operator operation parameter struct pointer according to the pointer given by
 *  the user.
 *
 *  After the unpool operator ends, release the created unpool operator operation parameter struct
 *  pointer.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer to the address of the unpool operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    (At least one of) the following conditions are not satisfied:
 *    - param is a null pointer.
 *    - The pointer content pointed to by param has been released.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyUnpoolOpParam(cnmlUnpoolOpParam_t *param);

/*!
 *  @brief cnmlCreateUnpoolOp.
 *
 *  Create an unpool operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, unpool operator parameters, input and
 *  output Tensors, pass them to the function to create an unpool operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tensor
 *    Output. A pointer to the mlu end Tensor
 *  @param[in] op
 *    Input. A pointer to the base operator
 *  @param[in] input_tensor
 *    Input. A pointer to the mlu end
 *  @param[in] unpool_param
 *    Input. A pointer to the address of the unpool operator operation parameter struct.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    Op, input, output, and unpool_param are not empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateUnpoolOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t index_tensor,
                                             cnmlTensor_t output_tensor,
                                             cnmlUnpoolOpParam_t unpool_param);

/*!
 *  @brief cnmlComputeUnpoolOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeUnpoolOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified unpool operator on the MLU.
 *
 *  After creating the unpool operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the unpool operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] index
 *    Input. indicating where the input should be mapped to the original pooling core.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *  affinity.
 *    at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeUnpoolOpForward_V3(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *index,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeUnpoolOpForward_V4.
 *
 *  It is used to compute the user-specified unpool operator on the MLU.
 *
 *  After creating the unpool operator, Input, Output, runtime parameters, and computation queue,
 *  pass them to the function to It is used to compute the unpool operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. MLU address pointing to input data.
 *  @param[in] index_tensor
 *    Input. Index MLU tensor pointer. Pass NULL if not used.
 *  @param[in] index
 *    Input. MLU address pointing to index data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeUnpoolOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t index_tensor,
                                                        void *index,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* unpool operation end */

/* top_k operation start */

/*!
 *  @brief cnmlCreateTopkOp.
 *
 *  The interface creates a TopK operator based on the base operator pointer given by the user.
 *
 *  The operator finds the top K largest number from the user-specified dimension, and outputs
 *  the value and the position.
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute max num of k by direction.
 *
 *    such as direction is n, output[k, c, h, w]
 *
 *    such as direction is c, output[n, k, h, w]
 *
 *    other direction is the same condition. k is the size of max num to calculate.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      output_data_type = input_data_type:float16, float32
 *
 *      index_data_type:
 *
 *        if direction is c, index_data_type = int32
 *
 *        else if input_data_type = float16 then index_data_type = int16
 *
 *        else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *      align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *      input_dt == float16: ct_line_num = 32
 *
 *      input_dt == float32: ct_line_num = 64
 *
 *     if direction is c, k <= c; and when datatype = float16, if c > 130000, k <= 80000; when
 * datetype = float32, if c > 65000, k <= 40000
 *
 *     if direction is h, k <= h; and when datatype = float16, if h > 2000, k <= 400; when datetype
 * = float32, if h > 1000,k <= 200
 *
 *     if direction is w, k <= w; and when datatype = float16, if w > 2000, k <= 400; when datetype
 * = float32, if w > 1000,k <= 200
 *
 *     if direction is n, k <= n; and when datatype = float16, if n > 2000, k <= 400; when datetype
 * = float32, if n > 1000,k <= 200
 *
 * **Performance Optimization**
 *
 *   direction c: The smaller the size of n, h, w, and k, the better performance.
 *
 *   direction n h w: The smaller the size of k, the better performance.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tensor:
 *    Output. 4-dimensional NCHW tensor, supporting data of float type.
 *  @param[out] index_tensor:
 *    Output. 4-dimensional NCHW tensor, supporting float16, int, and unsigned int types.
 *  @param[in] k:
 *    Input. Integer, the first k largest numbers to find.
 *  @param[in] input_tensor:
 *    Input. 4-dimensional NCHW tensor, supporting data of float16 type.
 *  @param[in] dim:
 *    Input. Enumerated type, the dimension where it is found, including four values: CNML_DIM_C,
 *    CNML_DIM_H, CNML_DIM_W, and CNML_DIM_N.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTopkOp(cnmlBaseOp_t *op,
                                           int k,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor,
                                           cnmlTensor_t index_tensor,
                                           cnmlDimension_t dim);

/*!
 *  @brief cnmlCreateTopkOp_V2.
 *
 *  The interface creates a TopK operator based on the base operator pointer given by the user.
 *
 *  The operator finds the top K largest or the bottom K smallest number from the user-specified
 *  dimension, and outputs the value and the position.
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute max num of k by direction.
 *
 *    such as direction is n, output[k, c, h, w]
 *
 *    such as direction is c, output[n, k, h, w]
 *
 *    other directions have the same condition. k is the size of max num to calculate.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      output_data_type = input_data_type:float16, float32
 *
 *      index_data_type:
 *
 *        if direction is c, index_data_type = int32
 *
 *        else if input_data_type = float16 then index_data_type = int16
 *
 *        else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *     align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *     input_dt == float16: ct_line_num = 32
 *
 *     input_dt == float32: ct_line_num = 64
 *
 *     if direction is c, k <= c; and when datatype = float16, if c > 130000, k <= 80000; when
 * datetype = float32, if c > 65000, k <= 40000
 *
 *     if direction is h, k <= h; and when datatype = float16, if h > 2000, k <= 400; when datetype
 * = float32, if h > 1000,k <= 200
 *
 *     if direction is w, k <= w; and when datatype = float16, if w > 2000, k <= 400; when datetype
 * = float32, if w > 1000,k <= 200
 *
 *     if direction is n, k <= n; and when datatype = float16, if n > 2000, k <= 400; when datetype
 * = float32, if n > 1000,k <= 200
 *
 * **Performance Optimization**
 *
 *   direction c: The smaller the size of n, h, w, and k, the better performance.
 *
 *   direction n h w: The smaller the size of k, the better performance.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tensor:
 *    Output. 4-dimensional NCHW tensor, supporting data of float type.
 *  @param[out] index_tensor:
 *    Output. 4-dimensional NCHW tensor, supporting float16, int, and unsigned int types.
 *  @param[in] k:
 *    Input. Integer, the first k largest numbers to find.
 *  @param[in] input_tensor:
 *    Input. 4-dimensional NCHW tensor, supporting data of float16 type.
 *  @param[in] dim:
 *    Input. Enumerated type, the dimension where it is found, including four values: CNML_DIM_C,
 *    CNML_DIM_H, CNML_DIM_W, and CNML_DIM_N.
 *  @param[in] kmode:
 *    Input. Enumerated type, specifies whether the largest number or the smallest number to
 *    find, including 2 values: CNML_TOPK_OP_MODE_MAX, or CNML_TOPK_OP_MODE_MIN.
 *    Only support CNML_TOPK_OP_MODE_MAX temporarily.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTopkOp_V2(cnmlBaseOp_t *op,
                                              int k,
                                              cnmlTensor_t input,
                                              cnmlTensor_t output,
                                              cnmlTensor_t index,
                                              cnmlDimension_t ch,
                                              cnmlTopkOpMode_t kmode);

/*!
 *  @brief cnmlCreateNdTopkOp.
 *
 *  The interface creates a TopK operator based on the base operator pointer given by the user.
 *
 *  The operator finds the top K largest or the bottom K smallest number from the user-specified
 *  dimension, and outputs the value and the position.
 *
 *  **Summary**
 *
 *  - Support tensor of arbitrary dimensional. Require to have the same input and output shape.
 *
 *  - dim belongs to [0, dim_num-1], and dim_num is the number of dimensions.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     value_data_type = input_data_type:float16, float32
 *
 *     index_data_type:
 *
 *     if input_data_type = float16 then index_data_type = int16
 *
 *      else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *     align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *     input_dt == float16: ct_line_num = 32
 *
 *     input_dt == float32: ct_line_num = 64
 *
 *     if direction is c, k <= c; and when datatype = float16, if c > 130000, k <= 80000; when
 datetype = float32, if c > 65000, k <= 40000
 *
 *     if direction is h, k <= h; and when datatype = float16, if h > 2000, k <= 400; when datetype
 = float32, if h > 1000,k <= 200
 *
 *     if direction is w, k <= w; and when datatype = float16, if w > 2000, k <= 400; when datetype
 = float32, if w > 1000,k <= 200
 *
 *     if direction is n, k <= n; and when datatype = float16, if n > 2000, k <= 400; when datetype
 = float32, if n > 1000,k <= 200
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output_tensor:
 *    Output. A MLU tensor of arbitrary dimension, supporting data of float type.
 *  @param[out] index_tensor:
 *    Output. A MLU tensor of arbitrary dimension, supporting float16, int, and unsigned int types.
 *  @param[in] k:
 *    Input. Integer, the first k largest numbers to find.
 *  @param[in] input_tensor:
 *    Input. A MLU tensor of arbitrary dimension, supporting data of float16 type.
 *  @param[in] dim:
 *    Input. Enumerated type, the dimension where it is found, counting from 0
 *  @param[in] kmode:
 *    Input. Enumerated type, specifies whether the largest number or the smallest number to
 *    find, including 2 values: CNML_TOPK_OP_MODE_MAX, or CNML_TOPK_OP_MODE_MIN.
 *    Only support CNML_TOPK_OP_MODE_MAX temporarily.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdTopkOp(cnmlBaseOp_t *op,
                                             int k,
                                             cnmlTensor_t input,
                                             cnmlTensor_t output,
                                             cnmlTensor_t index,
                                             int ch,
                                             cnmlTopkOpMode_t kmode);

/*!
 *  @brief cnmlComputeTopkOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeTopkOpForward_V4 is recommended to use.
 *
 *  The function is same as the cnmlComputeTopkOpForward interface.
 *
 *  In addition to the following parameters, the remaining parameters refer to the
 *  cnmlComputeTopkOpForward interface.
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute max num of k by direction.
 *
 *    such as direction is n, output[k, c, h, w]
 *
 *    such as direction is c, output[n, k, h, w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     output_data_type = input_data_type:float16, float32
 *
 *     index_data_type:
 *
 *      if direction is c, index_data_type = int32
 *
 *      else if input_data_type = float16 then index_data_type = int16
 *
 *      else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *     align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *     input_dt == float16: ct_line_num = 32
 *
 *     input_dt == float32: ct_line_num = 64
 *
 *     at least one c must be processed.
 *
 *     if direction is c, k <= c; and when datatype = float16, if c > 130000, k <= 80000; when
 * datetype = float32, if c > 65000, k <= 40000
 *
 *     if direction is h, k <= h; and when datatype = float16, if h > 2000, k <= 400; when datetype
 * = float32, if h > 1000,k <= 200
 *
 *     if direction is w, k <= w; and when datatype = float16, if w > 2000, k <= 400; when datetype
 * = float32, if w > 1000,k <= 200
 *
 *     if direction is n, k <= n; and when datatype = float16, if n > 2000, k <= 400; when datetype
 * = float32, if n > 1000,k <= 200
 *
 *    at least one c must be processed.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output:
 *    Output. An MLU address that points to the output data.
 *  @param[out] index:
 *    Output. An MLU address pointing to the index output.
 *  @param[in] op:
 *    Input. A pointer to the base operator.
 *  @param[in] input:
 *    Input. An MLU address that points to the input data.
 *  @param[in] stream:
 *    Input. A computation stream pointer.
 *  @param[in] compute_forw_param:
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue:
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeTopkOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      void *index,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeTopkOpForward_V4.
 *
 *  The function is same as the cnmlComputeTopkOpForward interface.
 *
 *  In addition to the following parameters, the remaining parameters refer to the
 *  cnmlComputeTopkOpForward interface.
 *
 *  **Summary**
 *
 *    input[n, c, h, w],and compute max num of k by direction.
 *
 *    such as direction is n, output[k, c, h, w]
 *
 *    such as direction is c, output[n, k, h, w]
 *
 *    other direction is the same condition. k is the size of max num to calculate.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *     output_data_type = input_data_type:float16, float32
 *
 *     index_data_type:
 *
 *      if direction is c, index_data_type = int32
 *
 *      else if input_data_type = float16 then index_data_type = int16
 *
 *      else if input_data_type = float32 then index_data_type = int32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *     align2num(k, 2*ct_line_num)*2 + align2num(c, 2 * ct_line_num) < 8192 * ct_line_num,
 *
 *     align2num -> make k_pad % (2 *ct_line_num) == 0
 *
 *     input_dt == float16: ct_line_num = 32
 *
 *     input_dt == float32: ct_line_num = 64
 *
 *     if direction is c, k <= c; and when datatype = float16, if c > 130000, k <= 80000; when
 * datetype = float32, if c > 65000, k <= 40000
 *
 *     if direction is h, k <= h; and when datatype = float16, if h > 2000, k <= 400; when datetype
 * = float32, if h > 1000,k <= 200
 *
 *     if direction is w, k <= w; and when datatype = float16, if w > 2000, k <= 400; when datetype
 * = float32, if w > 1000,k <= 200
 *
 *     if direction is n, k <= n; and when datatype = float16, if n > 2000, k <= 400; when datetype
 * = float32, if n > 1000,k <= 200
 *
 * **Performance Optimization**
 *
 *   direction c: The smaller the size of n, h, w, and k, the better performance.
 *
 *   direction n h w: The smaller the size of k, the better performance.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] index_tensor
 *    Input.  Index MLU tensor pointer. Pass NULL if not used.
 *  @param[out] index
 *    Output. An MLU address pointing to index position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeTopkOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnmlTensor_t index_tensor,
                                                      void *index,
                                                      cnrtQueue_t queue,
                                                      void *extra);

/*!
 *  @brief cnmlComputeNdTopkOpForward.
 *
 *  Compute a Topk operation that supports arbitrary dimensions.
 *
 *  **Supports MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] index_tensor
 *    Input.  Index MLU tensor pointer. Pass NULL if not used.
 *  @param[out] index
 *    Output. An MLU address pointing to index position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdTopkOpForward(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnmlTensor_t index_tensor,
                                                     void *index,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* top_k operation end */

/* where operation start */

/*!
 *  @brief cnmlCreateWhereOp.
 *
 *  The interface creates a where operator based on the address of the base operator pointer passed
 *  by the user.
 *
 *  The approximate operator is used to obtain the coordinates and the values that are
 *  true or non-zero in the input data.
 *
 *  @param[out] output_tensor:
 *    Output. 4-dimensional NCHW tensor, non-zero data coordinates, supporting data of int, uint32,
 *    and float16 types.
 *  @param[out] count_tensor:
 *    Output. 4-dimensional NCHW tensor, number of non-zero elements, supporting data of int,
 *    uint32, and float16 types.
 *  @param[in] op:
 *    Input. A pointer to the base operator pointer.
 *  @param[in] input_tensor:
 *    Input. 4-dimensional NCHW tensor, supporting data of bool and float16 types.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateWhereOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor,
                                            cnmlTensor_t output_tensor,
                                            cnmlTensor_t count_tensor);

/*!
 *  @brief cnmlComputeWhereOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeWhereOpForward_V4 is recommended to use.
 *
 *  The interface performs computation on the MLU based on the where operator created by the
 *  user.The parameters except the following parameters may refer to cnmlComputeWhereOpForward.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output:
 *    Output. The address pointing to the MLU coordinate output.
 *  @param[out] count:
 *    Output. The address pointing to the MLU count ouput.
 *  @param[in] op:
 *    Input. A pointer to the base operator.
 *  @param[in] input:
 *    Input. The address pointing to the MLU input data.
 *  @param[in] type:
 *    Input. An enumeration constant that represents the runtime task type.
 *  @param[in] compute_forw_param:
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue:
 *    Input. A computation queue pointer.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeWhereOpForward_V3(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *output,
                                                       void *count,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeWhereOpForward_V4.
 *
 *  The interface performs computation on the MLU based on the where operator created by the
 *  user.The parameters except the following parameters may refer to cnmlComputeWhereOpForward.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] count_tensor
 *    Input.  Count MLU tensor pointer. Pass NULL if not used.
 *  @param[out] count
 *    Output. An MLU address pointing to count position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeWhereOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnmlTensor_t count_tensor,
                                                       void *count,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* where operation end */

/*Nd Log Softmax operation start*/

/*!
 *  @brief cnmlCreateNdLogSoftmaxOp.
 *
 *  A function that creates an operator for the Log Softmax operation (logarithmic index
 *  normalization) based on the base operator pointer given by the user. In the cpu version of the
 *  operator, OUT = IN - log(reduce_sum(exp(IN) ), dim)); in the mlu version, IN = IN -
 *  reduce_max(IN, dim), OUT = IN - log(reduce_sum(exp(IN), dim)).
 *
 *  Notes:
 *
 *  - Support tensor of arbitrary dimensional. Require to have the same input and output shape.
 *
 *  - dim belongs to [0, dim_num-1], and dim_num is the number of dimensions.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  output
 *    Input. A MLU tensor of arbitrary dimension, supporting data of float16 type.
 *  @param[in]  input
 *    Input. A MLU tensor of arbitrary dimension, supporting data of float16 type.
 *  @param[in]  dim
 *    Input. The selected dimension, counting from 0
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - The operator pointer is empty.
 *    - The input and output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdLogSoftmaxOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor,
                                                   int dim);
/*!
 *  @brief cnmlComputeNdLogSoftmaxOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdLogSoftmaxOpForward_V2 is recommended to use.
 *
 *  Compute a Log Softmax operation that supports arbitrary dimensions (logarithmic index
 *  normalization).
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output data.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address pointing to the input data tensor.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeNdLogSoftmaxOpForward(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeNdLogSoftmaxOpForward_V2.
 *
 *  Compute a Log Softmax operation that supports arbitrary dimensions (logarithmic index
 *  normalization).
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdLogSoftmaxOpForward_V2(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/*Nd Log Softmax operation end*/

/* Log Softmax operation start */

/*!
 *  @brief cnmlCreateLogSoftmaxOp.
 *
 *  This function creates a logarithmic exponential normalization operator based on the basic
 *  operator pointer given by the user. In creation, it is necessary to indicate in which dimension
 *  the logarithmic index normalization operation is performed.
 *
 *  **Formula**
 *
 *    Such as when input[ni, ci, hi, wi], output[no, co, ho, wo] and `d` direction is `c`, then
 *    output[n, c, h, w] = logsoftmax(n, c, h, w) = log(exp(input[n, c, h, w]) / sum_i(exp(input[n,
 *    i, h, w])))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 1024 because of at least process one full line at a time
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor
 *    Input. 4-dimensional input tensor, of which the shape is [ni, ci, hi, wi], supporting data of
 *    float16 type.
 *  @param[in]  output_tensor
 *    Input. 4-dimensional output tensor, of which the shape is [no, co, ho, wo] (no = ni, co = ci,
 *    ho = ci, wo = wi), supporting data of float16 type.
 *  @param[in] ,  dim
 *    Input. enumeration variables of cnmlDimension_t type that specifies which dimension to operate
 *    in. The options include CNML_DIM_N, CNML_DIM_C, CNML_DIM_H, and CNML_DIM_W.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDARG.
 *    At least one of the following conditions are met:
 *    - Input is not empty.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLogSoftmaxOp(cnmlBaseOp_t *op,
                                                 cnmlTensor_t input_tensor,
                                                 cnmlTensor_t output_tensor,
                                                 cnmlDimension_t dim);

/*!
 *  @brief cnmlComputeLogSoftmaxOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLogSoftmaxOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified MLP operator on the MLU.
 *
 *  After creating the MLP operator, Input, Output, and computation stream, pass them to the
 *  function to It is used to compute the MLP operator.
 *
 *  **Formula**
 *
 *    Such as when input[ni, ci, hi, wi], output[no, co, ho, wo] and `d` direction is `c`, then
 *    output[n, c, h, w] = logsoftmax(n, c, h, w) = log(exp(input[n, c, h, w]) / sum_i(exp(input[n,
 *    i, h, w])))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      c < 1024 because of at least process one full line at a time
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address specifying the output position.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeLogSoftmaxOpForward_V3(cnmlBaseOp_t op,
                                  void *input,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeLogSoftmaxOpForward_V4.
 *
 *  It is used to compute the user-specified MLP operator on the MLU.
 *
 *  After creating the MLP operator, Input, Output, and computation queue, pass them to the
 *  function to It is used to compute the MLP operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLogSoftmaxOpForward_V4(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor,
                                                            void *input,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);
/* Log Softmax operation end */

/* Strided Slice operation start */
/*!
 *  @struct cnmlStridedSliceOpParam
 *  @brief A struct.
 *
 *  cnmlStridedSliceOpParam is a structure describing the param parameter of Strided Slice
 *  operation, used to create Strided Slice operation. cnmlCreateStridedSliceOpParam() is used to
 *  create an instance of cnmlStridedSliceOpParam_t. cnmlDestroyStridedSliceOpParam() is used to
 *  destroy an instance of cnmlStridedSliceOpParam_t. */
struct cnmlStridedSliceOpParam;
/*! ``cnmlStridedSliceOpParam_t`` is a pointer to ``cnmlStridedSliceOpParam`` which is a
    structure holding the description of a strided slice operation param. */
typedef struct cnmlStridedSliceOpParam *cnmlStridedSliceOpParam_t;

/*!
 *  @brief cnmlCreateStridedSliceOpParam.
 *
 *  This function is used to create parameters for partial area stride slicing operations. The
 *  parameter information includes the start index of each dimension, the end index of each
 *  dimension, and the stride of each dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  param
 *    Output. A pointer to the parameter struct of the initialized variable
 *  @param[in]  nb
 *    Input. n dimension start index
 *  @param[in]  cb
 *    Input. c dimension start index
 *  @param[in]  hb
 *    Input. h dimension start index
 *  @param[in]  wb
 *    Input. w dimension start index
 *  @param[in]  ne
 *    Input. n dimension end index
 *  @param[in]  ce
 *    Input. c dimension end index
 *  @param[in]  he
 *    Input. h dimension end index
 *  @param[in]  we
 *    Input. w dimension end index
 *  @param[in]  ns
 *    Input. n dimension stride index
 *  @param[in]  cs
 *    Input. c dimension stride index
 *  @param[in]  hs
 *    Input. h dimension stride index
 *  @param[in]  ws
 *    Input. w dimension stride index
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Param is not empty
 */
CNML_DLL_API cnmlStatus_t cnmlCreateStridedSliceOpParam(cnmlStridedSliceOpParam_t *param,
                                                        int nb,
                                                        int cb,
                                                        int hb,
                                                        int wb,
                                                        int ne,
                                                        int ce,
                                                        int he,
                                                        int we,
                                                        int ns,
                                                        int cs,
                                                        int hs,
                                                        int ws);

/*!
 *  @brief cnmlDestroyStridedSliceOpParam.
 *
 *  This function is used to release a pointer to the previously created StridedSlice operation
 *  parameter struct.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in]  param
 *    Input. A pointer to the StridedSlice parameter struct
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Param is not empty
 *    - The space pointed by param is not released.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyStridedSliceOpParam(cnmlStridedSliceOpParam_t *param);

/*!
 *  @brief cnmlCreateStridedSliceOp.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlCreateStridedSliceOpForward is recommended to use.
 *
 *  This function is used to create an operation of slicing by stride in partial area.
 *
 *  **Formula**
 *
 *    n_len = (ne - nb) > 0 ? ne - nb : nb - ne
 *
 *    h_len = (he - hb) > 0 ? he - hb : hb - he
 *
 *    w_len = (we - wb) > 0 ? we - wb : wb - we
 *
 *    c_len = (ce - cb) > 0 ? ce - cb : cb - ce
 *
 *    n_out = n_len / ns + (n_len % ns > 0 ? 1 : 0)
 *
 *    h_out = h_len / hs + (h_len % hs > 0 ? 1 : 0)
 *
 *    w_out = w_len / ws + (w_len % ws > 0 ? 1 : 0)
 *
 *    c_out = c_len / cs + (c_len % cs > 0 ? 1 : 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int8
 *
 *  **Scale Limitation**
 *
 *    According to the definition of StridedSlice,
 *    the input params should satisfy the following condition.
 *
 *    ns * cs * hs * ws != 0
 *
 *    when ns > 0, (nb >= 0 && ne > nb && n_input >= ne) should be true.
 *
 *    when ns < 0, (ne + 1 >= (-1) * n_input && nb > ne && nb <= -1) should be true.
 *
 *    when cs > 0, (cb >= 0 && ce > cb && c_input >= ce) should be true.
 *
 *    when cs < 0, (ce + 1 >= (-1) * c_input && cb > ce && cb <= -1) should be true.
 *
 *    when hs > 0, (hb >= 0 && he > hb && h_input >= he) should be true.
 *
 *    when hs < 0, (he + 1 >= (-1) * h_input && hb > he && hb <= -1) should be true.
 *
 *    when ws > 0, (wb >= 0 && we > wb && w_input >= we) should be true.
 *
 *    when ws < 0, (we + 1 >= (-1) * w_input && wb > we && wb <= -1) should be true.
 *
 *    Other Limit:
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]   op
 *    Output. returns a pointer to the created base op
 *  @param[in]  param
 *    Input. A pointer to the StridedSlice parameter struct
 *  @param[in]  input
 *    Input. A 4-dimensional MLU tensor, having the dimension of [ni,hi,wi,ci], supporting data of
 *    float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU tensor, having the dimension of [no,ho,wo,co], supporting data of
 *    float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Op is not empty
 *    - param is not empty
 *    - input is not empty
 *    - output are not empty
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateStridedSliceOp(cnmlBaseOp_t *op,
                                                   cnmlStridedSliceOpParam_t param,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor);
/*!
 *  @brief cnmlCreateStridedSliceOpForward.
 *
 *  This function is used to create an operation of slicing by stride in partial area.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]   op
 *    Output. returns a pointer to the created base op
 *  @param[in]  param
 *    Input. A pointer to the StridedSlice parameter struct
 *  @param[in]  input
 *    Input. A 4-dimensional MLU tensor, having the dimension of [ni,hi,wi,ci], supporting data of
 *    float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU tensor, having the dimension of [no,ho,wo,co], supporting data of
 *    float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Op is not empty
 *    - param is not empty
 *    - input is not empty
 *    - output are not empty
 */
CNML_DLL_API cnmlStatus_t cnmlCreateStridedSliceOpForward(cnmlBaseOp_t *op,
                                                          cnmlStridedSliceOpParam_t param,
                                                          cnmlTensor_t input_tensor,
                                                          cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeStridedSliceOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeStridedSliceOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified StridedSlice operator.
 *
 *  After creating the Cast operator, Input, Output, and computation streams, pass them to the
 *  function to It is used to compute the StridedSlice operator.
 *
 *  **Formula**
 *
 *    n_len = (ne - nb) > 0 ? ne - nb : nb - ne
 *
 *    h_len = (he - hb) > 0 ? he - hb : hb - he
 *
 *    w_len = (we - wb) > 0 ? we - wb : wb - we
 *
 *    c_len = (ce - cb) > 0 ? ce - cb : cb - ce
 *
 *    n_out = n_len / ns + (n_len % ns > 0 ? 1 : 0)
 *
 *    h_out = h_len / hs + (h_len % hs > 0 ? 1 : 0)
 *
 *    w_out = w_len / ws + (w_len % ws > 0 ? 1 : 0)
 *
 *    c_out = c_len / cs + (c_len % cs > 0 ? 1 : 0)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32, int8
 *
 *  **Scale Limitation**
 *
 *    According to the definition of StridedSlice,
 *    the input params should satisfy the following condition.
 *
 *    ns * cs * hs * ws != 0
 *
 *    when ns > 0, (nb >= 0 && ne > nb && n_input >= ne) should be true.
 *
 *    when ns < 0, (ne + 1 >= (-1) * n_input && nb > ne && nb <= -1) should be true.
 *
 *    when cs > 0, (cb >= 0 && ce > cb && c_input >= ce) should be true.
 *
 *    when cs < 0, (ce + 1 >= (-1) * c_input && cb > ce && cb <= -1) should be true.
 *
 *    when hs > 0, (hb >= 0 && he > hb && h_input >= he) should be true.
 *
 *    when hs < 0, (he + 1 >= (-1) * h_input && hb > he && hb <= -1) should be true.
 *
 *    when ws > 0, (wb >= 0 && we > wb && w_input >= we) should be true.
 *
 *    when ws < 0, (we + 1 >= (-1) * w_input && wb > we && wb <= -1) should be true.
 *
 *    Other Limit:
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeStridedSliceOpForward_V3(cnmlBaseOp_t op,
                                    void *input,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeStridedSliceOpForward_V4.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeStridedSliceOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified StridedSlice operator.
 *
 *  After creating the Cast operator, Input, Output, and computation streams, pass them to the
 *  function to It is used to compute the StridedSlice operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeStridedSliceOpForward_V4(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);
/* Strided Slice operation end */

/* Nd Strided Slice operation start */
/*!
 *  @struct cnmlNdStridedSliceOpParam
 *  @brief A struct.
 *
 *  cnmlNdStridedSliceOpParam is a structure describing the param parameter of Strided Slice nd
 *  operation, used to create Strided Slice nd operation. cnmlCreateNdStridedSliceOpParam() is used
 *  to create an instance of cnmlNdStridedSliceOpParam_t. cnmlDestroyNdStridedSliceOpParam() is used
 *  to destroy an instance of cnmlNdStridedSliceOpParam_t. */
struct cnmlNdStridedSliceOpParam;
/*! ``cnmlNdStridedSliceOpParam_t`` is a pointer to ``cnmlNdStridedSliceOpParam`` which is a
    structure holding the description of a strided slice nd operation param. */
typedef struct cnmlNdStridedSliceOpParam *cnmlNdStridedSliceOpParam_t;

/*!
 *  @brief cnmlCreateNdStridedSliceOpParam.
 *
 *  This function is used to create parameters for partial area stride slicing operations. The
 *  parameter information includes the start index of each dimension, the end index of each
 *  dimension, and the stride of each dimension. This API is the extension of
 * cnmlCreateStridedSliceOpParam,
 *  which can support one to any dimension tensor
 *
 *  @param[out]  param
 *    Output. A pointer to the parameter struct of the initialized variable.
 *  @param[in]  dim_num
 *    Input. the length of input Data.
 *  @param[in]  degin[]
 *    Input. the start index of each dimension.
 *  @param[in]  end[]
 *    Input. the end index of each dimension.
 *  @param[in]  stride[]
 *    Input. the stride index of each dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Param is not empty
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdStridedSliceOpParam(cnmlNdStridedSliceOpParam_t *param,
                                                          int dim_num,
                                                          int begin[],
                                                          int end[],
                                                          int stride[]);

/*!
 *  @brief cnmlDestroyNdStridedSliceOpParam.
 *
 *  This function is used to release a pointer to the previously created NdStridedSlice operation
 *  parameter struct.
 *
 *  @param[in]  param
 *    Input. A pointer to the NdStridedSlice parameter struct
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Param is not empty
 *    - The space pointed by param is not released.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyNdStridedSliceOpParam(cnmlNdStridedSliceOpParam_t *param);

/*!
 *  @brief cnmlCreateNdStridedSliceOp.
 *
 *  This API is the extension of cnmlCreateStridedSliceOp, using for create NdStridedSlice,
 *  which can support one to any diemnsion input tensor. We recommend you use the
 *  cnmlCreateNdStridedSliceOp interface to create the StridedSlice operator.
 *
 *  @param[out] op
 *    Output. returns a pointer to the created base op.
 *  @param[in]  param
 *    Input. A pointer to the NdStridedSlice parameter struct.
 *  @param[in]  input
 *    Input. A one to any dimensional MLU tensor, supporting data of float16 type.
 *  @param[in]  output
 *    Input. A one to any dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions is not satisfied:
 *    - Op is not empty
 *    - param is not empty
 *    - input is not empty
 *    - output are not empty
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdStridedSliceOp(cnmlBaseOp_t *op,
                                                     cnmlNdStridedSliceOpParam_t param,
                                                     cnmlTensor_t input,
                                                     cnmlTensor_t output);

/*!
 *  @brief cnmlComputeNdStridedSliceOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdStridedSliceOpForward_V2 is recommended to use.
 *
 *  It is used to compute the user-specified NdStridedSlice operator.
 *
 *  After creating the NdStridedSlice operator, Input, Output, and computation stream, pass them to
 *  the function to calculate the NdStridedSlice operator.
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  stream
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeNdStridedSliceOpForward(cnmlBaseOp_t op,
                                   void *input,
                                   void *output,
                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                   cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeNdStridedSliceOpForward.
 *
 *  It is used to compute the user-specified NdStridedSlice operator.
 *
 *  After creating the NdStridedSlice operator, Input, Output, and computation stream, pass them to
 *  the function to calculate the NdStridedSlice operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdStridedSliceOpForward_V2(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);

/* Nd Strided Slice operation end */

/* Plugin operation start */

/*!
 *  @brief cnmlPluginOpParamsBufferMarkTensorDimension.
 *
 *  In some situations, one pluginOp's param relates to its Input/Outputs'
 *  dimensions and can not be determined before compilation.
 *  Use this API to mark that dimension and param, a particular value will
 *  be filled back during compilation.
 *
 *  @param[in]  params
 *    Input. parameter pointer needed in kernel
 *  @param[in]  mark_tensors
 *    Input. Array of tensors.
 *  @param[in]  dim
 *    Input. Array of dims.
 *  @param[in]  mark_num
 *    Input. number of tensors and dims.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    -The input tensor is nullptr.
 *    -The param pointer is nullptr.
 */

CNML_DLL_API cnmlStatus_t
cnmlPluginOpParamsBufferMarkTensorDimension(cnrtKernelParamsBuffer_t params,
                                            cnmlTensor_t *mark_tensors,
                                            cnmlDimension_t *dim,
                                            int mark_num);

/*!
 *  @brief cnmlCreatePluginOp.
 *
 *  Create a Plugin operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, the operator name, the kernel function
 *  pointer, the kernel parameter pointer, and the input and output tensors, pass them to the
 *  function to create a Plugin operator.
 *
 *  PluginOp is firstly a CNML Op, and Plugin means that the specific behavior of this instance of
 *  Op is determined by the Kernel of its Plugin compiler. The core operation is to provide the
 *  kernel of the compiler with the same environment provided by cnrtInvokeKernel, so that the
 *  compiler's operators can be run using CNML.
 *
 *  The size of the Plugin operator is related to the specific kernel being written.
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  name
 *    Input. operator name for distinguishing several Plugin Ops.
 *  @param[in]  kernel
 *    Input. kernel function pointer.
 *  @param[in]  params
 *    Input. parameter pointer needed in kernel
 *  @param[in]  inputs_tensor
 *    Input. int output_num.
 *  @param[in]  input_num
 *    Input. number of input tensors.
 *  @param[in]  outputs_tensor
 *    Input. Array of output tensors.
 *  @param[in]  output_num
 *    Input. number of output tensors.
 *  @param[in]  statics_tensor
 *    Input. Array of constant tensors.
 *  @param[in]  static_num
 *    Input. number of constant tensors.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePluginOp(cnmlBaseOp_t *op,
                                             const char *name,
                                             void *kernel,
                                             cnrtKernelParamsBuffer_t params,
                                             cnmlTensor_t *input_tensors,
                                             int input_num,
                                             cnmlTensor_t *output_tensors,
                                             int output_num,
                                             cnmlTensor_t *statics_tensor,
                                             int static_num);

/*!
 *  @brief cnmlComputePluginOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputePluginOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified Plugin operator on the MLU.
 *
 *  After creating the Plugin operator, Input, Output, and computation queue, pass them to the
 *  function to It is used to compute the Plugin operator.
 *
 *  @param[out]  outputs
 *    Output. An array of MLU addresses pointing to the output position.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  inputs
 *    Input. An array of MLU addresses pointing to the input data.
 *  @param[in]  input_num
 *    Input. number of the input tensors.
 *  @param[in]  output_num
 *    Input. number of the output tensors.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputePluginOpForward_V3(cnmlBaseOp_t op,
                                                        void *inputs[],
                                                        int input_num,
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief cnmlComputePluginOpForward_V4.
 *
 *  It is used to compute the user-specified Plugin operator on the MLU.
 *
 *  After creating the Plugin operator, Input, Output, and computation queue, pass them to the
 *  function to It is used to compute the Plugin operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input.  A pointer array, each element pointing to the MLU address of input data.
 *  @param[in] intput_num
 *    Input.  The number of elements in the inputs array.
 *  @param[in] output_tensors
 *    Input. Input MLU tensor array pointer. Pass NULL if not used.
 *  @param[out] outputs
 *    Output. A pointer array, each element pointing to the MLU address of output position.
 *  @param[in] output_num
 *    Input.  The number of elements in the outputs array.
 *  @param[in] queue
 *    Input.  A computation stream pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputePluginOpForward_V4(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensors[],
                                                        void *inputs[],
                                                        int input_num,
                                                        cnmlTensor_t output_tensors[],
                                                        void *outputs[],
                                                        int output_num,
                                                        cnrtQueue_t queue,
                                                        void *extra);
/* Plugin operation end*/

/* dynamic rw param start */
/*!
 *  @struct cnmlDynamicRWParam
 *  @brief A struct.
 *
 *  cnmlDynamicRWParam is a structure created for dynamicRead and dynamicWrite Ops,
 *  cnmlCreateDynamicRWParam() is used to create an instance of cnmlDynamicRWParam_t,
 *  cnmlDestroyDynamicRWParam() is used to destroy an instance of cnmlDynamicRWParam_t
 */
struct cnmlDynamicRWParam;

/*! ``cnmlDynamicRWParam_t`` is a pointer to ``cnmlDynamicRWParam`` which is a
 *  structure holding the description of a dynamicRead or dynamicWrite operation param.
 */
typedef struct cnmlDynamicRWParam *cnmlDynamicRWParam_t;

/*!
 *  @brief A function
 *
 *  According to the pointer given by the user, the function creates a DynamicRW
 *  operation parameter struct and fills in the struct with the parameters input
 *  by the user.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of struct of DynamicRW operator
 *    operation parameter.
 *  @param[in] dim;
 *    Input. The dimension that is used for dynamic reading or writing. For detailed supported
 * values,
 *    see cnmlDimension_t data type.
 *  @param[in] length;
 *    Input. the length for dynamic reading or writing.
 *  retval CNML_STATUS_SUCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following condition is met:
 *      - param is a null pointer
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDynamicRWParam(cnmlDynamicRWParam_t *param,
                                                   cnmlDimension_t dim,
                                                   int length);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the struct pointer of DynamicRW
 *  operator operation parameter is freed.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  After the operation of the DynamicRW operator is finished, the created struct
 *  pointer of DynamicRW operator operation parameter is freed.
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of struct of DynamicRW operator
 *  operation parameter.
 *  @retval CNML_STATUS_SUCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *      - param is null pointer.
 *      - The content of the pointer pointed to by param has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyDynamicRWParam(cnmlDynamicRWParam_t *param);

/* dynamic rw param end */

/* dynamic write start */

/*!
 *  @brief cnmlCreateDynamicWriteOp.
 *
 *  Create an DynamicWrite operator based on the base operator pointer given by the user.
 *
 *  Writes data from input_Y [N2 C2 H2 W2] to input_X [N1, C1, H1, W1] and then copies the
 *  input_X to output [N1, C1, H1, W1]. The offset address of the input_X is specified by input_Z
 *  [1 1 1 1].
 *
 *  You can specify the dimension and length that is used for dynamic writing in the
 *   ``cnmlDynamicRWParam_t `` struct.
 *
 *  **Formula**
 *
 *    The formula varies depending on the values of the ``dim`` and ``length`` parameters you
 *    set in the ``cnmlDynamicRWParam_t `` struct.
 *
 *    If the ``dim`` parameter is set to DIM_N:
 *
 *      C1 = C2, H1 = H2, W1 = W2, and N2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[(idx + input_Z) C1 H1 W1] = input_Y[idx C2 H2 W2]
 *
 *        output = input_X   }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Z)  < N1
 *
 *    If the ``dim`` parameter is set to DIM_C:
 *
 *      N1 = N2, H1 = H2, W1 = W2, and C2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 (idx + input_Z) H1 W1] = input_Y[N2 idx H2 W2]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Z) < C1
 *
 *    If the ``dim`` parameter is set to DIM_H:
 *
 *      N1 = N2, C1 = C2, W1 = W2, and H2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 C1 (idx + input_Z) W1] = input_Y[N2 C2 idx W2]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Z) < H1
 *
 *    If the ``dim`` parameter is set to DIM_W:
 *
 *      N1 = N2, C1 = C2, H1 = H2, and W2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 C1 H1 (idx + input_Z)] = input_Y[N2 C2 H2 idx]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Z) < W1
 *
 *  **DataType**
 *
 *    Unlimited
 *
 *  **Scale Limitation**
 *
 *    (N1 * C1 * H1 * W1) >= (N2 * C2 * H2 * W2)
 *
 *  *Performance Optimization*
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  param
 *    Input. A cnmlDynamicRWParam_t.
 *  @param[in]  input_tensor_X
 *    Input. X 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Y
 *    Input. Y 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Z
 *    Input. Z 4-dimensional MLU input tensor.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDynamicWriteOp(cnmlBaseOp_t *op,
                                                   cnmlDynamicRWParam_t param,
                                                   cnmlTensor_t input_tensor_X,
                                                   cnmlTensor_t input_tensor_Y,
                                                   cnmlTensor_t input_tensor_Z,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeDynamicWriteOpForward.
 *
 *  It is used to compute the user-specified DynamicWrite operator on the MLU.
 *
 *  After creating the DynamicWrite operator, Input, Output, and computation stream, pass them to
 *  the function to It is used to compute the DynamicWrite operator.
 *
 *  **Formula**
 *
 *    The formula varies depending on the values of the ``dim`` and ``length`` parameters you
 *    set in the ``cnmlDynamicRWParam_t `` struct.
 *
 *    If the ``dim`` parameter is set to DIM_N:
 *
 *      C1 = C2, H1 = H2, W1 = W2, and N2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[(idx + input_Z) C1 H1 W1] = input_Y[idx C2 H2 W2]
 *
 *        output = input_X   }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Z)  < N1
 *
 *    If the ``dim`` parameter is set to DIM_C:
 *
 *      N1 = N2, H1 = H2, W1 = W2, and C2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 (idx + input_Z) H1 W1] = input_Y[N2 idx H2 W2]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Z) < C1
 *
 *    If the ``dim`` parameter is set to DIM_H:
 *
 *      N1 = N2, C1 = C2, W1 = W2, and H2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 C1 (idx + input_Z) W1] = input_Y[N2 C2 idx W2]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Z) < H1
 *
 *    If the ``dim`` parameter is set to DIM_W:
 *
 *      N1 = N2, C1 = C2, H1 = H2, and W2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        input_X[N1 C1 H1 (idx + input_Z)] = input_Y[N2 C2 H2 idx]
 *
 *        output = input_X  }
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Z) < W1
 *
 *  **DataType**
 *
 *    Unlimited
 *
 *  **Scale Limitation**
 *
 *   (N1 * C1 * H1 * W1) >= (N2 * C2 * H2 * W2)
 *
 *
 *  *Performance Optimization*
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor_X
 *    Input. X 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Y
 *    Input. Y 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Z
 *    Input. Z 4-dimensional MLU input tensor.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDynamicWriteOpForward(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor_X,
                                                           void *input_X,
                                                           cnmlTensor_t input_tensor_Y,
                                                           void *input_Y,
                                                           cnmlTensor_t input_tensor_Z,
                                                           void *input_Z,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* dynamic write end */

/* dynamic read start */

/*!
 *  @brief cnmlCreateDynamicReadOp.
 *
 *  Create an DynamicRead operator based on the base operator pointer given by the user.
 *
 *  Reads data from input_X [N1, C1, H1, W1] to output [N2, C2, H2, W2].
 *  The offset address of the input_X is specified by input_Y [1 1 1 1].
 *
 *  You can specify the dimension and length that is used for dynamic reading in the param .
 *
 *  **Formula**
 *
 *    The formula varies depending on the values of the ``dim`` and ``length`` parameters you
 *    set in the ``cnmlDynamicRWParam_t `` struct.

 *    If the ``dim`` parameter is set to DIM_N:
 *
 *      C1 = C2, H1 = H2, W1 = W2, and N2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)
 *
 *        output[idx C2 H2 W2] = input_X[(idx + input_Y) C1 H1 W1]
 *
 *      **Note:**  Make sure input_Y you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Y)  < N1
 *
 *    If the ``dim`` parameter is set to DIM_C:
 *
 *      N1 = N2, H1 = H2, W1 = W2, and C2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)
 *
 *        output[N2 idx H2 W2] = input_X[N1 (idx + input_Y) H1 W1]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Y) < C1
 *
 *    If the ``dim`` parameter is set to DIM_H:
 *
 *      N1 = N2, C1 = C2, W1 = W2, and H2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        output[N2 C2 idx W2] = input_X[N1 C1 (idx + input_Y) W1]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Y) < H1
 *
 *    If the ``dim`` parameter is set to DIM_W:
 *
 *      N1 = N2, C1 = C2, H1 = H2, and W2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        output[N2 C2 H2 idx] = input_X[N1 C1 H1 (idx + input_Y)]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Y) < W1
 *
 *  **DataType**
 *
 *    Unlimited
 *
 *  **Scale Limitation**
 *
 *   (N1 * C1 * H1 * W1) >= (N2 * C2 * H2 * W2)
 *
 *  *Performance Optimization*
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  param
 *    Input. A cnmlDynamicRWParam_t.
 *  @param[in]  input_tensor_X
 *    Input. X 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Y
 *    Input. Y 4-dimensional MLU input tensor.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateDynamicReadOp(cnmlBaseOp_t *op,
                                                  cnmlDynamicRWParam_t param,
                                                  cnmlTensor_t input_tensor_X,
                                                  cnmlTensor_t input_tensor_Y,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeDynamicReadOpForward.
 *
 *  It is used to compute the user-specified DynamicRead operator on the MLU.
 *
 *  After creating the DynamicRead operator, Input, Output, and computation stream, pass them to the
 *  function to It is used to compute the DynamicRead operator.
 *
 *  **Formula**
 *
 *    The formula varies depending on the values of the ``dim`` and ``length`` parameters you
 *    set in the ``cnmlDynamicRWParam_t `` struct.

 *    If the ``dim`` parameter is set to DIM_N:
 *
 *      C1 = C2, H1 = H2, W1 = W2, and N2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)
 *
 *        output[idx C2 H2 W2] = input_X[(idx + input_Y) C1 H1 W1]
 *
 *      **Note:**  Make sure input_Y you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Y)  < N1
 *
 *    If the ``dim`` parameter is set to DIM_C:
 *
 *      N1 = N2, H1 = H2, W1 = W2, and C2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)
 *
 *        output[N2 idx H2 W2] = input_X[N1 (idx + input_Y) H1 W1]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Y) < C1
 *
 *    If the ``dim`` parameter is set to DIM_H:
 *
 *      N1 = N2, C1 = C2, W1 = W2, and H2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        output[N2 C2 idx W2] = input_X[N1 C1 (idx + input_Y) W1]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *       (idx + input_Y) < H1
 *
 *    If the ``dim`` parameter is set to DIM_W:
 *
 *      N1 = N2, C1 = C2, H1 = H2, and W2 equals to the value of ``length``
 *
 *      for ( idx=0;  idx < the value of the ``length`` parameter;  idx++)  {
 *
 *        output[N2 C2 H2 idx] = input_X[N1 C1 H1 (idx + input_Y)]
 *
 *      **Note:**  Make sure input_Z you specified meet the following limitation, otherwise
 *      an error occurred:
 *
 *      (idx + input_Y) < W1
 *
 *  **DataType**
 *
 *    Unlimited
 *
 *  **Scale Limitation**
 *
 *    (N1 * C1 * H1 * W1) >= (N2 * C2 * H2 * W2)
 *
 *  *Performance Optimization*
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor_X
 *    Input. X 4-dimensional MLU input tensor.
 *  @param[in]  input_tensor_Y
 *    Input. Y 4-dimensional MLU input tensor.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeDynamicReadOpForward(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor_X,
                                                          void *input_X,
                                                          cnmlTensor_t input_tensor_Y,
                                                          void *input_Y,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* dynamic read end */

/*L1L2Norm operation start*/
/*!
 *  @brief cnmlCreateL1L2NormOp.
 *
 *  Computes L1/L2Norm of data in a specified dimension of a tensor.
 *
 *  Create an L1L2Norm operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create an L1L2Norm operator.
 *
 *  **Formula**
 *
 *  L1Norm:
 *
 *  DIM_N: out[1 c h w] = sum(abs(in[n c h w]), DIM_N)
 *
 *  DIM_C: out[n 1 h w] = sum(abs(in[n c h w]), DIM_C)
 *
 *  DIM_H: out[n c 1 w] = sum(abs(in[n c h w]), DIM_H)
 *
 *  DIM_W: out[n c h 1] = sum(abs(in[n c h w]), DIM_W)
 *
 *  L2Norm:
 *
 *  DIM_N: out[1 c h w] = sum(power(in[n c h w], 2), DIM_N)
 *
 *  DIM_C: out[n 1 h w] = sum(power(in[n c h w], 2), DIM_C)
 *
 *  DIM_H: out[n c 1 w] = sum(power(in[n c h w], 2), DIM_H)
 *
 *  DIM_W: out[n c h 1] = sum(power(in[n c h w], 2), DIM_W)
 *
 *  The ``DIM_N``, ``DIM_C``, ``DIM_H``, and ``DIM_W`` are dimensions to be reduced.
 *  ``in[]`` specifies the input data and ``out[]`` specifies the output data
 *  that is the sum of certain dimension.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      -input: float16, float32
 *
 *      -output: float16, float32
 *
 *    MLU220:
 *
 *      -input: float16, float32
 *
 *      -output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:   < 10000
 *
 *      NHW direction: < 2000
 *
 *    MLU220:
 *
 *      C direction:   < 10000
 *
 *      NHW direction: < 2000
 *
 *  *Performance Optimazation*
 *
 *    The number of bytes in the C dimension is a multiple of 128.
 *
 *  **Tips**
 *
 *  when scale becomes larger, error rate under some cases will exceed 1%
 *  for example, error rate will be 1.5% under L1Norm when c=10000, n=h=w=32
 *  at C direction, and error rate under L1/L2Norm at H direction when h=2000,
 *  n=c=w=64 will also exceed 1%.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] norm
 *    Input. A int number which determines the compute norm. 1 represents L1Norm and 2 represents
 *    L2Norm.
 *  @param[in] axis
 *    Input. An enumeration variable of cnmlDimension_t, Supported values are: CNML_DIM_N,
 * CNML_DIM_C,
 *    CNML_DIM_H and CNML_DIM_W.
 *    The selected dimension should be set to 1. Other dimensions should be set to the same value
 * with the input.
 *    - If the value is set to CNML_DIM_N, the shape of the tensor is [1, c, h, w].
 *    - If the value is set to CNML_DIM_C, the shape of the tensor is [n, 1, h, w].
 *    - If the value is set to CNML_DIM_H, the shape of the tensor is [n, c, 1, w].
 *    - If the value is set to CNML_DIM_W, the shape of the tensor is [n, c, h, 1].
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16/float32 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor, the size of dimensions of which the shape is reduced
 * must be 1;
 *    the size of other dimensions is consistent with that of input,
 *    supporting data of float16/float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateL1L2NormOp(int norm,
                                               cnmlDimension_t axis,
                                               cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t output_tensor);
/*!
 *  @brief cnmlComputeL1L2NormOpForward.
 *
 *  Compute the L1L2Norm operator given by users on the MLU.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. A 4-D tensor, supporting data of float16/float32 type.
 *  @param[out] output
 *    output. A 4-D tensor, supporting data pf float16/float32 type
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeL1L2NormOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/*L1L2Norm end*/

/* axpy start */

/*!
 *  @brief cnmlCreateAxpyOp.
 *
 *  Create an Axpy operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create an Axpy operator.
 *
 *  This function has the functionality of output = A Ã— X + Y.
 *
 *  The input input_tensor_X and input_tensor_Y must have the same shape.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w] + Y [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *       float16: < 43500
 *
 *       float32: < 21792
 *
 *      NHW direction: unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor_A
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, 1, 1], supporting data
 *    of float16 type.
 *  @param[in]  input_tensor_X
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @param[in]  input_tensor_Y
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAxpyOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor_A,
                                           cnmlTensor_t input_tensor_X,
                                           cnmlTensor_t input_tensor_Y,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeAxpyOpForward_V3.
 *
 *  It is used to compute the user-specified Axpy operator on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAxpyOpForward_V4
 *  is recommended to use.
 *
 *  After creating the Axpy operator, Input, Output, runtime parameters, and computation queue, pass
 *  them to the function to It is used to compute the Axpy operator.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w] + Y [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *       float16: < 43500
 *
 *       float32: < 21792
 *
 *      NHW direction: unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input_A
 *    Input. An MLU address pointing to the input data tensor A.
 *  @param[in]  input_X
 *    Input. An MLU address pointing to the input data tensor X.
 *  @param[in]  input_Y
 *    Input. An MLU address pointing to the input data tensor Y.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxpyOpForward_V3(cnmlBaseOp_t op,
                                                      void *input_A,
                                                      void *input_X,
                                                      void *input_Y,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeAxpyOpForward_V4.
 *
 *  It is used to compute the user-specified Axpy operator on the MLU.
 *
 *  After creating the Axpy operator, Input, Output, runtime parameters, and computation queue, pass
 *  them to the function to It is used to compute the Axpy operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_A
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_A
 *    Input. MLU address pointing to input_A data.
 *  @param[in] input_tensor_X
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_X
 *    Input. MLU address pointing to input_X data.
 *  @param[in] input_tensor_Y
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_Y
 *    Input. MLU address pointing to input_Y data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxpyOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor_A,
                                                      void *input_A,
                                                      cnmlTensor_t input_tensor_X,
                                                      void *input_X,
                                                      cnmlTensor_t input_tensor_Y,
                                                      void *input_Y,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* axpy end */

/* axpby start */

/*!
 *  @brief cnmlCreateAxpByOp.
 *
 *  Create an AxpBy operator based on the base operator pointer given by user.
 *
 *  After creating a pointer to the base operator address, input and output
 *  tensors, pass them to the function to create an AxpBy operator.
 *
 *  This function has the functionality of output = A * X + B * Y.
 *
 *  The input input_tensor_X and input_tensor_Y must have the same shape.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w] + B [n c 1 1] * Y [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *       float16: < 32500
 *
 *       float32: < 16200
 *
 *      NHW direction: unlimited
 *
 *
 *  @param[out]  op
 *    Output. a pointer to the base operator address.
 *  @param[in]  input_tensor_A
 *    Input. a 4-dimensional MLU input tensor, of which the shape is
 *    [ni, ci, 1, 1], supporting data of float16 type.
 *  @param[in]  input_tensor_X
 *    Input. a 4-dimensional MLU input tensor, of which the shape is
 *    [ni, ci, hi, wi], supporting data of float16 type.
 *  @param[in]  input_tensor_B
 *    Input. a 4-dimensional MLU input tensor, of which the shape is
 *    [ni, ci, 1, 1], supporting data of float16 type.
 *  @param[in]  input_tensor_Y
 *    Input. a 4-dimensional MLU input tensor, of which the shape is
 *    [ni, ci, hi, wi], supporting data of float16 type.
 *  @param[in]  output
 *    Input. a 4-dimensional MLU input tensor, of which the shape is
 *    [ni, ci, hi, wi], supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAxpByOp(cnmlBaseOp_t *op,
                                            cnmlTensor_t input_tensor_A,
                                            cnmlTensor_t input_tensor_X,
                                            cnmlTensor_t input_tensor_B,
                                            cnmlTensor_t input_tensor_Y,
                                            cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeAxpByOpForward_V3.
 *
 *  It is used to compute the user-specified AxpBy operator on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAxpByOpForward_V4
 *  is recommended to use.
 *
 *  After creating the AxpBy operator, Input, Output, runtime parameters,
 *  and computation queue, pass them to the function to It is used to compute
 *  the AxpBy operator.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w] + B [n c 1 1] * Y [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *      float16: < 32500
 *
 *      float32: < 16200
 *
 *      NHW direction: unlimited
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input_A
 *    Input. An MLU address pointing to the input data tensor A.
 *  @param[in]  input_X
 *    Input. An MLU address pointing to the input data tensor X.
 *  @param[in]  input_B
 *    Input. An MLU address pointing to the input data tensor B.
 *  @param[in]  input_Y
 *    Input. An MLU address pointing to the input data tensor Y.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data
 *    parallelism and device affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxpByOpForward_V3(cnmlBaseOp_t op,
                                                       void *input_A,
                                                       void *input_X,
                                                       void *input_B,
                                                       void *input_Y,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeAxpByOpForward_V4.
 *
 *  It is used to compute the user-specified AxpBy operator on the MLU.
 *
 *  After creating the AxpBy operator, Input, Output, runtime parameters,
 *  and computation queue, pass them to the function to It is used to compute
 *  the AxpBy operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor_A
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_A
 *    Input. MLU address pointing to input_A data.
 *  @param[in] input_tensor_X
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input__X
 *    Input. MLU address pointing to input_X data.
 *  @param[in] input_tensor_B
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_B
 *    Input. MLU address pointing to input_B data.
 *  @param[in] input_tensor_Y
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_B
 *    Input. MLU address pointing to input_Y data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxpByOpForward_V4(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor_A,
                                                       void *input_A,
                                                       cnmlTensor_t input_tensor_X,
                                                       void *input_X,
                                                       cnmlTensor_t input_tensor_B,
                                                       void *input_B,
                                                       cnmlTensor_t input_tensor_Y,
                                                       void *input_Y,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* axpby end */

/* ax start */

/*!
 *  @brief cnmlCreateAxOp.
 *
 *  Create an Ax operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create an Ax operator.
 *
 *  This function has the functionality of output = A Ã—X.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *       float16: < 65500
 *
 *       float32: < 16200
 *
 *      NHW direction: unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  input_tensor_A
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, 1, 1], supporting data
 *    of float16 type.
 *  @param[in]  input_tensor_X
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAxOp(cnmlBaseOp_t *op,
                                         cnmlTensor_t input_tensor_A,
                                         cnmlTensor_t input_tensor_X,
                                         cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeAxOpForward_V3.
 *
 *  It is used to compute the user-specified Ax operator on the MLU.
 *
 *  After creating the Ax operator, Input, Output, runtime parameters, and computation queue, pass
 *  them to the function to It is used to compute the Ax operator.
 *
 *  **Formula**
 *
 *    output X [n c h w] = A [n c 1 1] * X [n c h w]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *       float16: < 65500
 *
 *       float32: < 32750
 *
 *      NHW direction: unlimited
 *
 *  Deprecated. This interface will be deleted in next version and cnmlComputeAxOpForward_V4
 *  is recommended to use.
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input_A
 *    Input. An MLU address pointing to the input data tensor A.
 *  @param[in]  input_X
 *    Input. An MLU address pointing to the input data tensor X.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxOpForward_V3(cnmlBaseOp_t op,
                                                    void *input_A,
                                                    void *input_X,
                                                    void *output,
                                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                                    cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeAxOpForward_V4.
 *
 *  It is used to compute the user-specified Ax operator on the MLU.
 *
 *  After creating the Ax operator, Input, Output, runtime parameters, and computation queue, pass
 *  them to the function to It is used to compute the Ax operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensori_A
 *    Input. First input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_A
 *    Input. First MLU address pointing to input_A data.
 *  @param[in] input_tensor_X
 *    Input. Second input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_X
 *    Input. Second MLU address pointing to input_X data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAxOpForward_V4(cnmlBaseOp_t op,
                                                    cnmlTensor_t input_tensor_A,
                                                    void *input_A,
                                                    cnmlTensor_t input_tensor_X,
                                                    void *input_X,
                                                    cnmlTensor_t output_tensor,
                                                    void *output,
                                                    cnrtQueue_t queue,
                                                    void *extra);
/* ax end */

/* reduce sum operation start  */

/*!
 *  @brief cnmlCreateReduceSumOp.
 *
 *  Create a Reduce Sum operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create a Reduce Sum operator.
 *
 *  The functionality of this operator is to sum the input Tensor in the selected dimensions to be
 *  reduced.
 *
 *  **Formula**
 *
 *    DIM_N: out[1 c h w] = sum(in[n c h w], DIM_N)
 *
 *    DIM_C: out[n 1 h w] = sum(in[n c h w], DIM_C)
 *
 *    DIM_H: out[n c 1 w] = sum(in[n c h w], DIM_H)
 *
 *    DIM_W: out[n c h 1] = sum(in[n c h w], DIM_W)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *    We recommend you use FP32 rather than FP16 to prevent precision problem.
 *    If you want to use FP16, all below conditions should be met:
 *
 *      1. # of reduce dimension under 10k.
 *
 *      2. Input data is normal distribution with mean value [-1, 1], variation[-10, 10]
 *
 *      Unlimited in FP32
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  mode
 *    Input. An enumeration variable, the dimension to be reduced by the user,
 *    supporting N, C, H, W.
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional tensor, the size of dimensions of which the shape is reduced must be 1;
 *    the size of other dimenisions is consistent with that of input,
 *    supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReduceSumOp(cnmlBaseOp_t *op,
                                                cnmlDimension_t dim,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeReduceSumOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReduceSumOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified Reduce Sum operator on the MLU.
 *
 *  After creating the Reduce Sum operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Reduce Sum operator.
 *
 *  **Formula**
 *
 *    DIM_N: out[1 c h w] = sum(in[n c h w], DIM_N)
 *
 *    DIM_C: out[n 1 h w] = sum(in[n c h w], DIM_C)
 *
 *    DIM_H: out[n c 1 w] = sum(in[n c h w], DIM_H)
 *
 *    DIM_W: out[n c h 1] = sum(in[n c h w], DIM_W)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *    We recommend you use FP32 rather than FP16 to prevent precision problem.
 *    If you want to use FP16, all below conditions should be met:
 *
 *      1. # of reduce dimension under 10k.
 *
 *      2. Input data is normal distribution with mean value [-1, 1], variation[-10, 10]
 *
 *      Unlimited in FP32
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty *    - The output pointer is empty

 */
CNML_DLL_API cnmlStatus_t
cnmlComputeReduceSumOpForward_V3(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeReduceSumOpForward_V4.
 *
 *  It is used to compute the user-specified Reduce Sum operator on the MLU.
 *
 *  After creating the Reduce Sum operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Reduce Sum operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReduceSumOpForward_V4(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);
/* reduce sum operation end   */

/* std_dev operation start */
/*!
 *  @brief cnmlCreateStdDevOp.
 *  Create a Std Dev operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output tensors, pass them to
 *  the function to create a Std Dev operator.
 *
 *  The functionality of this operator is to compute std of the input Tensor in the selected
 * dimensions to be
 *  reduced.
 *
 *  **Formula**
 *
 *    unbiased is false:
 *
 *    out[1 c h w] = sqrt{mean{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}}, DIM_N
 *
 *    out[n 1 h w] = sqrt{mean{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}}, DIM_C
 *
 *    out[n c 1 w] = sqrt{mean{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}}, DIM_H
 *
 *    out[n c h 1] = sqrt{mean{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}}, DIM_W
 *
 *    unbiased is true:
 *
 *    out[1 c h w] = sqrt{{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}/(n-1)}, DIM_N
 *
 *    out[n 1 h w] = sqrt{{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}/(c-1)}, DIM_C
 *
 *    out[n c 1 w] = sqrt{{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}/(h-1)}, DIM_H
 *
 *    out[n c h 1] = sqrt{{(in[n, c, h, w]-mean(in[i, j, k, l]))^2}/(w-1)}, DIM_W
 *
 *  **Supports MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  mode
 *    Input. An enumeration variable, the dimension to be reduced by the user,
 *    supporting N, C, H, W.
 *  @param[in]  unbiased
 *    Input. A bool variable, use Bessel correction or not
 *    supporting True and False
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 and float32 type.
 *  @param[in]  output
 *    Input. A 4-dimensional tensor, the size of dimensions of which the shape is reduced must be 1;
 *    the size of other dimenisions is consistent with that of input,
 *    supporting data of float16 and float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateStdDevOp(cnmlBaseOp_t *op,
                                             cnmlDimension_t mode,
                                             bool unbiased,
                                             cnmlTensor_t input,
                                             cnmlTensor_t output);
/*!
 *  @brief cnmlComputeStdDevOpForward.
 *
 *  It is used to compute the user-specified Std Dev operator on the MLU.
 *
 *  After creating the Std Dev operator, Input, Output, runtime parameters, and computation
 *  queue, pass them to the function to It is used to compute the Std Dev operator.
 *
 *  **Supports MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeStdDevOpForward(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* std_dev operation end */

/* nd reduce sum operation start */

/*!
 *  @brief cnmlCreateNdReduceSumOp.
 *
 *  Create a reduce sum operator to support arbitrary dimension tensor based
 *  on the base operator pointer given by the user.
 *
 *  This operator is extended to support arbitrary dimension based on the reduce sum operator.
 *
 *  After creating a pointer to the base operator address, dimension of reduce operation, input and
 *  output tensors, pass them to the function to create a reduce sum operator
 *  that supports multi dimensions.
 *
 *  Before creating the operator, declare a pointer to the address of the operator parameter struct
 *  and pass it to the function together with the desired operator parameters to set the operator
 *  parameters.
 *
 *  Perform summation in the selected dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  dim
 *    Input. A variable of int type for specifying the dimension where the reduce operation is
 * performed.
 *  @param[in]  input
 *    Input. A multi-dimensional MLU tensor, supporting data of float16 type.
 *  @param[in]  output
 *    Input. A multi-dimensional MLU tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *  (At least one of) the following conditions are not satisfied:
 *    - The operator pointer is empty.
 *    - The input pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdReduceSumOp(cnmlBaseOp_t *op,
                                                  int dim,
                                                  cnmlTensor_t input_tensor,
                                                  cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeNdReduceSumOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdReduceSumOpForward_V2 is recommended to use.
 *
 *  It is used to compute the reduce sum operator that supports multi dimensions on the MLU.
 *
 *  After creating a multidimensional reduce sum operator, Input, Output, and computation stream,
 *  pass them to the function to It is used to compute the reduce sum operator
 *  that supports multi dimensions.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and
 *    device affinity at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdReduceSumOpForward(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeNdReduceSumOpForward_V2.
 *
 *  It is used to compute the reduce sum operator that supports multi dimensions on the MLU.
 *
 *  After creating a multidimensional reduce sum operator, Input, Output, and computation stream,
 *  pass them to the function to It is used to compute the reduce sum operator
 *  that supports multi dimensions.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdReduceSumOpForward_V2(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* nd reduce sum operation end */

/* reduce mean operation start  */

/*!
 *  @brief cnmlCreateNdReduceSumOp.
 *
 *  Create a reduce mean operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, reduce dimension, input and output
 *  tensors, pass them to the function to create a reduce mean operator.
 *
 *  Before creating the operator, declare a pointer to the address of the operator parameter struct
 *  and pass it to the function together with the desired operator parameters to set the operator
 *  parameters.
 *
 *  Perform mean operation in the selected dimension.
 *
 *  if the mode is CNML_DIM_N, the shape is [1, c, h, w];
 *
 *  if the mode is CNML_DIM_C, the shape is [n, 1, h, w];
 *
 *  if the mode is CNML_DIM_H, the shape is [n, c, 1, w];
 *
 *  if the mode is CNML_DIM_W, the shape is [n, c, h, 1];
 *
 *  **Formula**
 *
 *    DIM_N: out[1 c h w] = mean(in[n c h w], DIM_N)
 *
 *    DIM_C: out[n 1 h w] = mean(in[n c h w], DIM_C)
 *
 *    DIM_H: out[n c 1 w] = mean(in[n c h w], DIM_H)
 *
 *    DIM_W: out[n c h 1] = mean(in[n c h w], DIM_W)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *    We recommend you use FP32 rather than FP16 to prevent precision problem.
 *    If you want to use FP16, all below conditions should be met:
 *
 *      1. # of reduce dimension under 10k.
 *
 *      2. Input data is normal distribution with mean value [-1, 1], variation[-10, 10]
 *
 *      Unlimited in FP32
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  mode
 *    Input. An enumeration constant of the reduce dimension specified on the MLU, where the options
 *    include CNML_DIM_N, CNML_DIM_C, CNML_DIM_H and CNML_DIM_W.
 *  @param[in]  input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [n, c, h, w], supporting data
 *    of float16 type.
 *  @param[in]  output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [n, c, h, w], supporting data
 *    of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The input pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateReduceMeanOp(cnmlBaseOp_t *op,
                                                 cnmlDimension_t dim,
                                                 cnmlTensor_t input_tensor,
                                                 cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeReduceMeanOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeReduceMeanOpForward_V4 is recommended to use.
 *
 *  It is used to compute the reduce mean operator that supports multi dimensions on the MLU.
 *  After creating the reduce mean operator, Input, Output, computation type, and computation
 *  stream, pass them to the function to It is used to compute the reduce mean operator.
 *
 *  **Formula**
 *
 *    DIM_N: out[1 c h w] = mean(in[n c h w], DIM_N)
 *
 *    DIM_C: out[n 1 h w] = mean(in[n c h w], DIM_C)
 *
 *    DIM_H: out[n c 1 w] = mean(in[n c h w], DIM_H)
 *
 *    DIM_W: out[n c h 1] = mean(in[n c h w], DIM_W)
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *    We recommend you use FP32 rather than FP16 to prevent precision problem.
 *    If you want to use FP16, all below conditions should be met:
 *
 *      1. # of reduce dimension under 10k.
 *
 *      2. Input data is normal distribution with mean value [-1, 1], variation[-10, 10]
 *
 *      Unlimited in FP32
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeReduceMeanOpForward_V3(cnmlBaseOp_t op,
                                  void *input,
                                  void *output,
                                  cnrtInvokeFuncParam_t *compute_forw_param,
                                  cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeReduceMeanOpForward_V4.
 *
 *  It is used to compute the reduce mean operator that supports multi dimensions on the MLU.
 *  After creating the reduce mean operator, Input, Output, computation type, and computation
 *  stream, pass them to the function to It is used to compute the reduce mean operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeReduceMeanOpForward_V4(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor,
                                                            void *input,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);
/* reduce mean operation end   */

/* nd reduce mean operation start */

/*!
 *  @brief cnmlCreateNdReduceMeanOp.
 *
 *  Create a reduce mean operator that supports arbitrary dimension tensor based on the base
 * operator pointer
 *  given by the user.
 *
 *  This operator is extended to support arbitrary dimension tensor based on the reduce mean
 * operator.
 *
 *  After creating a pointer to the base operator address, reduce dimension, input and output
 *  tensors, pass them to the function to create a reduce mean operator that supports multi
 *  dimensions.
 *
 *  Before creating the operator, declare a pointer to the address of the operator parameter struct
 *  and pass it to the function together with the desired operator parameters to set the operator
 *  parameters. Perform mean operation in the selected dimension.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  op
 *    Output. A pointer to the base operator address.
 *  @param[in]  dim
 *    Input. A variable of int type for specifying the dimension where the reduce operation is
 *    performed.
 *  @param[in]  input
 *    Input. A multi-dimensional MLU output tensor, supporting data of float16 type.
 *  @param[in]  output
 *    Input. A multi-dimensional MLU weight tensor, supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The input pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdReduceMeanOp(cnmlBaseOp_t *op,
                                                   int dim,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeNdReduceMeanOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeNdReduceMeanOpForward_V2 is recommended to use.
 *
 *  It is used to compute the reduce mean operator that supports multi dimensions on the MLU.
 *
 *  After creating a reduce mean operator that supports multi dimensions, Input, Output, and
 *  computation stream, pass them to the function to It is used to compute the reduce mean
 *  operator that supports multi dimensions.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address that points to the input data.
 *  @param[in]  compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 * affinity
 *    at runtime are recorded.
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeNdReduceMeanOpForward(cnmlBaseOp_t op,
                                 void *input,
                                 void *output,
                                 cnrtInvokeFuncParam_t *compute_forw_param,
                                 cnrtQueue_t queue);

/*!
 *  @brief cnmlComputeNdReduceMeanOpForward.
 *
 *  It is used to compute the reduce mean operator that supports multi dimensions on the MLU.
 *
 *  After creating a reduce mean operator that supports multi dimensions, Input, Output, and
 *  computation stream, pass them to the function to It is used to compute the reduce mean
 *  operator that supports multi dimensions.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdReduceMeanOpForward_V2(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnrtQueue_t queue,
                                                              void *extra);

/* nd reduce mean operation end */

/* sin operation start */

/*!
 *  @brief cnmlCreateSinOp.
 *
 *  Create a Sin operator based on the base operator pointer given by the user.
 *  After creating a pointer to the base operator address, input and output tensors,
 *  pass them to the function to create a Sin operator.
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=sin(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor. The shapes of input
 *    and output should be exactly the same.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is empty.
 *    - input_tensor is empty.
 *    - output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSinOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeSinOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSinOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified sine operator on the MLU.
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=sin(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input parameter operator pointer op is empty.
 *    - Input parameter tensor pointer input is empty.
 *    - Output parameter tensor pointer output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSinOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeSinOpForward_V4.
 *
 *  It is used to compute the user-specified sine operator on the MLU.
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=sin(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSinOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* sin operation end */

/* cos operation start */

/*!
 *  @brief cnmlCreateCosOp.
 *
 *  Create a cosine operator based on the base operator pointer given by the user.
 *  After creating a pointer to the base operator address, input and output tensors,
 *  pass them to the function to create a Cos operator.
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=cos(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU tensor.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU tensor. The shapes of input
 *    and output should be exactly the same.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is empty.
 *    - input_tensor is empty.
 *    - output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCosOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeCosOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeCosOpForward_V4 is recommended to use.
 *  It is used to compute the user-specified cosine operator on the MLU.
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=cos(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input parameter operator pointer op is empty.
 *    - Input parameter tensor pointer input is empty.
 *    - Output parameter tensor pointer output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCosOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeCosOpForward_V4.
 *
 *  It is used to compute the user-specified cosine operator on the MLU.
 *  Parameter explanation:
 *
 *  **Formula**
 *
 *    out[n,c,h,w]=cos(in[n,c,h,w]);
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *    MLU220:
 *
 *      input: float16, float32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *    MLU220:
 *
 *      To avoid precision problem in FP16:
 *
 *      The numerical range of the input data is [-50, 50].
 *      Use the radian measure instead of the degree.
 *
 *      Unlimited in FP32
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCosOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* cos operation end */

/* softsign operation start */
/*!
 *  @brief cnmlCreateSoftsignOp.
 *
 *  Create an softsign activation operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, input and output Tensors, and pass
 *  them to the function to create a softsign activation operator.
 *
 *  output[i, j, k, l] = input[i, j, k, l] / (1 + fabs(input[i, j, k, l])
 *
 *  Shapes of the input and output must be the same.
 *
 *  Deprecated.
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @param[in] output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input tensor type is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSoftsignOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input,
                                               cnmlTensor_t output);

/*!
 *  @brief cnmlComputeSoftsignOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSoftsignOpForward_V4 is recommended to use.
 *
 *  Compute the user-specified Softsign operator on the MLU.
 *
 *  After creating Softsign operator, input, output and computation queue,
 *  introduce them to the function to compute the Softsign operator.
 *
 *  Deprecated.
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] computue_forw_param
 *    Input. A pointer pointing to the struct address,
 *    which records the degree of data parallelism and device affinity of runtime .
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftsignOpForward_V3(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeSoftsignOpForward_V4.
 *
 *  Compute the user-specified Softsign operator on the MLU.
 *
 *  After creating Softsign operator, input, output and computation queue,
 *  introduce them to the function to compute the Softsign operator.
 *
 *  Deprecated.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftsignOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* softsign operation end */

/* erf operation start */
/*!
 *  @brief A function.
 *
 *  Create a Gaussian error operator according to the basic operator pointer given by the user.
 *  The output dimension is same as the input dimension, and the output element is the Gaussian
 *  error function value corresponding to the input element.
 *
 *  The numerical range of input data is [-2Ï€, 2Ï€]. Use the radian measure instead of the degree
 *  measure.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output.  A pointer to the base operator address.
 *  @param[in] input_tensor
 *    Input.  A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *    supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input.  A 4-dimensional MLU input tensor, of which the shape is [no, co, ho, wo],
 *    supports data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *   (At least one of) the following conditions are not satisfied:
 *    - Op is empty.
 *    - Input_tensor is empty.
 *    - Output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateErfOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input_tensor,
                                          cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified Gaussian error operator on the MLU.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeErfOpForward_V4 is recommended to use.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output.  An MLU address that points to the output position.
 *  @param[in] op
 *    Input.  A pointer to the base operator.
 *  @param[in] input
 *    Input.  An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the address of the struct, in which the data parallelism
 *    and device affinity at runtime are recorded.
 *  @param[in] queue
 *    Input.  A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input parameter operator pointer op is empty.
 *    - Input parameter tensor pointer input is empty.
 *    - Output parameter tensor pointer output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeErfOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified Gaussian error operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeErfOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* erf operation end */

/* threshold operation start */

/*!
 *  @brief cnmlCreateThrsOp.
 *
 *  Create a threshold operator according to the base operator pointer given by the user. The output
 *  dimension is the same as the input dimension. Each input element is compared with the
 *  threatshold. If the input element is greater than the threshold, the corresponding output
 *  element is 1; if the input element is less than the threshold,
 *  the corresponding output element is 0.
 *
 *  **Formula**
 *
 *  y = (x > threshold) ? 1 : 0
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      in_type-in_oc_type-out_oc_type-out_type
 *
 *      float16-float16   -float16    -float16
 *
 *      float32-float32   -float32    -float32
 *
 *  **Scale Limitation**
 *
 *   Unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] threshold
 *    Input. A constant of float16 or float32 type
 *  @param[in] input_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 and float32 type.
 *  @param[in] output_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 and float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is empty.
 *    - input_tensor is empty.
 *    - output_tensor is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateThrsOp(cnmlBaseOp_t *op,
                                           float threshold,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeThrsOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeThrsOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified threshold operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 * affinity
 *    at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation stream pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Input parameter operator pointer op is empty.
 *    - Input parameter tensor pointer input is empty.
 *    - Output parameter tensor pointer output is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeThrsOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeThrsOpForward_V4.
 *
 *  It is used to compute the user-specified threshold operator on the MLU.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeThrsOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* threshold operation end */

/* elu operation start */
/*!
 *  @brief cnmlCreateEluOp.
 *
 *  Create an elu activation operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, elu activation operator operation
 *  parameters, input and output Tensors, pass them to the function to create a elu activation
 *  operator.
 *
 *  Before creating the elu activation operator, declare a pointer to the address of the elu
 *  activation operator operation structure structure and pass it to the function together
 *  with the required operator parameters to set the operator parameters.
 *
 *  output[i, j, k, l] = ( input[i, j, k, l] < 0 ) ? alpha * ( exp( input[i, j, k, l] ) â€“ 1 ) :
 *  input[i, j, k, l]
 *
 *  alpha: const float type, the value being 1
 *
 *  Shapes of the input and output should be consistent.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @param[in] output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The input pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateEluOp(cnmlBaseOp_t *op,
                                          cnmlTensor_t input,
                                          cnmlTensor_t output);

/*!
 *  @brief cnmlComputeEluOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeEluOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified elu activation function operator on the MLU.
 *
 *  After creating the elu activation function operator, Input, Output, runtime parameters, and
 *  computation queue, pass them to the function to It is used to compute the elu activation
 *  function operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 */
CNML_DLL_API cnmlStatus_t cnmlComputeEluOpForward_V3(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeEluOpForward_V4.
 *
 *  It is used to compute the user-specified elu activation function operator on the MLU.
 *
 *  After creating the elu activation function operator, Input, Output, runtime parameters, and
 *  computation queue, pass them to the function to It is used to compute the elu activation
 *  function operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeEluOpForward_V4(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* elu operation end */

/* selu operation start */

/*!
 *  @brief cnmlCreateSeluOp.
 *
 *  Create a selu activation operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, selu activation operator parameters,
 *  input and output Tensors, and pass them to the function to create a selu activation operator.
 *
 *  Before creating the selu activation operator, declare a pointer to the address of the elu
 *  activation operator operation struct and pass it to the function together with the required
 *  operator parameters to set the operator parameters.
 *
 *  output[i, j, k, l] = ( input[i, j, k, l] < 0 ) ? lambda * alpha *
 *  ( exp( input[i, j, k, l] ) â€“ 1 ) : lambda * input[i, j, k, l]
 *
 *  alpha: const float type, the value being 1.6732632423543772848170429916717
 *
 *  lambda: const float type, the value being 1.0507009873554804934193349852946
 *
 *  Shapes of the input and output should be consistent.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @param[in] output
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [batch, channel, height, width]
 *    and only supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The input pointer is empty.
 *    - The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSeluOp(cnmlBaseOp_t *op,
                                           cnmlTensor_t input,
                                           cnmlTensor_t output);

/*!
 *  @brief cnmlComputeSeluOpForward_V3.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSeluOpForward_V4 is recommended to use.
 *
 *  It is used to compute the user-specified selu activation function operator on the MLU.
 *
 *  After creating the selu activation function operator, Input, Output, runtime parameters,
 *  computation queue, pass them to the function to It is used to compute the selu activation
 *  function operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address that points to the output location.
 *  @param[in] op
 *    Input. A pointer to the base operator.
 *  @param[in] input
 *    Input. An MLU address that points to the input data.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the address of the struct, in which the data parallelism and device
 *    affinity at runtime are recorded.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSeluOpForward_V3(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeSeluOpForward_V4.
 *
 *  It is used to compute the user-specified selu activation function operator on the MLU.
 *
 *  After creating the selu activation function operator, Input, Output, runtime parameters,
 *  computation queue, pass them to the function to It is used to compute the selu activation
 *  function operator.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSeluOpForward_V4(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* selu operation end */

/* AsStride operation start */

/*!
 *  @brief cnmlCreateAsStrideOp.
 *
 *  DataType:
 *
 *    MLU270: float16, float32
 *
 *  Creates an AsStride operator that resizes the channel dimension.
 *
 *  Before creating an AsStride operator, you need to declare a pointer pointing to the AsStride
 *  operator you will create later.
 *
 *  The shapes of the input and output tensor should be consistent.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the AsStride operator you have created.
 *  @param[in] input
 *    Input. A 4-D MLU input tensor. The shape of the tensor is [batch, channel, height, width]
 *    The data type of this tensor descriptor must be float16. You need to declare a tensor using
 *    the cnmlTensor_t datatype and create the tensor using the cnmlCreateTensor API.
 *  @param[in] output
 *    Input. The descriptor of the 4-D MLU tensor. The shape of the tensor is [batch, channel,
 *    height, width]. The data type of this tensor descriptor must be float16. You need to declare
 *    a tensor using the cnmlTensor_t datatype and create the tensor using the cnmlCreateTensor API.
 *  @param[in] k_value
 *    Input. The size of the output channel. k_value is equal to the output channel size. Supported
 *    values are integers from 1 to 60,000.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The operator pointer is NULL
 *    - The input pointer is NULL.
 *    - The output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateAsStrideOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input,
                                               cnmlTensor_t output,
                                               int k_value);

/*!
 *  @brief cnmlComputeAsStrideOpForward_V3.
 *
 *  Resizes the channel dimension on MLU.
 *
 *  The cnmlComputeAsStrideOpForward_V2 API is not recommended to use and will be deprecated in
 *  a future release. We recommend you use cnmlComputeAsStrideOpForward_V3 API instead.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. A pointer to output data after the AsStride operator is applied.
 *  @param[in] op
 *    Input. A pointer to the AsStride operator you have created.
 *  @param[in] input
 *    Input. A pointer to the input data you want to compute.
 *  @param[in] compute_forw_param
 *    Input. A pointer to the struct address that records the data parallelism
 *    and device affinity for runtime.
 *  @param[in] queue
 *    Input. A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *     This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAsStrideOpForward_V3(cnmlBaseOp_t op,
                                                          void *input,
                                                          void *output,
                                                          cnrtInvokeFuncParam_t *compute_forw_param,
                                                          cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeAsStrideOpForward_V4.
 *
 *  It is used to compute the user-specified selu activation function operator on the MLU.
 *
 *  After creating the selu activation function operator, Input, Output, runtime parameters,
 *  computation queue, pass them to the function to It is used to compute the selu activation
 *  function operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeAsStrideOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* AsStride operation end */

/* log2 operation start */
/*!
 *  @brief A function.
 *
 *  Creates a logarithmic operator with base 2.
 *
 *  The shapes of input and output tensor should be the same.
 *
 *  **Formula**
 *
 *    output[n c h w] = log2(input[n c h w])
 *
 *  **DataType**
 *
 *    MLU270: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270: unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the logarithm operator you have created.
 *  @param[in] input_tensor
 *    Input. A 1 to N dimension input tensor. The data type of this
 *    tensor descriptor must be float16 or float32. You need to declare
 *    a tensor using the cnmlTensor_t datatype and create the tensor using
 *    the cnmlCreateTensor API.
 *  @param[in] output_tensor
 *    Input. The descriptor of the 1 to N dimensional output tensor. The
 *    data type of this tensor descriptor must be float16 or float32.
 *    You need to declare a tensor using the cnmlTensor_t datatype and
 *    create the tensor using the cnmlCreateTensor API.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of the output tensor is different from the shape of the
 *    input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateLog2Op(cnmlBaseOp_t *op,
                                           cnmlTensor_t input_tensor,
                                           cnmlTensor_t output_tensor);
/*!
 *  @brief A function.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeLog2OpForward_V2 is recommended to use.
 *
 *  Computes the logarithmic operator with base 2 on MLU.
 *
 *  **Formula**
 *
 *    output[n c h w] = log2(input[n c h w])
 *
 *  **DataType**
 *
 *    MLU270: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270: unlimited
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] output
 *    Output. A pointer to output data after the logarithmic operator is applied.
 *  @param[in] op
 *    Input. A pointer to the logarithmic operator you have created.
 *  @param[in] input
 *    Input. A pointer to the input data you want to compute.
 *  @param[in] computue_forw_param
 *    Input. A pointer to the struct address that records the data parallelism
 *    and device affinity for runtime.
 *  @param[in] queue
 *    Input.A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.
 *  @retval CNML_STATUS_INVALIDARG
 *    The runtime task type is invalid.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLog2OpForward(cnmlBaseOp_t op,
                                                   void *input,
                                                   void *output,
                                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                                   cnrtQueue_t queue);
/*!
 *  @brief A function.
 *
 *  Compute the user-specified exponent operator with the base being 2.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeLog2OpForward_V2(cnmlBaseOp_t op,
                                                      cnmlTensor_t input_tensor,
                                                      void *input,
                                                      cnmlTensor_t output_tensor,
                                                      void *output,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* log2 operation end */

/* square operation start */
/*!
 *  @brief cnmlCreateSquareOp.
 *
 *  Creates a square operator that performs element-wise square.
 *
 *  Perform element-wise square on one input to obtain output.
 *
 *  The formula is as follows:
 *
 *  output[n, c, h, w] = input[n, c, h, w] ^ 2
 *
 *  The shapes of the input and output should be the same.
 *  The datatype of the input and output should be the same.
 *  Before creating the square operator, declare a pointer pointing to the struct
 *  address of the operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w]) ^ 2
 *
 *  **DataType**
 *
 *    input_dt = output_dt
 *
 *    float16, float32
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the square operator you created.
 *  @param[in] input_tensor
 *    Input. A 4-D MLU input tensor. The shape of the tensor is [ni, hi, wi, ci].
 *    The data type of this tensor descriptor must be float16 or float32. You
 *    need to declare a tensor using the cnmlTensor_t datatype and create the
 *    tensor using the cnmlCreateTensor API.
 *  @param[in] output_tensor
 *    Input. The descriptor of the 4-D MLU output tensor. The shape of the tensor is
 *    [no, ho, wo, co] (no = ni, co = ci, ho = hi, wi = wo). The data type of
 *    this tensor descriptor must be float16 or float32 type.You need to declare
 *    a tensor using the cnmlTensor_t datatype and create the tensor using the
 *    cnmlCreateTensor API.
 *  @retval CNML_STATUS_SUCCESS
 *    The function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The operator pointer is NULL.
 *    - The input pointer is NULL.
 *    - The output tensor is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSquareOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief cnmlComputeSquareOpForward.
 *
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeSquareOpForward_V2 is recommended to use.
 *
 *  Computes the square operation on the MLU.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w]) ^ 2
 *
 *  **DataType**
 *
 *    input_dt = output_dt
 *
 *    float16, float32
 *
 *  **Scale Limitation**
 *
 *    Unlimited
 *
 *  **Only supports MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer to the square operator you have created.
 *  @param[in] input
 *    Input. A pointer to the input data you want to compute.
 *  @param[out] output
 *    Output. A pointer to output data after the square operator is applied.
 *  @param[in] compute_forw_param
 *    Input.  A pointer to the struct address that records the data parallelism
 *    and device affinity for runtime.
 *  @param[in] queue
 *    Input. A pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    One of the following conditions are met:
 *    - The operator pointer is NULL.
 *    - The output pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSquareOpForward(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);

/*!
 *  @brief cnmlComputeSquareOpForward_V2.
 *
 *  Computes the square operation on the MLU.
 *
 *  **Only supports MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSquareOpForward_V2(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnrtQueue_t queue,
                                                        void *extra);

/* square operation end */

/* maximum operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a maximum operator.
 *
 *  A maximum operator is selet the bigger one from the two input tensors at same
 *  position and write it at the same position in output tensors.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] inputTensorA
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] inputTensorB
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMaximumOp(cnmlBaseOp_t *op,
                                              const cnmlTensor_t inputTensorA,
                                              const cnmlTensor_t inputTensorB,
                                              const cnmlTensor_t outputTensor);

/*!
 *  @brief A function.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMaximumOpForward_V2 is recommended to use.
 *
 *  Compute the maximum operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. An pointer which points to base operators.
 *  @param[in] inputTensor1,inputTensor2
 *    Input. An MLU address pointing to input data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaximumOpForward(cnmlBaseOp_t op,
                                                      void *inputTensor1,
                                                      void *inputTensor2,
                                                      void *outputTensor,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the maximum operator given by users on the MLU.
 *
 *  After creating a maixmum operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute the division operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaximumOpForward_V2(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);

/* maximum operation end */

/* minimum operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a minimum operator.
 *
 *  A minimum operator is selet the bigger one from the two input tensors at same
 *  position and write it at the same position in output tensors.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] inputTensorA
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] inputTensorB
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMinimumOp(cnmlBaseOp_t *op,
                                              const cnmlTensor_t inputTensorA,
                                              const cnmlTensor_t inputTensorB,
                                              const cnmlTensor_t outputTensor);

/*!
 *  @brief A function.
 *
 *  Compute the minimum operator.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMinimumOpForward_V2 is recommended to use.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. An pointer which points to base operators.
 *  @param[in] inputTensor1,inputTensor2
 *    Input. An MLU address pointing to input data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinimumOpForward(cnmlBaseOp_t op,
                                                      void *inputTensor1,
                                                      void *inputTensor2,
                                                      void *outputTensor,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *  Compute the minimum operator given by users on the MLU.
 *
 *  After creating a minimum operator, input, output, runtime parameters, and computation queue,
 *  pass them into the function to compute the division operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinimumOpForward_V2(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor1,
                                                         void *input_1,
                                                         cnmlTensor_t input_tensor2,
                                                         void *input_2,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* minimum operation end */

/* broadcast args operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a broadcast args operator.
 *
 *  A broadcast args operator is given two one-dimension tensors that represent shapes, compute the
 *  broadcasted
 *  shape, output tensor is also one-dimension.
 *
 *  It's just the same as max equal in one-dimension and support different input size.
 *
 *  **Formula**
 *
 *    output[index] = input1[index] >= input2[index] ? input1[index] : input2[index]
 *
 *    if size of input1 larger than input2, compute max equal in same index(from high to low), the
 *    remain position in output just the same as input1, and vice versa.
 *
 *    for example:
 *
 *      input1 data shape: {2}, input2 data shape: {4}, output data shape: {4}
 *
 *      input1 data: [12, 1]
 *
 *      input2 data: [1, 14, 1, 9]
 *
 *      output data: [1, 14, 12, 9]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      int16, int32
 *
 *    MLU220:
 *
 *      int16, int32
 *
 *  **Scale Limitation**
 *
 *    Only supports one-dimension tensor, and input size should follow limitation below.
 *
 *    MLU270:
 *
 *      int32: input1 size < 32768, input2 size < 32768
 *
 *      int16: input1 size < 65536, input2 size < 65536
 *
 *    MLU220:
 *
 *      int32: input1 size < 32768, input2 size < 32768
 *
 *      int16: input1 size < 65536, input2 size < 65536
 *
 *  **Performance Optimization**
 *
 *    The number of bytes in the C dimension is a multiple of 128
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] inputTensorA
 *    Input. A one-dimensional MLU input tensor, supporting data of int16/int32 type.
 *  @param[in] inputTensorB
 *    Input. A one-dimensional MLU input tensor, supporting data of int16/int32 type.
 *  @param[in] output_tensor
 *    Input. A one-dimensional MLU output tensor, shape of which equals to max shape between input1
 * and input2, supporting data of int16/int32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBroadcastArgsOp(cnmlBaseOp_t *op,
                                                    const cnmlTensor_t inputTensorA,
                                                    const cnmlTensor_t inputTensorB,
                                                    const cnmlTensor_t outputTensor);

/*!
 *  @brief A function.
 *
 *  Compute the broadcast args operator given by users on the MLU.
 *
 *  After creating a broadcast args operator, input, output, runtime parameters, and computation
 *  queue, pass them into the function to compute the division operator.
 *
 *  **Supports MLU270 and MLU220.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input_2
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBroadcastArgsOpForward(cnmlBaseOp_t op,
                                                            cnmlTensor_t input_tensor1,
                                                            void *input_1,
                                                            cnmlTensor_t input_tensor2,
                                                            void *input_2,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/* broadcast args operation end */

/* embedding operation start */
/*!
 *  @brief cnmlCreateEmbeddingOp.
 *
 *  Create a embedding operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer pointing to the base operator address, input, output and weight tensor
 *  of the embedding operator, pass them to the function to create the embedding operator.
 *
 *  **Formula**
 *
 *    This operator maps integer indices to vector representations
 *
 *    1. weight is a two dimension array, can be regarded as a dict in python.
 *
 *    2. input is a 1 to n-dimension array which stores a series of keys,
 *       this means the range of value in input must be [0, weight_shape[0]).
 *
 *    3. output is also a 1 to n-dimension array store those series of values which input corrspond
 *       in that dict(weight).
 *
 *    4. output_shape = input_shape + weight_shape[1:]
 *
 *       for example, input_shape = (1, 2), weight_shape = (4, 5), output_shape = (1, 2, 5)
 *
 *    5. for example, input = [1, 0, 0], weight = [[0, 1], [2, 3]], then
 *       output = [[2, 3], [0, 1], [0, 1]]
 *
 *  **DataType**
 *
 *    The datatype of input must be int32.
 *
 *    The datatype of weight and output should be exactly the same, such as fp32 or fp16.
 *
 *  **Scale limitation**
 *
 *    1. if using multi-dimension tensor api, then input's shape and output's shape can be
 *       multi-dimension, but weight's shape must be two dimension.
 *
 *       if not using multi-dimension tensor api, then input's shape and weight's shape must be two
 *       dimension and output's shape must be three dimension.
 *
 *    2. input_shape[0] * input_shape[1] * ... input_shape[input_shape.size() - 1] + weight_shape[1]
 *       <= 63000
 *
 *  **Supports MLU270/MLU220**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A 1 to n-dimensional MLU input tensor, supporting data of int32 type.
 *  @param[in] output_tensor
 *    Input. A 1 to n-dimensional MLU output tensor, supporting data of float16 or float32 type.
 *  @param[in] weight_tensor
 *    Input. A 1 to n-dimensional MLU weight tensor, only support two dimension,
 *    supporting data of float16 or float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null
 *    - The input pointer is null
 *    - The output tensor is null
 *    - The weight tensor is null
 */
CNML_DLL_API cnmlStatus_t cnmlCreateEmbeddingOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t weight_tensor);
/*!
 *  @brief cnmlComputeEmbeddingOpForward.
 *
 *  Compute the embedding operator on the MLU.
 *
 *  After creating the embedding operator, input, output, runtime parameters,
 *  computation queue, pass them to the function to It is used to compute the embedding operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. An MLU address which points to input data.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *           and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeEmbeddingOpForward(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);
/*!
 *  @brief cnmlComputeEmbeddingOpForward_V2.
 *
 *  Compute the embedding operator on the MLU.
 *
 *  After creating the embedding operator, input_tensor, input,output_tensor, output, and
 *  computation queue, pass them to the function to compute the embedding operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeEmbeddingOpForward_V2(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *  @brief cnmlComputeEmbeddingOpTrainingForward.
 *
 *  After creating the embedding operator, input_tensor, input, output_tensor, output,
 *  weight_tensor, weight and computation queue, pass them to the function to compute
 *  the embedding operator on the MLU.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] weight_tensor
 *    Input. Weight MLU tensor pointer. Pass NULL if not used.
 *  @param[in] weight
 *    Input. An MLU address pointing to weight data.
 *  @param[in] output_tensor
 *    Input. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeEmbeddingOpTrainingForward(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t weight_tensor,
                                                                void *weight,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);

/* embedding operation end */

/* minimum operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a minimum operator.
 *
 *  A minimum operator is selet the bigger one from the two input tensors at same
 *  position and write it at the same position in output tensors.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] inputTensorA
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] inputTensorB
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] output_tensor
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMinimumOp(cnmlBaseOp_t *op,
                                              const cnmlTensor_t inputTensorA,
                                              const cnmlTensor_t inputTensorB,
                                              const cnmlTensor_t outputTensor);

/*!
 *  @brief A function.
 *
 *  Compute the minimum operator.
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] op
 *    Input. An pointer which points to base operators.
 *  @param[in] inputTensor1,inputTensor2
 *    Input. An MLU address pointing to input data.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMinimumOpForward(cnmlBaseOp_t op,
                                                      void *inputTensor1,
                                                      void *inputTensor2,
                                                      void *outputTensor,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);

/* minimum operation end */

/* frozen_batch_norm operation start */
/*!
 *  @brief A function.
 *
 *  Create a FrozenBatchNorm operator according to base operator pointers given by users.
 *
 *  A FrozenBatchNorm operator that freezes the scaling parameters in batch normalization.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] -mean[1 c 1 1])* rsqrt(var[1 c 1 1]) * filter[1 c 1 1] +
 *                      scale[1 c 1 1]
 *
 *      inputDataType float16, float32
 *
 *      outputDataType float16, float32
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] filter
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] bias
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] mean
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] var
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] output
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVAILDPA
 *    - The operator pointer is null.
 *    - The input pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateFrozenBatchNormOp(cnmlBaseOp_t *op,
                                                      cnmlTensor_t input,
                                                      cnmlTensor_t filter,
                                                      cnmlTensor_t bias,
                                                      cnmlTensor_t mean,
                                                      cnmlTensor_t var,
                                                      cnmlTensor_t output);

/*!
 *  @brief A function.
 *  Freezes the scaling parameters in batch normalization on the MLU.
 *
 *  @param[out] output
 *    Output. Pointer to the data after the FrozenBatchNorm operator is applied.
 *    the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] op
 *    Input. Pointer to the FrozenBatchNorm operator you have created.
 *  @param[in] input
 *    Input. The shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float16 or float32.
 *  @param[in] compute_forw_param
 *    Input. Pointer to the struct that records the data parallelism
 *  and device affinity for runtime.
 *  @param[in] queue
 *    Input. Pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input pointer is NULL.
 */

CNML_DLL_API cnmlStatus_t
cnmlComputeFrozenBatchNormOpForward(cnmlBaseOp_t op,
                                    void *input,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);

/* frozen_batch_norm operation end */
/* group_norm operation start */
/*!
 *  @brief A function.
 *
 *  Create a GroupNorm operator according to base operator pointers given by users.
 *
 *  **Formula**
 *
 *   input transfer groupnum inputtemps. And the shape of inputtemps is[ni, hi, wi, ci / groupnum].
 *
 *   output_temps[n, h1, w, c] = 1 / sigma * (inputtemps[n, h1, w, c] - mean)
 *
 *   output_temps[n, h2, w, c] = 1 / sigma * (inputtemps[n, h2, w, c] - mean)
 *
 *   ...
 *
 *	 Output[n, sum(h1, h2, ..., hh), w, c] = [output_temps([n, h1, w, c], [n, h2, w, c], ...,
 *   [n, hn, w,c])]*gamma + beta
 *
 *  **Supports only MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float32.
 *  @param[in] groupnum
 *    Input. The ci  must be divisible by groupnum.
 *  @param[in] gamma
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float32.
 *  @param[in] beta
 *    Input. A four-dimensional MLU input tensor, the shape is [1, 1, 1, ci],
 *    The data type of this tensor descriptor must be float32.
 *  @param[in] output
 *    Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float32.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVAILDPA
 *    - The operator pointer is null.
 *    - The input pointer is null.
 */
cnmlStatus_t cnmlCreateGroupNormOp(cnmlBaseOp_t *op,
                                   int groupnum,
                                   cnmlTensor_t input,
                                   cnmlTensor_t gamma,
                                   cnmlTensor_t beta,
                                   cnmlTensor_t output);
/*!
 *  @brief A function.
 *
 *  @param[out] output
 *    Output. Pointer to the data after the GroupNorm operator is applied.
 *    the shape is [no, ho, wo, co],
 *    the shape of output is the same as that of input.
 *    The data type of this tensor descriptor must be float32.
 *  @param[in] op
 *    Input. Pointer to the GroupNorm operator you have created.
 *  @param[in] input_tensor
 *   Input. A four-dimensional MLU input tensor, the shape of which is [ni,hi,wi,ci].
 *  @param[in] input
 *    Input. The shape is [ni, hi, wi, ci],
 *    The data type of this tensor descriptor must be float32.
 *  @param[in] output_tensor
 *   Input. A four-dimensional MLU output tensor, the shape of which is [no,ho,wo,co].
 *  @param[in] queue
 *    Input. Pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input pointer is NULL.
 */
cnmlStatus_t cnmlComputeGroupNormOpForward(cnmlBaseOp_t op,
                                           cnmlTensor_t input_tensor,
                                           void *input,
                                           cnmlTensor_t output_tensor,
                                           void *output,
                                           cnrtQueue_t queue,
                                           void *extra);
/* group_norm operation end */

/* frozen_batch_norm operation start */
/*!
 *  @brief A function.
 *
 *  Creates a FrozenBatchNorm operator that scales parameters after batch normalization.
 *
 *  **Only supports MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer to the FrozenBatchNorm operator you have created.
 *  @param[in] input
 *    Input. A 4-D MLU input tensor. The shape of the tensor is [n, c, h, w].
 *  @param[in] filter
 *    Input. A 4-D filter tensor. The shape of the tensor is [1, c, 1, 1].
 *  @param[in] bias
 *    Input. A 4-D bias tensor. The shape of the tensor is [1, c, 1, 1].
 *  @param[in] mean
 *    Input. A 4-D mean tensor of MLU. The shape of the tensor is [1, c, 1, 1].
 *  @param[in] var
 *    Input. A 4-D variance tensor of MLU. The shape of the tensor is [1, c, 1, 1].
 *  @retval CNML_STATUS_SUCCESS
 *    The function was success.
 *  @retval CNML_STATUS_INVAILDPA
 *    One of the following conditions are met:
 *    - The operator pointer is NULL.
 *    - The input pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFrozenBatchNormOp(cnmlBaseOp_t *op,
                                                      cnmlTensor_t input,
                                                      cnmlTensor_t filter,
                                                      cnmlTensor_t bias,
                                                      cnmlTensor_t mean,
                                                      cnmlTensor_t var,
                                                      cnmlTensor_t output);
/*!
 *  @brief A function.
 *
 *  Compute the Fused FrozenBatchNorm operator specified by users on the CPU.
 *
 *  Before calling this API, you need to create the CPU input tensor, CPU input address,
 *  CPU output tensor, and CPU output address.
 *
 *  **Formula**
 *
 *    output[n c h w] = (input[n c h w] - mean[1 c 1 1]) / srqt(var[1 c 1 1]) * filter[1 c 1 1] +
 *                      bias[1 c 1 1]
 *
 *  @param[out] output
 *    Output. Pointer to the data after the FrozenBatchNorm operator is applied.
 *  @param[in] compute_forw_param
 *    Input. Pointer to the struct that records the data parallelism
 *    and device affinity for runtime.
 *  @param[in] queue
 *    Input.  Pointer to the queue that is used to implement the computation.
 *  @retval CNML_STATUS_SUCCESS
 *    This function run successfully.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    The input pointer is NULL.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeFrozenBatchNormOpForward(cnmlBaseOp_t op,
                                    void *input,
                                    void *output,
                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                    cnrtQueue_t queue);

/*!
 *  @brief A function.
 *
 *
 *  Scales parameters after batch normalization on MLU.
 *
 *  **Only supports MLU270.**
 *
 *  Before call this API, you need to create a FrozenBatchNorm operator, input, output,
 *  and computation queue.
 *
 *  **Note: the inputs and output must meet the options set in cnmlCreateFrozenBatchNormOp.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. Pointer to the data of the tensor you want to compute.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. Pointer to the data after the FrozenBatchNorm operator is applied.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeFrozenBatchNormOpForward_V2(cnmlBaseOp_t op,
                                                                 cnmlTensor_t input_tensor,
                                                                 void *input,
                                                                 cnmlTensor_t output_tensor,
                                                                 void *output,
                                                                 cnrtQueue_t queue,
                                                                 void *extra);

/* frozen_batch_norm operation end */
////////////////////////////////// offline API ///////////////////////////////
/*!
 *  @struct cnmlModel
 *  @brief A struct.
 *
 *  cnmlModel is a structure describing offline model, used to generate and use offline model.
 *  cnmlCreateModel() is used to create an instance of cnmlModel_t. cnmlDestroyModel() is used to
 *  destroy an instance of cnmlModel_t. */
struct cnmlModel;
/*! ``cnmlModel_t`` is a pointer to ``cnmlModel`` which is a
    structure holding the description of a offline model. */
typedef struct cnmlModel *cnmlModel_t;

/*!
 *  @brief A function.
 *
 *  This function creates an offline model.
 *
 *  @param[in] model
 *    Input. A pointer pointing to an offline model.
 *  @param[in] name
 *    Input. Name of the offline model.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateModel(cnmlModel_t *model, const char *name);

/*!
 *  @brief A function.
 *
 *  This function destroys an offline model.
 *
 *  @param[in] model
 *    Input. A pointer pointing to an offline model.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyModel(cnmlModel_t model);

/*!
 *  @brief A function.
 *
 *  Add a compiled base operator to the model.
 *
 *  @param[in] model
 *    Input. A pointer pointing to the model.
 *  @param[in] op
 *    Input. A pointer pointing to base operator.
 *  @param[in] symbol
 *    Input. The name of this add operation (for future reference).
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlAddBaseOpToModel(cnmlModel_t model,
                                               cnmlBaseOp_t op,
                                               const char *symbol);

/*!
 *  @brief A function.
 *
 *  Add a compiled fusion operator to the model.
 *
 *  @param[in] model
 *    Input. A pointer pointing to the model.
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @param[in] symbol
 *    Input. The name of this add operation (for future reference).
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlAddFusionOpToModel(cnmlModel_t model,
                                                 cnmlFusionOp_t op,
                                                 const char *symbol);

/*!
 *  @brief A function.
 *
 *  Save the current model locally.
 *
 *  @param[in] model
 *    Input. A pointer pointing to the current model.
 *  @param[in] fname
 *    Input. The name of the local file.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlSaveModel(cnmlModel_t model, const char *fname);

/*!
 *  @brief A function.
 *
 *  Get the size of storage space needed to save the current model.
 *
 *  @param[out] size
 *    Output. The size of storage space needed to save the current model.
 *  @param[in] model
 *    Input. A pointer pointing to the current model.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
CNML_DLL_API cnmlStatus_t cnmlGetModelSize(cnmlModel_t model, uint64_t *size);

/*!
 *  @brief A function.
 *
 *  Extract Function (a data object of CNRT) from compiled base operators.
 *
 *  @param[out] function
 *    Output. The function extracted from base operator
 *  @param[in] op
 *    Input. A pointer pointing to base operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
cnmlStatus_t cnmlExtractFunctionFromOp(cnmlBaseOp_t op, cnrtFunction_t function);

/*!
 *  @brief A function.
 *
 *  Extract Function (a data object of CNRT) from compiled fusion operators.
 *
 *  @param[out] function
 *    Output. The function extracted from fusion operator
 *  @param[in] op
 *    Input. A pointer pointing to fusion operator.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
cnmlStatus_t cnmlExtractFunctionFromFusionOp(cnmlFusionOp_t op, cnrtFunction_t function);

/*!
 *  @brief A function.
 *
 *  Save the model in a specified space.
 *
 *  @param[out] size
 *    Output. The actual size of the current model.
 *  @param[in] model
 *    Input. A pointer pointing to the model
 *  @param[in] ptr
 *    Input. A pointer pointing to storage space.
 *  @param[in] len
 *    Input. Size of storage space.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */

CNML_DLL_API cnmlStatus_t cnmlSaveModelToMem(cnmlModel_t model,
                                             void *ptr,
                                             uint64_t len,
                                             uint64_t *size);

////////////////////////////////// test tools ///////////////////////////////

/*!
 *  @brief A function.
 *
 *  Get position and scale by datatype
 *
 *  @param[in] buffer
 *    Input. Header pointer of data array.
 *  @param[in] size
 *    Input. Array length
 *  @param[in] dataType
 *    Input. quantized dataType INT8/INT16
 *  @param[out] position
 *    Output. pointer of quantized position.
 *  @param[out] scale
 *    Output. pointer of quantized scale
 */
CNML_DLL_API cnmlStatus_t getPositionScaleByDataType(float *buffer,
                                                     int size,
                                                     int *position,
                                                     float *scale,
                                                     cnmlDataType_t dataType);

/*!
 *  @brief A function.
 *
 *  Find out the computation result difference between MLU and CPU.
 *
 *  @param[in] mlu_res
 *    Input. The name of the file that stores the computation result of the MLU.
 *  @param[in] cpu_res
 *    Input. The name of the file that stores the computation result of the CPU.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    Unable to open the file of MLU or CPU computation results.
 *  @retval CNML_STATUS_OUTOFRANGE
 *    The number of CPU and MLU results is inconsistent.
 *  @retval CNML_STATUS_OVERFLOWERR
 *    MLU results overflow, illegal.
 *  @retval CNML_STATUS_SUCCESS
 *    The function returns normally.
 */
cnmlStatus_t cnmlDiffFiles(const char *mlu_res, const char *cpu_res);

/* MaskZero operation start  */
// set param start
/*!
 *  @struct cnmlMaskZeroOpParam
 *  @brief A struct.
 *
 *  cnmlMaskZeroOpParam is a structure describing the param parameter of computing datatype
 *  on device, using to specify the data type when Tensor participates in the computation on
 *  the chip. cnmlCreateMaskZeroOpParam() is used to create an instance of
 *  cnmlMsakZeroLayerParam_t.
 *  cnmlDestroyMaskZeroOpParam() is used to destroy an instance of cnmlMaskZeroLayerParam_t.
 */
struct cnmlMaskZeroOpParam;
/*!
 * ``cnmlMaskZeroLayerParam_t`` is a pointer to the structure ``cnmlMaskZeroOpParam`` that descibes
 * MaskZero operation parameters.
 */
typedef struct cnmlMaskZeroOpParam *cnmlMaskZeroLayerParam_t;

CNML_DLL_API cnmlStatus_t cnmlCreateMaskZeroOp(cnmlBaseOp_t *op,
                                               cnmlMaskZeroLayerParam_t param,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t label_tensor,
                                               cnmlTensor_t output_tensor);

/*!
 * @brief cnmlCreateMaskZeroOpParam.
 *
 * According to the pointer given by the user, the function creates the parameters required by
 * MaskZero operator.
 * @param[in] param
 *   Output. A pointer pointing to the address of the parameter of the MaskZero operator.
 * @param[in] pad_label
 *   Input. It should be an float32 value
 * @param[in] slope
 *   Input. It should be an float32 value.
 * @param[in] fuse_relu
 *   Input. It should be an bool value
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *   - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMaskZeroOpParam(cnmlMaskZeroLayerParam_t *param,
                                                    float pad_label,
                                                    float slope,
                                                    bool fuse_relu);
/*!
 *  @brief A function.
 *
 *  This function is used to destroy an instance of cnmlMaskZeroLayerParam_t.
 *
 *  @param[in] param
 *    Input. A pointer instance pointing to the cnmlMaskZeroParam.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer instance of cnmlQuantizedParam is null.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyMaskZeroOpParam(cnmlMaskZeroLayerParam_t *param);
/* set param end */
/*!
 *  @brief cnmlComputeMaskZeroOpForward.
 *
 *  Deprecated. This interface will be deleted in next version and
 *  cnmlComputeMaskZeroOpForward_V4 is recommended to use.
 *
 *  Compute the MaskZero operator given by users on the MLU.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input
 *    Input. A 4-D tensor, supporting data of float16/float32 type.
 *  @param[in] label
 *    Input. A 4-D tensor, supporting data of float16/float32 type.
 *  @param[out] output
 *    output. A 4-D tensor, supporting data pf float16/float32 type
 *  @param[in] compute_forw_param
 *    Input. A pointer pointing to the struct address, which records the degree of data parallelism
 *  and device affinity of runtime.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaskZeroOpForward(cnmlBaseOp_t op,
                                                       void *input,
                                                       void *label,
                                                       void *output,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);

/*!
 *  @brief cnmlComputeMaskZeroOpForward_V4.
 *
 *  Compute the MaskZero operator given by users on the MLU.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. A 4-D tensor, supporting data of float16/float32 type.
 *  @param[in] label_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] label
 *    Input. A 4-D tensor, supporting data of float16/float32 type.
 *  @param[out] output_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    output. A 4-D tensor, supporting data pf float16/float32 type
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 *
 */
CNML_DLL_API cnmlStatus_t cnmlComputeMaskZeroOpForward_V4(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t label_tensor,
                                                          void *label,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* MaskZero operation end  */

/* random_uniform operation start */
/*! cnmlRngType_t is an enumeration type to describe underlying algorithm to pseudo random number.
 */
typedef enum {
  CNML_RNG_MT19937 = 0,
} cnmlRngType_t;
/*!
 *  @struct cnmlRandomUniformOpParam
 *  @brief A struct.
 *
 *  cnmlRandomUniformOpParam is a structure describing the param parameter of random_uniform
 *  operation, used to create random_uniform operation. cnmlCreateRandomUniformOpParam() is used
 *  to create an instance of cnmlRandomUniformOpParam_t. cnmlDestroyRandomUniformOpParam() is used
 *  to destroy an instance of cnmlRandomUniformOpParam_t.
 */
struct cnmlRandomUniformOpParam;
/*! ``cnmlRandomUniformOpParam_t`` is a pointer to ``cnmlRandomUniformOpParam`` which is a
                structure holding the description of a Conv operation param. */
typedef struct cnmlRandomUniformOpParam *cnmlRandomUniformOpParam_t;
/*!
 *	@brief A function
 *
 *	This function fills cnmlRandomUniformOpParam_t struct with random_uinform operation
 *  parameters giver by user.
 *
 *	This function allocates param memory, and after usage is done, user needs to call
 *  ``cnmlDestroyRandomUniformOpParam`` to destroy this param instance.
 *
 *	**Supports MLU270.**
 *
 *  @param[out] param
 *    Output. A pointer pointing to the address of the struct of random_uinform operation.
 *  @param[in] type
 *    Input. An enumerate type to describe underlying algorithm used to generate pseudorandom
 *    number.
 *  @param[in] seed
 *    Input. Seed used to initialize seed value in algorithm.
 *  @param[in] min_val
 *    Input. A value represents the left bound of distribution range.
 *  @param[in] max_val
 *    Input. A value represents the right bound of distribution range. max_val should be greater
 *    than min val, and the distribution range is [min_val, max_val).
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateRandomUniformOpParam(cnmlRandomUniformOpParam_t *param,
                                                         cnmlRngType_t type,
                                                         float min_val,
                                                         float max_val);
/*!
 *	@brief A function.
 *
 *  Free the struct pointer of random_uniform operator operation parameter according to the
 *  pointer given by the user.
 *
 *  At the end of the random_uniform operator operation, the struct pointer of the random_uniform
 *  operator operation parameter is freed.
 *
 *	**Supports both MLU220 and MLU270.**
 *
 *  @param[in] param
 *    Input. A pointer pointing to the address of the struct of the random_uniform operation
 *    parameter.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - param is a null pointer.
 *    - The content of the pointer pointed to by param has been freed.

 */
CNML_DLL_API cnmlStatus_t cnmlDestroyRandomUniformOpParam(cnmlRandomUniformOpParam_t *param);
/*!
 *  @brief A function
 *
 *  According to the base operator pointer given by the user, create an random_uniform number
 *  generator operator.
 *
 *  After creating a pointer to the base operator address, the random_uinform param and output
 *  tensor are created, they are introduced into the function to create the random_uinform
 *  operator.
 *
 *  **Formla**
 *
 *    for each float value z in output_tensor:
 *
 *    1. x = rng.get_rand_uint32()
 *
 *    2. man = x & 0x7FFFFFF
 *
 *    3. exp = static_cast<unsigned int>(127)
 *
 *    4. val = (exp << 23) | man;
 *
 *    5. memcpy(&z, &val, sizeof(float32))
 *
 *  **DataType**
 *
 *    output_tensor: float32
 *
 *  **Scale Limitation**
 *
 *    output_tensor[n c h w]: n > 0, c > 0, h > 0, w > 0
 *
 *	**Supports MLU270.**
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] param
 *		Input. A random_uniform param structure to describe op's attribution.
 *	@param[in] output_tensor
 *		Input. A 1 to n-dimensional MLU tensor, only support float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason3 The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateRandomUniformOp(cnmlBaseOp_t *op,
                                                    cnmlRandomUniformOpParam_t param,
                                                    cnmlTensor_t output_tensor);

/*!
 *  @brief A function
 *
 *  For setting random seed to random number generator operation.
 *  Default seed value is 1 if no cnmlSetRandSeed is called.
 *
 *	**Support MLU270.**
 *
 *  @param[out] output
 *    Output. A pointer pointing to base operator address
 *  @param[in] seed
 *    Input. random seed
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 Seed function is not compatible with underlying prng type.
 */
CNML_DLL_API cnmlStatus_t cnmlSetRandomSeed(cnmlBaseOp_t op, unsigned int seed);

/*!
 *  @brief A function.
 *
 *  For computing the user-specified random_uniform operator on the MLU.
 *
 *	**Supports MLU270.**
 *
 *  @param[in] op
 *    Input. An pointer which points to base operator.
 *  @param[in] output_tensor
 *    Input. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input. Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeRandomUniformOpForward(cnmlBaseOp_t op,
                                                            cnmlTensor_t output_tensor,
                                                            void *output,
                                                            cnrtQueue_t queue,
                                                            void *extra);

/* random_uniform operation end */

/*for training begin*/
/*! Specific mode of poolbp operator in CNML.Enumeration cnmlPoolBackwardMode_t has 4 enumerated
 * values,
 *	each of which represent a kind of poolbp mode. User can pass in it according to their actual
 *	needs when they create the poolbp operator. */
typedef enum {
  CNML_POOLBP = 0,
  /*!< poolbp mode */
  CNML_ROWWISE_POOLBP = 1,
  /*!< rowwise poolbp mode */
  CNML_MAX_POOLBP = 2,
  /*!< maxpoolbp mode */
  CNML_AVG_POOLBP = 3,
  /*!< avgpoolbp mode */
} cnmlPoolBackwardMode_t;

//! @brief An enum.
/*! It is an enumerated type passed to ``cnmlCreatePoolBackwardParam`` to select
 *	poolbackward strategy method to be used by ``cnmlCreatePoolBackwardOp``, which may
 *	cause different output size. */
typedef enum {
  CNML_POOL_BACKWARD_KSAME = 0,
  /*!< The window can be out of bounds. */
  CNML_POOL_BACKWARD_KVALID = 1,
  /*!< The window must be within the bounds. */
} cnmlPoolBackwardStrategyMode_t;

//! @brief An enum.
/*! In which dimension of layernormgrad operator is processed in CNML.Enumeration
 * cnmlLayerNormAxis_t has 4
 *	enumerated values, indicating the dimension in which LayerNorm operator is processed. User
 *can
 * pass
 *	in it according to their actual needs when they create the LayerNorm operator. */
typedef enum {
  CNML_LAYERNORM_AXIS_NCHW,
  /*!< LayernormGrad input data in dimension NCHW and output */
  CNML_LAYERNORM_AXIS_CHW,
  /*!< LayerNormGrad input data in dimension CHW and output */
  CNML_LAYERNORM_AXIS_HW,
  /*!< LayerNormGrad input data in dimension HW and output */
  CNML_LAYERNORM_AXIS_W,
  /*!< LayerNormGrad input data in dimension W and output */
} cnmlLayerNormGradAxis_t;

//! @brief An enum.
/*! In which different mode of divbp operator is calculated in CNML.Enumeration
 *	cnmlDivBpMode_t has 3 enumerated values, indicating the mode in which divbp
 *	operator is calculated. User can pass in it according to their actual needs
 *	when they create the divbp operator. */
typedef enum {
  CNML_DIVBP_NUMERATOR = 0,
  /*!< Compute the derivation of numerator: dy/dx */
  CNML_DIVBP_DENOMINATOR,
  /*!< Compute the derivation of denominator: dy/do */
  CNML_DIVBP_BOTH
  /*!< Compute the derivation of numerator and denominator */
} cnmlDivBpMode_t;
/*! Mode of ClipGradients methods in CNML. Enumeration cnmlSolverClipGradsMode_t has 2 enumerated
 * values,
 * each of which represents a type of Clip Gradients method supported by our SolverOp.
 * */
typedef enum {
  CNML_SOLVER_CLIPGRADS_NO = 0,
  /*!< Not clip grads */
  CNML_SOLVER_CLIPGRADS_BYVALUE = 1,
  /*!< Clip gradients by threshold value */
} cnmlSolverClipGradsMode_t;

//! @brief An enum.
/*! Mode of Regularization methods in CNML. Enumeration cnmlSolverRegularizeMode_t has 3 enumerated
 * values,
 * each of which represents a type of regularization method supported by our SolverOp.
 * */
typedef enum {
  CNML_SOLVER_REGULARIZATION_NO = 0,
  /*!< Not regularize */
  CNML_SOLVER_REGULARIZATION_L2 = 1,
  /*!< L2 regularization */
  CNML_SOLVER_REGULARIZATION_L1 = 2,
  /*!< L1 regularization */
} cnmlSolverRegularizeMode_t;

/*!
 * ``cnmlReductionMode_t`` is an enum type indicating the reduction modes in NllLoss and
 * NllLossBackward operations.
 */
typedef enum {
  CNML_REDUCTIONMODE_NONE = 0,
  CNML_REDUCTIONMODE_MEAN,
  CNML_REDUCTIONMODE_SUM,
} cnmlReductionMode_t;

//! @brief An enum.
/*! In which reduction of mselossbp operator is calculated in CNML.Enumeration cnmlMselossbpReu_t
 * has 3
 *	enumerated values, indicating the dimension in which mselossbp operator is calculated. User
 *can
 *	pass in it according to their actual needs when they create the mselossbp operator. */
typedef enum {
  CNML_MSELOSSBP_REU_NONE = 0,
  /*!< Compute mselossbp with reduction none */
  CNML_MSELOSSBP_REU_MEAN = 1,
  /*!< Compute mselossbp with reduction none */
  CNML_MSELOSSBP_REU_SUM = 2,
  /*!< Compute mselossbp with reduction none */
} cnmlMselossbpReu_t;

/* quantify operation start */

/**
 *	@brief cnmlGetPosition.
 *	Get position of output Tensors.
 *	@param[out] pos
 *		Output. A pointer to the position
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetPosition(cnmlTensor_t cnml_tensor, void *cnml_ptr, int *pos);

/**
 *	@brief cnmlGetScale.
 *	Get scale of output Tensors.
 *	@param[out] scale
 *		Output. A pointer to the scale
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetScale(cnmlTensor_t cnml_tensor, void *cnml_prt, float *scale);

/**
 *	@brief cnmlGetOffset.
 *	Get offset of output Tensors.
 *	@param[out] offset
 *		Output. A pointer to the offset
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetOffset(cnmlTensor_t cnml_tensor, void *cnml_ptr, float *offset);

/**
 *	@brief cnmlGetMovingPosition.
 *	Get moving position of output Tensors.
 *	@param[out] pos
 *		Output. A pointer to the moving position
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetMovingPosition(cnmlTensor_t cnml_tensor, void *cnml_ptr, int *pos);

/**
 *	@brief cnmlGetBitWidth.
 *	Get bit width of output Tensors.
 *	@param[out] bit_width
 *		Output. A pointer to the bit width.
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetBitWidth(cnmlTensor_t cnml_tensor, void *cnml_ptr, int *bit_width);

/**
 *	@brief cnmlGetInterval.
 *	Get interval of output Tensors.
 *	@param[out] interval
 *		Output. A pointer to the interval
 *	@param[in] cnml_tensor
 *		Output. A pointer to the mlu end Tensor
 *	@param[in] cnml_ptr
 *		Input. A pointer to the mlu end addr
 */
CNML_DLL_API cnmlStatus_t cnmlGetInterval(cnmlTensor_t cnml_tensor, void *cnml_ptr, int *interval);

/*!
 *  @brief cnmlCreateQuantifyOp.
 *
 *  Create a quantify operator based on the base operator pointer given by the user.
 *
 *  After creating a pointer to the base operator address, quantify operator parameters, input and
 *  output Tensors, pass them to the function to create an quantify operator.
 *
 *  @param[out] output_tensor
 * 	 Output. A pointer to the mlu end Tensor
 *  @param[out] output_param_tensor
 * 	 Output. A pointer to the mlu end Tensor
 *  @param[out] output_mp_tensor
 * 	 Output. A pointer to the mlu end Tensor
 *  @param[in] op
 * 	 Input. A pointer to the base operator
 *  @param[in] input_tensor
 * 	 Input. A pointer to the mlu end
 *  @param[in] input_param_tensor
 * 	 Input. A pointer to the mlu end
 *  @param[in] input_mp_tensor
 * 	 Input. A pointer to the mlu end
 *  @param[in] interval
 * 	 Input. A pointer to the address of the quantify operator operation mode.
 *  @retval CNML_STATUS_SUCCESS
 * 	 The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 * 	 At least one of the following conditions are met:
 * 	 Op, input, output, and mode are not empty.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateQuantifyOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor,
                                               cnmlTensor_t input_param_tensor,
                                               cnmlTensor_t input_mp_tensor,
                                               cnmlTensor_t output_tensor,
                                               cnmlTensor_t output_param_tensor,
                                               cnmlTensor_t output_mp_tensor,
                                               cnmlTensor_t interval);

/*!
 *	@brief cnmlComputeQuantifyOpForward.
 *
 *	It is used to compute the user-specified quantify operator on the MLU.
 *
 *	After creating the quantify operator, Input, Output, map subscript, computation task type,
 *	computation queue, pass them to the function to It is used to compute the quantify operator.
 *
 *	@param[in] op
 *		Input. A pointer to the base operator.
 *	@param[in] input_tensor
 *		Input. Input MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input
 *		Input. An MLU address that points to the input data.
 *	@param[in] input_param_tensor
 *		Input. Input param MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_param
 *		Input. An MLU address that points to the input param data.
 *	@param[in] input_mp_tensor
 *		Input. Input mp MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_mp
 *		Input. An MLU address that points to the input moving position data.
 *  @param[in] interval_tensor
 *		Input. Interval MLU tensor pointer. Pass NULL if not used.
 *	@param[in] interval
 *		Input. An MLU address that points to the interval data.
 *  @param[out] output_tensor
 *		Output. Output MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output
 *		Output. An MLU address that points to the output location.
 *  @param[out] output_param_tensor
 *		Output. Output Param MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output_param
 *		Output. An MLU address that points to the output param location.
 *  @param[out] output_mp_tensor
 *		Output. Output Mp MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output_mp
 *		Output. An MLU address that points to the output moving position location.
 *      parallelism
 *	    and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is empty.
 *		- The output pointer is empty.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeQuantifyOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t input_param_tensor,
                                                       void *input_param,
                                                       cnmlTensor_t input_mp_tensor,
                                                       void *input_mp,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnmlTensor_t output_param_tensor,
                                                       void *output_param,
                                                       cnmlTensor_t output_mp_tensor,
                                                       void *output_mp,
                                                       cnmlTensor_t interval_tensor,
                                                       void *interval,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* quantify operation end */

/* tile begin*/
/*!
 *	@brief cnmlCreateTileOp.
 *
 *	Create a tile operator based on the base operator pointer given by the user. The output
 *	dimension is equal to input dimension multiply by multiplier.
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] input_tensor
 *		Input. A 1-D or more MLU input tensor, of which the shape is [ni, hi, wi,ci],
 *supporting
 *		data of float32 type.
 *	@param[in] output_tensor
 *		Input. A 1-D or more MLU output tensor, of which the shape is [no, ho, wo, co],
 *supporting
 *		data of float32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- op is empty.
 *		- input_tensor is empty.
 *		- output_tensor is empty.
 */

cnmlStatus_t cnmlCreateTileOp(cnmlBaseOp_t *op,
                              const cnmlTensor_t input_tensor,
                              const cnmlTensor_t output_tensor);

/*!
 *	@brief cnmlComputeTileOpForward.
 *
 *	Compute the Tile operator given by users on the MLU.
 *
 *	After creating Tile operator, input, output, runtime parameters, and computation
 * queue, pass them into the function to compute Tile operator.
 *
 *	@param[out] output
 * 	 Output. An MLU address pointing to output position.
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *      @param[in] input_tensor
 *              Input. input tensor, Pass null if not used.
 *	@param[in] input
 *		Input. An MLU address which points to input data.
 *      @param[in] output_tensor
                Output. output tensor, Pass null if not used.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *      @param[in] extra
 *              Input. Reserved for funture use. Pass null if not used.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The output pointer is null.
 */
cnmlStatus_t cnmlComputeTileOpForward(cnmlBaseOp_t op,
                                      cnmlTensor_t input_tensor,
                                      void *input,
                                      cnmlTensor_t output_tensor,
                                      void *output,
                                      cnrtQueue_t queue,
                                      void *extra);
/*!
 *  @brief A function.
 *
 *  Create a n-dimensional tile operator according to base operator pointers given by users,
 *  which is the extension of tile operator. It supports tensor from one to any dimension.
 *  We recommend you use this interface to create the broadcast operator.
 *
 *  @note
 *
 *  1. The shape of input cannot be 0.
 *
 *  2. Each dimension of the output shape is an integral multiple of the corresponding dimension of
 *  the input shape.
 *
 *  **Supports both MLU220 and MLU270.**
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] input_tensor
 *    Input. A one to any dimensional MLU tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Input. A one to any dimensional MLU tensor,  supporting data of float16 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The input pointer is null.
 *    - The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNdTileOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  Compute the extensional tile operator on the MLU.
 *
 *  After creating a NdTile operator, input, output, and computation stream, pass them into the
 *  function to compute the nd tile operator.
 *
 *  **Supports both MLU220 and MLU270.**

 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNdTileOpForward(cnmlBaseOp_t op,
                                                     cnmlTensor_t input_tensor,
                                                     void *input,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);

/* Tile end */

/* floor div operation start */
/*!
 *	@brief A function.
 *
 *	Create a division operator according to base operator pointers given by users. After
 *  creating a
 *	pointer pointing to base operator address, and input and output Tesor, pass them into the
 *	fucntion to create the division operator.
 *
 *	Before creating a division operator, declare a pointer pointing to the struct address of
 *	operation parameters of the division operator, and pass the pointer and operator parameters
 *	required into the function to set operator parameters.
 *
 *	Perform element-wise division on the two inputs to obtain output.
 *
 *	The divisor should be greater than zero, The shapes of the two inputs and one output should
 *  be
 *	exactly the same.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] input_tensor_1
 *		Input. A four-dimensional MLU input tensor, the shape of which is [ni, ci, hi, wi],
 *      supporting
 *	    data of float16 type.
 *	@param[in] input_tensor_2
 *		Input. A four-dimensional MLU output tensor, the shape of which is [ni, ci, hi, wi],
 *	supporting data of float16 type.
 *	@param[in] output_tensor
 *		Input. A four-dimensional MLU weight tensor, the shape of which is [no, co, ho, wo]
 *      (no = ni,
 *	    co = ci, ho = hi, wi = wo), supporting data of int16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFloorDivOp(cnmlBaseOp_t *op,
                                               cnmlTensor_t input_tensor_1,
                                               cnmlTensor_t input_tensor_2,
                                               cnmlTensor_t output_tensor);

/*!
 *	@brief A function.
 *
 *	Compute the division operator given by users on the MLU.
 *
 *	After creating a division operator, input, output, runtime parameters, and computation
 *  queue,
 *	pass them into the function to compute the division operator.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[out] output_tensor
 *		Output. Output MLU tensor pointer. Pass NULL if not used.
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] input_1_tensor
 *		Input. Input_2 MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_1
 *		Input. An MLU address which points to input data.
 *	@param[in] input_2_tensor
 *		Input. Input_2 MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_2
 *		Input. An MLU address which points to input data.
 *      parallelism
 *	    and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The operator pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeFloorDivOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_1_tensor,
                                                       void *input_1,
                                                       cnmlTensor_t input_2_tensor,
                                                       void *input_2,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);

/* real div operation end */

/* Invert Permutation operation start */
/*!
 *	@brief A function.
 *
 *	According to the base operator pointer given by the user, a invert permutation operator is
 *	created.
 *
 *	After a pointer pointing to the address of base operator, the operation parameter of invert
 *	permutation operator and input-output tensor are created, they are introduced into the
 *	function to create the invert permutation operator.

 *	The invert permutation computes the inverse permutation of a index tensor, which represents
 *  the
 *	indices of a zero-based array, and swaps each value with its index position.
 *	In other words, for an output tensor y and an input tensor x, this operation computes the
 *	following:
 *
 *	y[x[i]] = i for i in [0, 1, ..., len(x) - 1]
 *
 *	x[i] >=0, and must belong to [0, 1, 2, ..., len(x) - 1], can not be duplicate values or
 *  negative
 *	values.
 *
 *	ni == 1 && ci == len(x) && wi == 1 && hi == 1.
 *
 *	len(x) > 0 && shape(x) == shape(y).
 *
 *	@param[out] op
 *		Output. A pointer pointing to the address of the base operator.
 *	@param[in] input_tensor
 *		Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci], supporting
 *      integer
 *		data.
 *	@param[in] output_tensor
 *		Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co], supporting
 *      integer
 *		data.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Operator pointer is null.
 *		- Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateInvertPermutationOp(cnmlBaseOp_t *op,
                                                        cnmlTensor_t input_tensor,
                                                        cnmlTensor_t output_tensor);
/*!
 *	@brief A function.
 *
 *	Computing invert permutation operator run on MLU.
 *
 *  After the invert permutation operator, input, output, parameter at runtime, and
 *  computational queue are created, they are introduced into the function for operation.
 *
 *      @param[in] op
 *        Input. A pointer which points to base operators.
 *      @param[in] input_tensor
 *        Input. Input MLU tensor pointer. Pass NULL if not used.
 *      @param[in] input
 *        Input. MLU address pointing to input data.
 *      @param[in] output_tensor
 *        Input.  Output MLU tensor pointer. Pass NULL if not used.
 *      @param[out] output
 *        Output. An MLU address pointing to output position.
 *      @param[in] queue
 *        Input. A computation queue pointer.
 *      @param[in] extra
 *        Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *      @retval CNML_STATUS_SUCCESS
 *        The function ends normally.
 *      @retval CNML_STATUS_INVALIDPARAM
 *        At least one of the following conditions are met:
 *        - The operator pointer is null.
 *        - The output pointer is null.
 *        - The input pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeInvertPermutationOpForward(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnrtQueue_t queue,
                                                                void *extra);

/* Invert Permutation operation end */

/* fused_batch_norm operation start */
/*!
 *	@brief A function.
 *
 *	Create a FusedBatchNorm operator according to base operator pointers given by users.
 *
 *	After creating a pointer pointing to base operator address, and input and output Tensor,
 *  pass
 *	them into the fucntion to create a FuseBatchNorm operator.
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] input
 *		Input. A four-dimensional MLU input tensor, the shape of which is [n, c, h, w]
 *	@param[in] mom_mean
 *		Input. A four-dimensional MLU input tensor, the shape of which is [1, c, 1, 1]
 *		This param can be nullptr.
 *		if mom_mean is nullptr, the mom_mean_out should be nullptr.
 *	@param[in] mom_var
 *		Input. A four-dimensional MLU input tensor, the shape of which is [1, c, 1, 1]
 *		This param can be nullptr
 *		if mom_var is nullptr , the mom_var is nullptr too.
 *	@param[in] gamma
 *		Input. A four-dimensional mean value tensor of MLU, the shape of which is [1, c, 1,
 *1],
 *		This param can be nullprt. if gamma is null, the beta and output are both null.
 *	@param[in] beta
 *		Input. A four-dimensional variance tensor of MLU, the shape of which is [1, c, 1, 1]
 *	@param[in] eps
 *		Input. A four-dimensional variance tensor of MLU, the shape of which is [1, c, 1, 1]
 *	@param[in] output
 *		Input. A four-dimensional MLU output tensor, the shape of which is [n, c, h, w]
 *	@param[in] mean
 *		Input. A four-dimensional MLU output tensor, the shape of which is [1, c, 1, 1]
 *		if you want the mean of mini-batch, create tensor for  mean, or set mean as nullptr.
 *	@param[in] var
 *		Input. A four-dimensional MLU output tensor, the shape of which is [1, c, 1, 1]
 *		same as mean
 *	@retval CNML_STATUS_INVAILDPARAM
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The eps value is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFusedBatchNormOp(cnmlBaseOp_t *op,
                                                     cnmlTensor_t input,
                                                     cnmlTensor_t mom_mean,
                                                     cnmlTensor_t mom_var,
                                                     cnmlTensor_t gamma,
                                                     cnmlTensor_t beta,
                                                     cnmlTensor_t eps,
                                                     float momentum,
                                                     cnmlTensor_t output,
                                                     cnmlTensor_t mom_mean_out,
                                                     cnmlTensor_t mom_var_out,
                                                     cnmlTensor_t mean,
                                                     cnmlTensor_t var,
                                                     cnmlTensor_t bn_out);
/*!
 *  @brief A function.
 *
 *  Create a FusedBatchNorm operator according to base operator pointers given by users.
 *
 *  After creating a pointer pointing to base operator address, and input and output Tensor,  pass
 *  them into the fucntion to create a FuseBatchNorm operator.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFusedBatchNormOp_V2(cnmlBaseOp_t *op,
                                                        cnmlTensor_t input,
                                                        cnmlTensor_t es_mean,
                                                        cnmlTensor_t es_var,
                                                        cnmlTensor_t gamma,
                                                        cnmlTensor_t beta,
                                                        cnmlTensor_t eps,
                                                        cnmlTensor_t output,
                                                        cnmlTensor_t batch_mean,
                                                        cnmlTensor_t batch_var,
                                                        cnmlTensor_t mean,
                                                        cnmlTensor_t var);

/*!
 *	@brief A function.
 *	Compute the FusedBatchNorm operator specified by users on the MLU.
 *
 *	After creating a FusedBatchNorm operator, input, output, and computation stream, pass them
 *into
 * the function to compute the FusedBatchNorm operator.
 * attention: the inputs and output must meet the options set in cnmlCreateFusedBatchNormOp
 *	@param[in] queue
 *		Input. A computational stream pointer.
 *		- The input pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeFusedBatchNormOpForward(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t mom_mean_tensor,
                                                             void *mom_mean,
                                                             cnmlTensor_t mom_var_tensor,
                                                             void *mom_var,
                                                             cnmlTensor_t gamma_tensor,
                                                             void *gamma,
                                                             cnmlTensor_t beta_tensor,
                                                             void *beta,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnmlTensor_t mom_mean_out_tensor,
                                                             void *mom_mean_out,
                                                             cnmlTensor_t mom_var_out_tensor,
                                                             void *mom_var_out,
                                                             cnmlTensor_t mean_tensor,
                                                             void *mean,
                                                             cnmlTensor_t var_tensor,
                                                             void *var,
                                                             cnmlTensor_t bn_out_tensor,
                                                             void *bn_out,
                                                             cnrtQueue_t queue,
                                                             void *extra);

/*!
 *  @brief A function.
 *  Compute the FusedBatchNorm operator specified by users on the MLU.
 *
 *  After creating a FusedBatchNorm operator, input, output, and computation stream, pass them into
 *  the function to compute the FusedBatchNorm operator.
 *  attention: the inputs and output must meet the options set in cnmlCreateFusedBatchNormOp
 *  @param[in] queue
 *    Input. A computational stream pointer.
 *    - The input pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeFusedBatchNormOpForward_V2(cnmlBaseOp_t op,
                                                                cnmlTensor_t input_tensor,
                                                                void *input,
                                                                cnmlTensor_t es_mean_tensor,
                                                                void *es_mean,
                                                                cnmlTensor_t es_var_tensor,
                                                                void *es_var,
                                                                cnmlTensor_t gamma_tensor,
                                                                void *gamma,
                                                                cnmlTensor_t beta_tensor,
                                                                void *beta,
                                                                cnmlTensor_t output_tensor,
                                                                void *output,
                                                                cnmlTensor_t batch_mean_tensor,
                                                                void *batch_mean,
                                                                cnmlTensor_t batch_var_tensor,
                                                                void *batch_var,
                                                                cnmlTensor_t mean_tensor,
                                                                void *mean,
                                                                cnmlTensor_t var_tensor,
                                                                void *var,
                                                                cnrtQueue_t queue,
                                                                void *extra);
/* fused_batch_norm operation end */

/* square operation start */

/*!
 *	@brief cnmlCreateSquareOp.
 *
 *	Create a square operator based on the base operator pointer given by the user.
 *
 *	After creating a pointer pointing to the base operator address,
 *	input and output tensor of the square operator,
 *	pass them to the function to create the square operator.
 *
 *	Before creating the square operator, declare a pointer pointing to the struct address of
 *  operation
 *
 *	Perform element-wise square on the one input to obtain output.
 *
 *	output[n, c, h, w] = input[n, c, h, w] ^ 2
 *
 *	The shapes of one input and one output should be exactly the same.
 *	The datatype of one input and one output should be exactly the same.
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] input_tensor
 *		Input. A four-dimensional MLU input tensor, the shape of which is [ni, hi, wi, ci],
 *supporting
 *	data of float16 or float32 type.
 *	@param[in] output_tensor
 *		Input. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo, co]
 *(no = ni,
 *	co = ci, ho = hi, wi = wo), supporting data of float16 or float32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null
 *		- The input pointer is null
 *		- The output tensor is null
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSquareOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input_tensor,
                                             cnmlTensor_t output_tensor);
/*!
 *	@brief cnmlComputeSquareOpForward.
 *
 *	Compute the square operator on the MLU.
 *
 *	After creating the square operator, Input, Output, runtime parameters,
 *	computation queue, pass them to the function to It is used to compute the square operator.
 *
 *	After creating the selu activation function operator, Input, Output, runtime parameters, and
 *	computation stream, pass them to the function to It is used to compute the selu activation
 *	function operator.
 *
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] input
 *		Input. An MLU address which points to input data.
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records the degree of data
 *parallelism
 *	and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeSquareOpForward(cnmlBaseOp_t op,
                                                     void *input,
                                                     void *output,
                                                     cnrtInvokeFuncParam_t *compute_forw_param,
                                                     cnrtQueue_t queue);

/* square operation end */

/* pool index operation start */
/*!
 *	@brief A function.
 *
 *	This function creates a pooling op object by allocating the memory
 *	needed to hold its opaque structure.
 *
 *	@param[out] op
 *		Output. The returning op descriptor.
 *	@param[in] param
 *		Input. Param of this pooling op.
 *	@param[in] input
 *		Input. Input cnml tensor of this pooling op.
 *	@param[in] output
 *		Input. Output cnml tensor of this pooling op.
 *	@param[in] index
 *		Input. Index cnml tensor of this pooling op.
 *	@retval CNML_STATUS_SUCCESS
 *		The object was set successfully.
 *	@retval CNML_STATUS_BADALLOC
 *		At least one of the following conditions are met:
 *		- Reason1 TODO.
 *		- Reason2 TODO.
 */
CNML_DLL_API cnmlStatus_t cnmlCreatePoolIndexOp(cnmlBaseOp_t *op,
                                                cnmlPoolOpParam_t param,
                                                cnmlTensor_t input_tensor,
                                                cnmlTensor_t output_tensor,
                                                cnmlTensor_t index_tensor);

/*!
 *	@brief A function.
 *	@brief cnmlComputePoolIndexOp.
 *
 *	This function pool index the input image by taking the
 *	max, average, etc. within regions.
 *	It is used to compute the poolindex operator on the MLU.
 *  After creating the poolindex operator, Input, Output, Index and computation stream, pass
 *  them to the function to compute the poolindex operator.
 *
 *  @param[in]  index
 *    Input. Addr of index.
 *  @param[in]  index_tensor
 *    Input. A 4-dimensional MLU index tensor, of which the shape is [ni, ci, hi, wi], supporting
 *  @param[in]  output
 *    Output. An MLU address that points to the output location.
 *  @param[in]  op
 *    Input. A pointer to the base operator.
 *  @param[in]  input
 *    Input. An MLU address pointing to the input data tensor.
 *  @param[in]  input_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi], supporting
 *    data of float16 or float32 type.
 *  @param[in]  output_tensor
 *    Input. A 4-dimensional MLU input tensor, of which the shape is [no, co, ho, wo], supporting
 *    data of float16 or float32 type.
 *  @param[in]  queue
 *    Input. A computation stream pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputePoolIndexOpForward(cnmlBaseOp_t op,
                                                        cnmlTensor_t input_tensor,
                                                        void *input,
                                                        cnmlTensor_t output_tensor,
                                                        void *output,
                                                        cnmlTensor_t index_tensor,
                                                        void *index,
                                                        cnrtQueue_t queue,
                                                        void *extra);

/* pool index operation end */

/* pack operation start*/
/*!
 *  **Description**
 *
 *	@brief A function.
 *
 *	According to the base operator pointer given by the user,
 *	create a pack operator.
 *
 *	Pack a list of rank-R tensors into one rank-(R+1) tensor.
 *	Packs the list of tensors in values into a tensor with rank one higher than each tensor in
 *  values,
 *	by packing them along the axis dimension. Given a list of length N of tensors of shape (A,
 *  B, C);
 *	if axis == 0 then the output tensor will have the shape (N, A, B, C).
 *	if axis == 1 then the output tensor will have the shape (A, N, B, C). Etc.
 *	pack just like stack, they have same result.
 *
 *  **Formula**
 *    - Input Tensor :
 *      in1, in2, in3 ... inN, shape[A, B, C, D]
 *    - Output Tensor :
 *      if axis == 0 : out, shape[N, A, B, C, D];
 *      if axis == 1 : out, shape[A, N, B, C, D];
 *      if axis == 2 : out, shape[A, B, N, C, D];
 *      Etc.
 *
 *  **DataType**
 *    - input : float16/32
 *    - output: float16/32
 *
 *  **Supports MLU220 and MLU270**
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] input_tensors
 *		Input. A	MLU input tensor array, the shape can be multi dimension ,
 *		supports data of float16 type.
 *	@param[in] output_tensor
 *		Input. A	MLU output tensor
 *	@param[in] input_num
 *		Input. The size of input tensor array,as well as the num of input tensors
 *	@param[in] axis
                        Input. The axis which you want to pack
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The shape of output tensor is different from that of input tensor.
 */

CNML_DLL_API cnmlStatus_t cnmlCreatePackOp(cnmlBaseOp_t *op,
                                           const cnmlTensor_t *inputTensors,
                                           int input_num,
                                           int axis,
                                           const cnmlTensor_t outputTensor);
/*!
 *	@brief A function.
 *
 *	Compute the pack operator.
 *
 *	@param[out] outputTensor
 *		Output. An MLU address pointing to output position.
 *	@param[in] op
 *		Input. An pointer which points to base operators.
 *	@param[in] inputTensors
 *		Input. An MLU address pointing to input data.
 *	@param[in] input_num
 *		Input. The num of inputTensors.
 *	@param[in] axis
 *		Input. The axis which you want to pack.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records
 *		the degree of data parallelism and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputePackOpForward(cnmlBaseOp_t op,
                                                   void *inputTensors[],
                                                   int input_num,
                                                   int axis,
                                                   void *outputTensor,
                                                   cnrtInvokeFuncParam_t *compute_forw_param,
                                                   cnrtQueue_t queue);
/*!
 *	@brief A function.
 *
 *	Compute the pack operator.
 *
 *	@param[out] outputTensor
 *		Output. An MLU address pointing to output position.
 *	@param[in] op
 *		Input. An pointer which points to base operators.
 *	@param[in] inputTensors
 *		Input. An MLU address pointing to input data.
 *	@param[in] input_num
 *		Input. The num of inputTensors.
 *	@param[in] axis
 *		Input. The axis which you want to pack.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records
 *		the degree of data parallelism and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputePackOpForward_V1(cnmlBaseOp_t op,
                                                      cnmlTensor_t inputCnmlTensors[],
                                                      void *inputTensors[],
                                                      int input_num,
                                                      int axis,
                                                      cnmlTensor_t outputCnmlTensor,
                                                      void *outputTensor,
                                                      cnrtQueue_t queue,
                                                      void *extra);
/* pack operation end*/
/* SoftmaxCeLogits operation */
/*!	@brief cnmlCreateSoftmaxCeLogitsOp.
 *
 *	Create a softmaxCrossEntoryWithLogits operator based on the base operator pointer given by
 *  the
 * user.
 *  NOTE: VERY IMPORTANT!
 *  when input is float16, input must less than 11.08; when reduce dim is C, N * H * W
 *  should less than 1000;
 *
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] input_tensor
 *		Input. A four-dimensional MLU input tensor, the shape of which is [ni, hi, wi, ci],
 *supporting data of float32 type.
 *  @param[in] label_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is [ni, hi, wi, ci],
 *supporting data of float32 type.
 *	@param[out] output_tensor
 *		Output. A four-dimensional MLU weight tensor, the shape of which is [no, ho, wo,
 *co],
 *	@param[out] d_logits_tensor
 *	  Output. A four-dimensional MLU weight tensor, the shape of which is [ni, hi, wi, ci],
 *	@param dim
 *		input point out normalize-dim of loss
 *	supporting data of float16 or float32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null
 *		- The input pointer is null
 *		- The output tensor is null
 */
CNML_DLL_API cnmlStatus_t cnmlCreateSoftmaxCeLogitsOp(cnmlBaseOp_t *op,
                                                      cnmlDimension_t dim,
                                                      cnmlTensor_t input,
                                                      cnmlTensor_t label,
                                                      cnmlTensor_t output,
                                                      cnmlTensor_t d_logits_tensor);
/*!
 *	@brief A function.
 *
 *	Compute the  softmaxCeLogits operator specified by users on the MLU.
 *
 *	After creating a Mult operator, x, label, y, runtime parameters,
 *	and computation queue, pass them into the function to compute the SoftmaxCeLogits operator.
 *
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[out] ouput_tensor
 *		Output. Output MLU tensor pointer. Pass NULL if not used.
 *	@param[out] d_logits
 *	  Output. An MLU address pointing to output position.
 *  @param[out] d_logits_tensor
 *    Output. d_logits MLU tensor pointer. Pass NULL if not used.
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] input_tensor
 *		Input. Input MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input
 *		Input. An MLU address pointing to input data.
 *	@param[in] label_tensor
 *		Input. label MLU tensor pointer. Pass NULL if not used.
 *	@param[in] label
 *		Input. An MLU address pointing to label data.
 *parallelism
 *	and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeSoftmaxCeLogitsOpForward(cnmlBaseOp_t op,
                                                              cnmlTensor_t input_tensor,
                                                              void *input,
                                                              cnmlTensor_t label_tensor,
                                                              void *label,
                                                              cnmlTensor_t output_tensor,
                                                              void *output,
                                                              cnmlTensor_t d_logits_tensor,
                                                              void *d_logits,
                                                              cnrtQueue_t queue,
                                                              void *extra);

/* SoftmaxCeLogits end*/

/* SoftmaxCeLogitsNd begin */

/*!	@brief cnmlCreateNdSoftmaxCeLogitsOp.
 *
 *	Create a softmaxCrossEntoryWithLogits operator based on the base operator pointer given by
 *  the user.
 *
 *  **Formula**
 *
 *   This operation combines logsoftmax and cross entropy.
 *   logsoftmax is an operation of taking logarithm of softmax results. Mathematicaly, softmax
 *   has K real vectors as inputs, and normalize them to a probability distribution with K
 *   probabilities. Its mathematical expression is as follows:
 *
 *   logsoftmax(Z)j = log(exp(zj) / sigma(exp(zk)))
 *
 *   where Z is input real vector, j and k is from 1 to K.
 *
 *   SoftmaxCeWithLogits indicates do a cross entropy after logsoftmax, expressed as:
 *
 *   SoftmaxCeWithLogits(p,q) = - sigma(pk * logsoftmax(qk))
 *
 *   where p is the expected output(label) and q is the real output. k is from 1 to K.
 *
 *   Example for this interface paramters:
 *
 *   if input = [1,2,3,4], label = [1,2,3,4], output = [1,2,1,4],logits = [1,2,3,4], then dim
 *   should be 2, which means third dimension of input array.
 *
 *   **DataType**:
 *
 *   MLU270/220:
 *
 *   -- input:  float16, float32
 *
 *   -- label:  float16, float32
 *
 *   -- output: float16, float32
 *
 *   -- logits: float16, float32
 *
 *   **Limitation**
 *
 *   This interface now supports 1D~4D input and output tensor. Tensors with dimsion higher than
 *   4 is not supported right now.
 *
 *   **Supports MLU270 and MLU220**
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] dim
 *		Input. Normalize-dim of loss.
 *	@param[in] input
 *		Input. MLU input tensor
 *      @param[in] label
 *             Input.  MLU label tensor
 *      @param[in] output
 *             Input.  MLU output tensor
 *      @param[in] d_logits
 *             Input.  MLU logits tensor
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null
 *		- The input pointer is null
 *		- The output tensor is null
 */
cnmlStatus_t cnmlCreateNdSoftmaxCeLogitsOp(cnmlBaseOp_t *op,
                                           int dim,
                                           cnmlTensor_t input,
                                           cnmlTensor_t label,
                                           cnmlTensor_t output,
                                           cnmlTensor_t d_logits);
/*!
 *	@brief cnmlComputeNdSoftmaxCeLogitsOpForward.
 *
 *	Compute the  softmaxCeLogitsNd operator specified by users on the MLU.
 *
 *	After creating a Mult operator, x, label, y, and computation queue,
 *  pass them into the function to compute the SoftmaxCeLogitsNd operator.
 *
 *  @param[in] op
 *          Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *          Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *          Input. An MLU address pointing to input data.
 *  @param[in] label_tensor
 *          Input. Label MLU tensor pointer. Pass NULL if not used.
 *  @param[in] label
 *          Input. An MLU address pointing to label data.
 *  @param[in] output_tensor
 *          Input. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[in] output
 *          Output. An MLU address pointing to output data.
 *  @param[in] d_logits_tensor
 *          Input. Logits MLU tensor pointer. Pass NULL if not used.
 *  @param[in] d_logits
 *          Output. An MLU address pointing to logits data.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *      @param[in] extra
 *              Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output pointer is null.
 */
cnmlStatus_t cnmlComputeNdSoftmaxCeLogitsOpForward(cnmlBaseOp_t op,
                                                   cnmlTensor_t input_tensor,
                                                   void *input,
                                                   cnmlTensor_t label_tensor,
                                                   void *label,
                                                   cnmlTensor_t output_tensor,
                                                   void *output,
                                                   cnmlTensor_t d_logits_tensor,
                                                   void *d_logits,
                                                   cnrtQueue_t queue,
                                                   void *extra);
/* SoftmaxCeLogitsNd End */

/* convbpfilter operation start */
/*!
 *  *  @brief A struct.
 *   *
 *    *  cnmlConvOpBackwardParam is a structure describing the param of convbpfilter operation, used
 *     *  to create convbpfilter operation.
 *      *  cnmlCreateConvOpBackwardParam() is used to create an instance of
 * cnmlConvOpBackwardParam_t.
 *       *  cnmlDestroyConvOpBackwardParam() is used to destroy an instance of
 * cnmlConvOpBackwardParam_t.
 *        */
struct cnmlConvOpBackwardParam;
/*!
 *  * ``cnmlConvOpBackwardParam_t`` is a pointer to the structure ``cnmlConvOpBackwardParam`` that
 *   * describes conv backward operation parameters.
 *    */
typedef struct cnmlConvOpBackwardParam *cnmlConvOpBackwardParam_t;
/* convbpfilter operation end */

/* dynamicstitch begin */

/*!
 *	@brief cnmlCreateDynamicStitchOp.
 *
 *	According to indice list's order, rearrange order of data list
 *
 *	Create a DynamicStitch operator based on the base operator pointer given by the user.
 *
 *  **Formula**
 *
 * indices[0] = 6
 *
 * indices[1] = [4, 1]
 *
 * indices[2] = [[5, 2], [0, 3]]
 *
 * data[0] = [61, 62]
 *
 * data[1] = [[41, 42], [11, 12]]
 *
 * data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
 *
 * output = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42], [51, 52], [61, 62]]
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input1: float16, float32
 *
 *      input2: uint32
 *
 *      output: float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      Unlimited
 *
 *  **Supports only for MLU270.**
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] indices
 *		Input. A tensor list, supporting data of int type.
 *	@param[in] data
 *		Input. A tensor list, supporting data of float32 or float16 type.
 *	@param[in] tensor_num_in_list
 *		Input. number of tensor in list[indice, data],which means tensor number in indices
 *must
 *		be euqal to tensor number in data.
 *	@param[out] output
 *		Output, outpur tensor, supporting data of float32 or float16 type.
 *	@retval CNML_STATUS_SUCCE
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- op is empty.
 *		- input_tensor is empty.
 *		- output_tensor is empty.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateDynamicStitchOp(cnmlBaseOp_t *op,
                                                    cnmlTensor_t *indices,
                                                    cnmlTensor_t *data,
                                                    int tensor_num_in_list,
                                                    cnmlTensor_t output);

/*!
 *	@brief cnmlComputeDynamicStitchOpForward.
 *
 *	Compute the dynamicstitch operator given by users on the MLU.
 *
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *  @param[in] indice_tensor
 *    Input. Indice MLU tensor pointer. Pass NULL if not used.
 *	@param[in] indices_list
 *		Input. A 1-D or more tensor list, supporting data of int type.
 *  @param[in] data_tensor
 *    Input. Data MLU tensor pointer. Pass NULL if not used.
 *	@param[in] data_list
 *		Input. A 1-D or more tensor list, supporting data of int type.
 *	@param[in] tensor_num_in_list
 *		Input. number of tensor in list[indicei_list, data_list],
                        which means tensor number in indices must be euqal to tensor number in
 data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Operator pointer is null.
 *		- Output pointer is null.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeDynamicStitchOpForward(cnmlBaseOp_t op,
                                                            cnmlTensor_t indice_tensor,
                                                            void **indice_list,
                                                            cnmlTensor_t data_tensor,
                                                            void **data_list,
                                                            int tensor_num_in_list,
                                                            cnmlTensor_t output_tensor,
                                                            void *outputTensor,
                                                            cnrtQueue_t queue,
                                                            void *extra);
/* dynamicstitch end */

/* scatter operation start */
/*!
 * @struct cnmlScatterOpParam
 * @brief A struct.
 *
 * cnmlScatterOpParam is a structure describing the parameters required by scatter.
 * cnmlCreateScatterOpParam() and cnmlDestroyScatterOpParam are used to create and
 * destroy an instance of cnmlScatterOpParam_t, respectively.
 */
struct cnmlScatterOpParam;
/*! ``cnmlScatterOpParam_t`` is a pointer to ``cnmlScatterOpParam``, which is a
 *	struct describing the parameters of the scatter operator.
 */
typedef struct cnmlScatterOpParam *cnmlScatterOpParam_t;

/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function creates the parameters required by
 * Scatter operator.
 * @param[out] param
 *	 Output. A pointer pointing to the address of the parameter of the Scatter operator.
 * @param[in] axis
 *	 Input. the specified dimension to be scattered. The value is chosen from
 *	 CNML_DIM_N, CNML_DIM_C, CNML_DIM_H, CNML_DIM_W.
 * @param[in] scatter_length
 *	 Input. the length of the output tensor on the chosen dimension axis.
 *	 It should be an uint32 value.
 * @retval CNML_STATUS_SUCCESS
 *	 The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *	 At least one of the following conditions are met:
 *	 - param is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterOpParam(cnmlScatterOpParam_t *param,
                                                   cnmlDimension_t axis,
                                                   int scatter_length);
/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function destroies the parameters of the
 *Scatter
 * operator.
 *
 * After the Scatter operator is finished, the created struct pointer of Scatter operator is
 *freed.
 * @param[in] param
 *	 Input. A pointer pointing to the address of the struct of Scatter operator parameters.
 * @retval CNML_STATUS_SUCCESS
 *	 The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *	 At least one of the following conditions are met:
 *	 - param is a null pointer.
 *	 - the pointer has been freed in advance.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyScatterOpParam(cnmlScatterOpParam_t *param);

/*!
 * @brief A function.
 *
 * The function creates a Scatter operator according to the base operator pointer given by users.
 * The scatter operator is the inverse of the gather operator.
 *
 * After creating a pointer pointing to the base operators, the functions pass the input tensor,
 * the index tensor, and the output Tensor	into the function to create the Scatter operator.
 *
 * Scatter an input tensor on a specified dimension according to the indices.
 * The shape of the output tensor on the scattered dimension will become "scatter_length", which
 *is
 * a value provided by users. Taking axis = CNML_DIM_N as an example, the output[indices[n], c, h,
 * w] += input[n, c, h, w].
 *
 * Note that the length of the input tensor on the chosen dimension should be equal to the length
 *of
 * indices, which can be expressed in the form of equation as: input_tensor.shape[axis] ==
 * len(indices) Note that the length of the output tensor on the chosen dimension should be
 *greater
 * or equal than the length of indices, which can be expressed in the form of equation as:
 * (scatter_length == output_tensor.shape[axis]) >= len(indices)
 *
 * @param[out] op
 *	 Output. A pointer pointing to the base operator address.
 * @param[in] input_tensor
 *	 Input. A four-dimensional input tensor, the shape of which is [ni, ci, hi, wi].
 *	 The datatype of the input can be float16.
 * @param[in] index Tensor
 *	 Input. A four-dimensional input tensor, the shape of which is
 *	 [n_index, c_index, h_index, w_index], only uint32 datatype is supported.
 * @param[in] param
 *	 Input. A struct param for the scatter operator, including axis and scatter_length.
 *	 The scatter_length should be uint32 type and the axis should be one of CNML_DIM_N,
 *	 CNML_DIM_C, CNML_DIM_H and CNML_DIM_W.
 *	 @retval CNML_STATUS_SUCCESS
 *		 The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input_tensor,
                                              cnmlTensor_t index_tensor,
                                              cnmlTensor_t output_tensor,
                                              cnmlScatterOpParam_t param);
/*!
 * @brief A function.
 *
 * Compute the Scatter operator specified by users on MLU.
 *
 * After creating a pointer pointing to the base operators, the Scatter operator input tensor,
 *index
 * tensor, and output Tensor, pass them into the function to create the Scatter operator.
 *
 * @param[out] output_tensor
 *   Output. An pointer pointing to the output_tensor.
 * @param[out] output
 *   Output. An MLU address pointing to the output data.
 * @param[in] input
 *   Input. An MLU address pointing to the input data.
 * @param[in] input_tensor
 *   Input. An pointer pointing to the input tensor.
 * @param[in] index
 *   Input. An MLU address pointing to the index data.
 * @param[in] index_tensor
 *   Input. An pointer pointing to the index tensor.
 * @param[in]  queue
 *   Input. A computation stream pointer.
 * @param[in] extra
 *   Input. A pointer pointing to the extra param.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *    - The operator pointer is empty
 *    - The output pointer is empty
 * @retval CNML_STATUS_INVALIDARG
 *   At least one of the following conditions are met:
 *    - The runtime task type is invalid
 * @retval CNML_STATUS_SUCCESS
 *	 The function ends normally.
 */
cnmlStatus_t cnmlComputeScatterOpForward(cnmlBaseOp_t op,
                                         cnmlTensor_t input_tensor,
                                         void *input,
                                         cnmlTensor_t index_tensor,
                                         void *index,
                                         cnmlTensor_t output_tensor,
                                         void *output,
                                         cnrtQueue_t queue,
                                         void *extra);
/* scatter operation end */

/* caxpby operation start */
/*!
 *	@brief cnmlCreateCaxpbyOp.
 *
 *	This function is used to create an operation of caxpby by a * X + b * Y.
 *
 *	@param[out] 	op
 *		Output. returns a pointer to the created base op
 *	@param[in]	input1
 *		Input. A 4-dimensional MLU tensor, having the dimension of [ni,hi,wi,ci], supporting
 *data of
 *		float16 type.
 *	@param[in]	input2
 *		Input. A 4-dimensional MLU tensor, having the dimension of [ni,hi,wi,ci], supporting
 *data of
 *		float16 type.
 *	@param[out]  output
 *		Output. A 4-dimensional MLU tensor, having the dimension of [no,ho,wo,co],
 *supporting
 *data of
 *		float16 type.
 *	@param[in]	alpha
 *		Input. A scalar, supporting data of float16 type.
 *	@param[in]	beta
 *		Input. A scalar, supporting data of float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		One of the following conditions is not satisfied:
 *		- Op is not empty
 *		- input1 is not empty
 *		- input2 is not empty
 *		- alpha is not empty
 *		- beta is not empty
 *		- output are not empty
 */

CNML_DLL_API cnmlStatus_t cnmlCreateCaxpbyOp(cnmlBaseOp_t *op,
                                             cnmlTensor_t input1_tensor,
                                             cnmlTensor_t input2_tensor,
                                             cnmlTensor_t output_tensor,
                                             float alpha,
                                             float beta);

/*!
 *  @brief cnmlComputeCaxpbyOpForward.
 *
 *  Compute the Caxpby operator given by users on the MLU.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input1_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input1
 *    Input. A 4-D tensor, supporting data of float16 type.
 *  @param[in] input2_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input2
 *    Input. A 4-D tensor, supporting data of float16 type.
 *  @param[in] output_tensor
 *    Output. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[in] output
 *    Output. A 4-D tensor, supporting data of float16 type.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Operator pointer is null.
 *    - Output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeCaxpbyOpForward(cnmlBaseOp_t op,
                                                     cnmlTensor_t input1_tensor,
                                                     void *input1,
                                                     cnmlTensor_t input2_tensor,
                                                     void *input2,
                                                     cnmlTensor_t output_tensor,
                                                     void *output,
                                                     cnrtQueue_t queue,
                                                     void *extra);
/* caxpby operation end */

/* NLL-loss operation start */
/*!
 *	@brief A function.
 *
 *	Create a NLL-loss forward operator according to base operator pointers given by users.
 *
 *	After creating a pointer pointing to base operator address, and input and output Tensor,
 *pass
 *	them into the fucntion to create a Nll-loss operator.
 *
 *	**Supports only MLU270.**
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] self
 *		Input. A four-dimensional MLU input tensor, the shape of which is [n, h, w, c],
 *supporting
 *	data of float16/32 type.
 *	@param[in] target
 *		Input. A four-dimensional MLU input tensor, the shape of which is [n, h, w, 1],
 *supporting
 *	data of int32 type.
 *	@param[in] weight
 *		Input. A four-dimensional MLU input tensor, the shape of which is [1, 1, 1, c],
 *supporting
 *	data of float16/32 type.
 *	@param[in] output
 *		Input. A four-dimensional MLU output tensor, the shape of which is [1, 1, 1, c] for
 *NONE mode,
 *	and [1, 1, 1, 1] for MEAN/SUM mode, supporting data of float16/32 type.
 *	@param[in] total_weight
 *		Input. A four-dimensional MLU output tensor, the shape of which is [1, 1, 1, 1],
 *supporting
 *	data of float16/32 type.
 *	@param[in] ignore_index
 *		Input. A int value.
 *	@param[in] reduction
 *		Input. A enum value, supporting NONE/MEAN/SUM.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateNlllossOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t self,
                                              cnmlTensor_t target,
                                              cnmlTensor_t weight,
                                              cnmlTensor_t output,
                                              cnmlTensor_t total_weight,
                                              int ignore_index,
                                              cnmlReductionMode_t reduction);

/*!
 *	@brief A function.
 *
 *	Compute the NLL-loss operator specified by users on the MLU.
 *
 *	After creating a NLL-loss operator, input, output, runtime parameters,
 *	and computation queue, pass them into the function to compute fused BatchNorm backward.
 *
 *	**Supports only MLU270.**
 *
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[out] total_weight
 *		Output. An MLU address pointing to output total_weight position.
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] self
 *		Input. An MLU address which points to input self data.
 *	@param[in] target
 *		Input. An MLU address which points to input target data.
 *	@param[in] weight
 *		Input. An MLU address which points to input weight data.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records the degree of data
 *parallelism
 *	and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output pointer is null.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeNlllossOpForward(cnmlBaseOp_t op,
                                                      void *self,
                                                      void *target,
                                                      void *weight,
                                                      void *output,
                                                      void *total_weight,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue);

/* floor_mod operation start*/
/*!
 *	@brief A function.
 *
 *	According to the base operator pointer given by the user,
 *	create a floormod operator. a floormod operator can compute the mod on float num.
 *	eg. floormod(3.8,1.2) = 0.2, floormod(3.9,1.4) = 1.1
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] inputTensorA
 *		Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *		supports data of float16 type.
 *	@param[in] inputTensorB
 *		Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *		Input. A four-dimensional MLU output tensor, the shape is [no, ho, wo, co],
 *		the shape of output is the same as that of input. supports data of float16 type.
 *	@param[out]  outputTensor
 *		Output. A 4-dimensional MLU tensor, having the dimension of [no,ho,wo,co],
 *supporting
 *data of
 *		float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The shape of output tensor is different from that of input tensor.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFloorModOp(cnmlBaseOp_t *op,
                                               const cnmlTensor_t inputTensorA,
                                               const cnmlTensor_t inputTensorB,
                                               const cnmlTensor_t outputTensor);
/*!
 *	@brief A function.
 *
 *	Compute the floormod operator.
 *
 *	@param[out] outputTensor
 *		Output. An MLU address pointing to output position.
 *	@param[in] op
 *		Input. An pointer which points to base operators.
 *	@param[in] inputTensor1,inputTensor2
 *		Input. An MLU address pointing to input data.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeFloorModOpForward(cnmlBaseOp_t op,
                                                       void *inputTensor1,
                                                       void *inputTensor2,
                                                       void *outputTensor,
                                                       cnrtInvokeFuncParam_t *compute_forw_param,
                                                       cnrtQueue_t queue);
/* floor_mod operation end*/

/* floor_mod_pro operation start*/
/*!
 *  **Description**
 *
 *	@brief A function.
 *
 *	According to the base operator pointer given by the user,
 *	create a floormodpro operator. a floormodpro operator can compute the mod
 *	on float num or int num.
 *
 *	**Formula**
 *
 *  ouput[n c h w] = floor_mod_pro(input1[n c h w], input2[1 1 1 1])
 *
 *	int x，y；
 *	int trunc_mod = x % y;
 *	output = x < 0 == y < 0 ? trunc_mod : (trunc_mod + y) % y；
 *	float x，y；
 *	float trunc_mod = std::fmod(x, y);
 *	output = (x < 0.f == y < 0.f) ? trunc_mod : std::fmod(trunc_mod + y, y);
 *	eg. floormodpro(5,2) = 1, floormod(5,-2) = 1
 *
 *	**DataType**
 *
 *  MLU270/MLU220
 *    - input: int16, in32, float16, float32
 *    - output: int16, in32, float16, float32
 *
 *  **Scale Limitation**
 *
 *  Unlimited.
 *
 *  **Supports MLU270/MLU220.**
 *
 *	@param[out] op
 *		Output. A pointer to the base operator address.
 *	@param[in] inputTensorA
 *		Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *		supports data of float16, float32, int16, int32 type.
 *	@param[in] inputTensorB
 *		Input. A four-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],
 *		supports data of float16, float32, int16, int32 type.
 *	@param[out]  outputTensor
 *		Output. A 4-dimensional MLU tensor, having the dimension of [no,ho,wo,co],
 *		the shape of output is the same as that of input. supports data of float16, float32,
 *    int16, int32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The input tensor type is either CNML_TENSOR or CNML_CONST.
 *		See CNML User Guide for more infomration about debugging.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFloorModProOp(cnmlBaseOp_t *op,
                                                  const cnmlTensor_t inputTensorA,
                                                  const cnmlTensor_t inputTensorB,
                                                  const cnmlTensor_t outputTensor);

/*!
 *  @brief A function.
 *
 *	Compute the floormod operator.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor1
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] inputTensor1
 *    Input. An MLU address pointing to input data.
 *  @param[in] input_tensor2
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] inputTensor2
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] outputTensor
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
cnmlStatus_t cnmlComputeFloorModProOpForward(cnmlBaseOp_t op,
                                             cnmlTensor_t input_tensor1,
                                             void *inputTensor1,
                                             cnmlTensor_t input_tensor2,
                                             void *inputTensor2,
                                             cnmlTensor_t output_tensor,
                                             void *outputTensor,
                                             cnrtQueue_t queue,
                                             void *extra);
/* floor_mod_pro operation end*/

/* LayerNorm operation start*/
/*!
 *	@brief A function.
 *
 *	Create a LayerNorm operator according to base operator pointers given by users.
 *
 *	After creating a pointer pointing to base operator address, and  input, beta, gamma, output,
 *	mean, variance, norm_out Tensor,	pass them into the fucntion to create a LayerNorm
 *operator.
 *
 * **Formula**
 *
 *		norm_out = 1 / sigma * (input - mean)
 *
 *	where mean = 1 / H * sum_{i=1}^{H} input_i
 *
 *	and sigma = sqrt{1 / H *sum_{i=1}^{H}(input_i - mean)^2}
 *
 *	where H is the number of hidden units (i.e. product of dimensions from 'axis' to the end.)
 *
 *	 output = gamma * norm_out + beta
 *
 * **DataType**
 *
 *	 float16, float32
 *
 * **Scale Limitation**
 *
 *   (1). axis == "batch" or axis == "feature"
 *      i. computing layout == nchw
 *         input tensor's c is 18869 at most
 *      ii. computing layout == nhwc
 *         input tensor's c is unlimited
 *   (2). axis == "hight" or axis == "width"
 *      i. core_limit == 1
 *         input tensor's c is 11328 at most
 *      ii. core_limit != 1
 *         input tensor's c is 8096 at most
 *
 * @param[out] op
 *		Output. A pointer pointing to base operators address.
 * @param[in] input
 *		Input. A four-dimensional MLU input tensor, the shape of which is [n, c, h, w],
 *supporting
 *	data of float16 or float32 type.
 * @param[in] beta
 *		Input. A four-dimensional MLU output tensor, and the size of dimensions of which the
 *shape is
 *	normalized must be 1. The size of other dimenisions is consistent with that of input Tensor,
 *	supporting data of float16 or float32 type.
 *		This param can be nullptr.
 *		If nullptr do not add beta to normalized result.
 * @param[in] gamma
 *		Input. A four-dimensional MLU output tensor, and the size of dimensions of which the
 *shape is
 *	normalized must be 1. The size of other dimenisions is consistent with that of input Tensor,
 *	supporting data of float16 or float32 type.
 *		This param can be nullptr.
 *		If nullptr do not mulitply gamma.
 * @param[in] axis
 *		Input. An enumeration variable, a dimension that users will reduce, supporting N, C,
 *H, and W.
 * @param[in] epsilon
 *		Input. epsilon very small, used to calc rsqrt(var + epsilon)
 * @param[in] output
 *		Input. A four-dimensional MLU output tensor, the shape of which is [n, c, h, w],
 *supporting
 *	data of float16 or float32 type.
 * @param[in] mean
 *		Input. A four-dimensional MLU output tensor, and the size of dimensions of which the
 *shape is
 *	normalized must be 1. The size of other dimenisions is consistent with that of input Tensor,
 *	supporting data of float16 or float32 type.
 *		This param can be nullptr.
 * @param[in] variance
 *		Input. A four-dimensional MLU output tensor, and the size of dimensions of which the
 *shape is
 *	normalized must be 1. The size of other dimenisions is consistent with that of input Tensor,
 *	supporting data of float16 or float32 type.
 *		This param can be nullptr.
 * @param[in] norm_out
 *		Input. A four-dimensional MLU output tensor, the shape of which is [n, c, h, w],
 *supporting
 *	data of float16 or float32 type.
 *		This param can be nullptr.
 * @retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *		- The operator pointer is null.
 *		- The input pointer is null.
 *		- The output pointer is null.
 */
cnmlStatus_t cnmlCreateLayerNormOp(cnmlBaseOp_t *op,
                                   cnmlTensor_t input,
                                   cnmlTensor_t beta,
                                   cnmlTensor_t gamma,
                                   cnmlDimension_t axis,
                                   float epsilon,
                                   cnmlTensor_t output,
                                   cnmlTensor_t mean,
                                   cnmlTensor_t variance,
                                   cnmlTensor_t norm_out);
/*!
 *
 *  It is used to compute the user-specified MLP operator on the MLU.
 *
 *  After creating the MLP operator, Input, Output, and computation queue, pass them to the
 *  function to It is used to compute the MLP operator.
 *
 * **Formula**
 *
 *		norm_out = 1 / sigma * (input - mean)
 *
 *	where mean = 1 / H * sum_{i=1}^{H} input_i
 *
 *	and sigma = sqrt{1 / H *sum_{i=1}^{H}(input_i - mean)^2}
 *
 *	where H is the number of hidden units (i.e. product of dimensions from 'axis' to the end.)
 *
 *	 output = gamma * norm_out + beta
 *
 * **DataType**
 *
 *	 float16, float32
 *
 * **Scale Limitation**
 *
 *   (1). axis == "batch" or axis == "feature"
 *      i. computing layout == nchw
 *         input tensor's c is 18869 at most
 *      ii. computing layout == nhwc
 *         input tensor's c is unlimited
 *   (2). axis == "hight" or axis == "width"
 *      i. core_limit == 1
 *         input tensor's c is 11328 at most
 *      ii. core_limit != 1
 *         input tensor's c is 8096 at most
 *
 * **supports only MLU270.**
 *
 *  @param[out] output_tensor
 *    Output. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[out] mean_tensor
 *    Output. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] mean
 *    Output. An MLU address pointing to output position.
 *    This param can be nullptr.
 *  @param[out] variance_tensor
 *    Output. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] variance
 *    Output. An MLU address pointing to output position.
 *    This param can be nullptr.
 *  @param[out] norm_out_tensor
 *    Output. Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] norm_out
 *    Output. An MLU address pointing to output position.
 *    This param can be nullptr.
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] beta_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] beta
 *    Input. An MLU address pointing to input data.
 *    This param can be nullptr.
 *    If nullptr, do not add beta to normalized resutl.
 *  @param[in] gamma_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] gamma
 *    Input. An MLU address which points to input data.
 *    This param can be nullptr.
 *    If nullptr, do not multiply gamma.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *     The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *     At least one of the following conditions are met:
 *     - The operator pointer is null.
 *     - The input pointer is null.
 *     - The output pointer is null.
 */
cnmlStatus_t cnmlComputeLayerNormOpForward(cnmlBaseOp_t op,
                                           cnmlTensor_t input_tensor,
                                           void *input,
                                           cnmlTensor_t beta_tensor,
                                           void *beta,
                                           cnmlTensor_t gamma_tensor,
                                           void *gamma,
                                           cnmlTensor_t output_tensor,
                                           void *output,
                                           cnmlTensor_t mean_tensor,
                                           void *mean,
                                           cnmlTensor_t variance_tensor,
                                           void *variance,
                                           cnmlTensor_t norm_out_tensor,
                                           void *norm_out,
                                           cnrtQueue_t queue,
                                           void *extra);
/* LayerNorm operation end*/

/* zero start */
/*!
 *	@
 *	@brief cnmlCreatezeroOpBackward.
 *
 *	Create an Zero operator based on the base operator pointer given by the user.
 *
 *	After creating a pointer to the base operator address, input and output tensors, pass them
 *to
 *	the function to create an Zero operator.
 *
 *	This function has the functionality of output = Zero(input).
 *
 *	The input input_tensor and output output_tensor  have the same shape.
 *
 *	@param[out]  op
 *		Output. A pointer to the base operator address.
 *	@param[in]	input_tensor
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *supporting
 * data
 *	@param[in]	output
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *supporting
 *		data of float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The input tensor type is either CNML_TENSOR or CNML_CONST.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateZeroOpBackward(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t output_tensor);

/*!
 *	@brief cnmlComputeZeroOpBackward.
 *
 *	It is used to compute the user-specified Zero operator on the MLU.
 *
 *	After creating the Zero operator, Input, Output, runtime parameters, and computation stream,
 *	pass them to the function to It is used to compute the Zero operator.
 *
 *	@param[out]  output
 *		Output. An MLU address that points to the output location.
 *	@param[in]	op
 *		Input. A pointer to the base operator.
 *	@param[in]	input
 *		Input. An MLU address pointing to the input data tensor A.
 *	@param[in]	compute_forw_param
 *		Input. A pointer to the address of the struct, in which the data parallelism and
 *device
 *		affinity at runtime are recorded.
 *	@param[in]	stream
 *		Input. A computation stream pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is empty
 *		- The output pointer is empty
 */

CNML_DLL_API cnmlStatus_t cnmlComputeZeroOpBackward(cnmlBaseOp_t op,
                                                    void *input,
                                                    void *output,
                                                    cnrtInvokeFuncParam_t *compute_forw_param,
                                                    cnrtQueue_t queue);
/* zero end */

/* setconst start */
/*!
 *	@
 *	@brief cnmlCreateSetConstOpBackward.
 *
 *	Create an SetConst operator based on the base operator pointer given by the user.
 *
 *	After creating a pointer to the base operator address, input and output tensors, pass them
 *to
 *	the function to create an SetConst operator.
 *
 *	This function has the functionality of output = SetConst(input).
 *
 *	The input input_tensor and output output_tensor  have the same shape.
 *
 *	@param[out]  op
 *		Output. A pointer to the base operator address.
 *	@param[in]	input_tensor
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *supporting
 * data
 *	@param[in]	output
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *supporting
 *		data of float16 type.
 *	@param[in] Const
 *		Input. A float16/32 type num
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The input tensor type is either CNML_TENSOR or CNML_CONST.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateSetConstOpBackward(cnmlBaseOp_t *op,
                                                       cnmlTensor_t input_tensor,
                                                       cnmlTensor_t output_tensor,
                                                       float Const);

/*!
 *	@brief cnmlComputeSetConstOpBackward.
 *
 *	It is used to compute the user-specified SetConst operator on the MLU.
 *
 *	After creating the SetConst operator, Input, Output, runtime parameters, and computation
stream,
 *	pass them to the function to It is used to compute the SetConst operator.
 *
 *	@param[out]  output
 *		Output. An MLU address that points to the output location.
 *	@param[in]	op
 *		Input. A pointer to the base operator.
 *	@param[in]	input
 *		Input. An MLU address pointing to the input data tensor A.
 *	@param[in]	compute_forw_param
 *		Input. A pointer to the address of the struct, in which the data parallelism and
device
 *		affinity at runtime are recorded.
 *	@param[in]	stream
 *		Input. A computation stream pointer.

* 	 - The operator pointer is empty
 *		- The output pointer is empty
 */

CNML_DLL_API cnmlStatus_t cnmlComputeSetConstOpBackward(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue);

/* bceloss start */

/*!
 *	@brief cnmlCreateBcelossOp.
 *
 *	Create an bceloss operator based on the base operator pointer given by the user.
 *
 *	After creating a pointer to the base operator address, input and output tensors, pass them
 *to
 *	the function to create an Bceloss operator.
 *
 *	The input input and target must have the same shape.
 *
 *  **Formula**
 *
 *    output[n c h w] = -weight[n c h w] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *                 float16: < 20000
 *
 *                 float32: < 10000
 *
 *      NHW direction: unlimited
 *
 *	@param[in]	op
 *		Input. A pointer to the base operator address.
 *	@param[in]	input
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		supporting data of float16 type.
 *	@param[in]	target
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		supporting data of float16 type.
 *	@param[in]	weight
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		supporting data of float16 type.
 *	@param[out]  output
 *		Ouput. A 4-dimensional MLU input tensor, of which the shape is [no, co, ho, wo],
 *		supporting data of float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBcelossOp(cnmlBaseOp_t *op,
                                              cnmlTensor_t input,
                                              cnmlTensor_t target,
                                              cnmlTensor_t output,
                                              cnmlTensor_t weight);

/*!
 *	@brief cnmlComputeBcelossOpForward.
 *
 *	It is used to compute the user-specified Bceloss operator on the MLU.
 *
 *	After creating the Bceloss operator, Input, Output, and computation queue, pass them to the
 *	function to It is used to compute the Bceloss operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = -weight[n c h w] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *                 float16: < 20000
 *
 *                 float32: < 10000
 *
 *      NHW direction: unlimited
 *
 *	@param[out]  output
 *		Output. An MLU address that points to the output location.
 *	@param[in]	op
 *		Input. A pointer to the base operator.
 *	@param[in]	input
 *		Input. An MLU address pointing to the input data tensor input.
 *	@param[in]	target
 *		Input. An MLU address pointing to the input data tensor target.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records the degree
 *		of data parallelism and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *	@param[in]	weight
 *		Input. An MLU address pointing to the input data tensor weight.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is empty
 *		- The output pointer is empty
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBcelossOpForward(cnmlBaseOp_t op,
                                                      void *input,
                                                      void *target,
                                                      void *output,
                                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                                      cnrtQueue_t queue,
                                                      void *weight);
/* bceloss end */

/*bcelossfu  start*/

/*!
 *	@brief cnmlCreateBcelossfuOp.
 *
 *	Create an bceloss operator based on the base operator pointer given by the user.
 *
 *	After creating a pointer to the base operator address, input and output tensors, pass them
 *  to the function to create an Bceloss operator.
 *
 *	The input input and target must have the same shape.
 *
 *  **Formula**
 *
 *    output[n c h w] = -weight[n c h w] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *    or
 *
 *    output[n c h w] = -weight[1 1 1 1] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *                 float16: < 20000
 *
 *                 float32: < 10000
 *
 *      NHW direction: unlimited
 *
 *	@param[in]	op
 *		Input. A pointer to the base operator address.
 *	@param[in]	input
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		supporting data of float16 type.
 *	@param[in]	target
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		supporting data of float16 type.
 *	@param[in]	weight
 *		Input. A 4-dimensional MLU input tensor, of which the shape is [ni, ci, hi, wi],
 *		or [1, 1, 1, 1], supporting data of float16 type.
 *	@param[out]  output
 *		Ouput. A 4-dimensional MLU input tensor, of which the shape is [no, co, ho, wo],
 *		supporting data of float16 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		The input tensor type is either CNML_TENSOR or CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBcelossfuOp(cnmlBaseOp_t *op,
                                                cnmlTensor_t input,
                                                cnmlTensor_t target,
                                                cnmlTensor_t output,
                                                cnmlTensor_t weight);

/*!
 *	@brief cnmlComputeBcelossfuOpForward.
 *
 *	It is used to compute the user-specified Bceloss operator on the MLU.
 *
 *	After creating the Bceloss operator, Input, Output, and computation queue, pass them to the
 *	function to It is used to compute the Bceloss operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = -weight[n c h w] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *    or
 *
 *    output[n c h w] = -weight[1 1 1 1] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *                 float16: < 20000
 *
 *                 float32: < 10000
 *
 *      NHW direction: unlimited
 *
 *	@param[out]  output
 *		Output. An MLU address that points to the output location.
 *	@param[in]	op
 *		Input. A pointer to the base operator.
 *	@param[in]	input
 *		Input. An MLU address pointing to the input data tensor input.
 *	@param[in]	target
 *		Input. An MLU address pointing to the input data tensor target.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records the degree
 *		of data parallelism and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *	@param[in]	weight
 *		Input. An MLU address pointing to the input data tensor weight.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is empty
 *		- The output pointer is empty
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBcelossfuOpForward(cnmlBaseOp_t op,
                                                        void *input,
                                                        void *target,
                                                        void *output,
                                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                                        cnrtQueue_t queue,
                                                        void *weight);

/*!
 *	@brief cnmlComputeBcelossfuOpForward_V2.
 *
 *	It is used to compute the user-specified Bceloss operator on the MLU.
 *
 *	After creating the Bceloss operator, Input, Output, and computation queue, pass them to the
 *	function to It is used to compute the Bceloss operator.
 *
 *  **Formula**
 *
 *    output[n c h w] = -weight[n c h w] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *    or
 *
 *    output[n c h w] = -weight[1 1 1 1] * (target[n c h w] * Log(input[n c h w]) +
 *                      (1 - target[n c h w]) * Log(1 - input[n c h w]))
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      float16, float32
 *
 *  **Scale Limitation**
 *
 *    MLU270:
 *
 *      C direction:
 *
 *                 float16: < 20000
 *
 *                 float32: < 10000
 *
 *      NHW direction: unlimited
 *
 *	@param[out]  output
 *		Output. An MLU address that points to the output location.
 *	@param[in]	op
 *		Input. A pointer to the base operator.
 *	@param[in]	input
 *		Input. An MLU address pointing to the input data tensor input.
 *	@param[in]	target
 *		Input. An MLU address pointing to the input data tensor target.
 *	@param[in] compute_forw_param
 *		Input. A pointer pointing to the struct address, which records the degree
 *		of data parallelism and device affinity of runtime.
 *	@param[in] queue
 *		Input. A computational queue pointer.
 *	@param[in]	weight
 *		Input. An MLU address pointing to the input data tensor weight.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The operator pointer is empty
 *		- The output pointer is empty
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- The runtime task type is invalid
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBcelossfuOpForward_V2(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t target_tensor,
                                                           void *target,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           cnmlTensor_t weight_tensor,
                                                           void *weight);
/*bcelossfu end*/

/* mse param start */
/*!
 *	@struct cnmlMseOpParam
 *	@brief A struct.
 *	cnmlMseOpParam is a structure describing the param parameter of mse operation,
 *	used to
 *	create mse operation.
 *	cnmlCreateMseOpParam is used to create an instance of cnmlMseOpParam_t.
 *	cnmlDestroyMseOpParam is used to destroy an instance of cnmlMseOpParam_t. */

struct cnmlMseOpParam;
typedef struct cnmlMseOpParam *cnmlMseOpParam_t;

cnmlStatus_t cnmlCreateMseOpParam(cnmlMseOpParam_t *param, int reduction_type);

cnmlStatus_t cnmlDestroyMseOpParam(cnmlMseOpParam_t *param);

/* mse param end */

/* mse operation start */
/*!
 *	@brief A function.
 *
 *	cnmlCreateMseOp is used to create an instance of mse.
 *	@param[in] op
 *	Input. An pointer which points to base operators.
 *	@param[in] input_tensor_label, input_tensor_predicted
 *	Input. An Mlu address pointing to input data
 *	@param[out] output_tensor
 *	Output. An Mlu address pointing to output position.
 */
cnmlStatus_t cnmlCreateMseOp(cnmlBaseOp_t *op,
                             cnmlTensor_t input_tensor_label,
                             cnmlTensor_t output_tensor,
                             cnmlMseOpParam_t param,
                             cnmlTensor_t input_tensor_predicted);

/*!
 *	@brief A function.
 *
 *	cnmlComputeMseOpForward is used to compute the mse operator.
 *	@param[in] op
 *	  Input. An pointer which points to base operators.
 *	@param[in] input_label_tensor
 *	  Input. An MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_label, input_tensor_predicted
 *	  Input. An Mlu address pointing to input data
 *	@param[in] input_predicted_tensor
 *	  Input. An MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input_predicted, input_tensor_predicted
 *	  Input. An Mlu address pointing to input data
 *	@param[in] output_tensor
 *	  Input. Output MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output
 *	  Output. An Mlu address pointing to output position.
 */
cnmlStatus_t cnmlComputeMseOpForward(cnmlBaseOp_t op,
                                     cnmlTensor_t *input_label_tensor,
                                     void *input_label,
                                     cnmlTensor_t *input_predicted_tensor,
                                     void *input_predicted,
                                     cnmlTensor_t *output_tensor,
                                     void *output,
                                     cnrtQueue_t queue,
                                     void *extra);
/* mse operation end */

/* isfinite operation start */
/*!
 *  @brief A function.
 *
 *	This function is used to create an operation of IsFinite according to base operator
 *	pointers given by users. After creating a pointer pointing to base operator address,
 *	input and output Tensor, pass them into the fucntion to create the IsFinite operator.
 *
 *	IsFinite operator perform element-wise operation on the input and obtain output.
 *  1.0 value if input[i] has finite value, 0.0 if input[i] is infinite or nan.
 *
 *	For example:
 *
 *	input = [nan, inf, -inf, 0.0, 1.0]
 *
 *	isfinite(input, output)
 *
 *	output = [0.0, 0.0, 0.0, 1.0, 1.0]
 *
 *	The shapes and data types of input and of output should be exactly the same.
 *
 *  **DataType**
 *
 *      input : float16, float32
 *
 *      output : the same as input or bool
 *
 *  **Supports only MLU270.**
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		One of the following conditions is not satisfied:
 *		- op is nullptr
 *		- input is nullptr
 *		- output is nullptr
 *
 *
 */
cnmlStatus_t cnmlCreateIsFiniteOp(cnmlBaseOp_t *op,
                                  cnmlTensor_t input_tensor,
                                  cnmlTensor_t output_tensor);

/*!
 *  @brief A function.
 *
 *  cnmlComputeIsFiniteOpForward is used to compute the isfinite operator on MLU.
 *
 *	Perform element-wise operation on the input and obtain output.
 *  1.0 value if input[i] has finite value, 0.0 if input[i] is infinite or nan.
 *
 *	For example:
 *
 *	input = [nan, inf, -inf, 0.0, 1.0]
 *
 *	isfinite(input, output)
 *
 *	output = [0.0, 0.0, 0.0, 1.0, 1.0]
 *
 *	The shapes and data types of input and of output should be exactly the same.
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] input
 *    Input. An MLU address pointing to input data.
 *  @param[in] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *  @param[in] queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - Reason1 The operator pointer is null.
 *    - Reason2 The output pointer is null.
 *    - Reason3 The input pointer is null.
 *  @retval CNML_STATUS_INVALIDARG
 *    At least one of the following conditions are met:
 *    - Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeIsFiniteOpForward(cnmlBaseOp_t op,
                                                       cnmlTensor_t input_tensor,
                                                       void *input,
                                                       cnmlTensor_t output_tensor,
                                                       void *output,
                                                       cnrtQueue_t queue,
                                                       void *extra);
/* isfinite operation end */

/* l1loss param start */
/*!
 *	@struct cnmlL1lossOpParam
 *	@brief A struct.
 *	cnmlL1lossOpParam is a structure describing the param parameter of l1loss operation,
 *	used to
 *	create l1loss operation.
 *	cnmlCreateL1lossOpParam is used to create an instance of cnmlL1lossOpParam_t.
 *	cnmlDestroyL1lossOpParam is used to destroy an instance of cnmlL1lossOpParam_t. */

struct cnmlL1lossOpParam;
typedef struct cnmlL1lossOpParam *cnmlL1lossOpParam_t;

cnmlStatus_t cnmlCreateL1lossOpParam(cnmlL1lossOpParam_t *param, int reduction_type);

cnmlStatus_t cnmlDestroyL1lossOpParam(cnmlL1lossOpParam_t *param);

/* l1loss param end */

/* l1loss operation start */
/*!
 *	@brief A function.
 *
 *	cnmlCreateL1lossOp is used to create an instance of l1loss.
 *	@param[in] op
 *	Input. An pointer which points to base operators.
 *	@param[in] input_tensor_label, input_tensor_predicted
 *	Input. An Mlu address pointing to input data
 *	@param[out] output_tensor
 *	Output. An Mlu address pointing to output position.
 */
cnmlStatus_t cnmlCreateL1lossOp(cnmlBaseOp_t *op,
                                cnmlTensor_t input_tensor_label,
                                cnmlTensor_t input_tensor_predicted,
                                cnmlTensor_t output_tensor,
                                cnmlL1lossOpParam_t param);

/*!
 *	@brief A function.
 *
 *	cnmlComputeL1lossOpForward is used to compute the l1loss operator.
 *	@param[in] op
 *	Input. An pointer which points to base operators.
 *	Input. An pointer which points to base operators.
 *	@param[in] input_tensor_label, input_tensor_predicted
 *	Input. An Mlu address pointing to input data
 *	@param[out] output_tensor
 *	Output. An Mlu address pointing to output position.
 */
cnmlStatus_t cnmlComputeL1lossOpForward(cnmlBaseOp_t op,
                                        void *input_label,
                                        void *input_predicted,
                                        void *output,
                                        cnrtInvokeFuncParam_t *compute_forw_param,
                                        cnrtQueue_t queue);
/* l1loss operation end */

/* matrix band part operation start  */
/*!
 *	@brief A function.
 *
 *	According to the base operator pointer given by the user,
 *	create a matrix band part operation operator.
 *
 *	The operator copy an input
 *	tensor setting everything outside a central band in each innermost matrix.
 *
 *	The scale of input and output must be the same.
 *
 *	@param[out] op
 *		Output. A pointer pointing to base operators address.
 *	@param[in] input_tensor
 *		Input. A four-dimensional MLU input tensor,
 *		the shape is [ni, ci, hi, wi], supports data of float16 and float32 type.
 *	@param[in] output_tensor
 *		Input. A four-dimensional MLU output tensor,
 *		the shape is [no, co, ho, wo], supports data of float16 and float32 type.
 *	@param[in] num_lower
 *		Input. Number of subdiagonals to keep, supports data of int type..
 *	@param[in] num_upper
 *		Input. Number of superdiagonals to keep, supports data of int type.
 *	@retval CNML_STATUS_SUCCESS
 *		Successfully created a matrix band part operation.
 *		Return the corresponding error code when execution is failed.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateMatrixBandPartOp(cnmlBaseOp_t *op,
                                                     cnmlTensor_t input,
                                                     cnmlTensor_t output,
                                                     int num_lower,
                                                     int num_upper);

/*!
 *	@brief A function.
 *
 *	Perform the user-specified clipping operation on the MLU.
 *
 *	After creating matrix band part operator, input, output and computation stream,
 *	introduce them to the function to compute the Matrix Band Part operator.
 *
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *  @param[in] input_tensor
 *    Input. Input MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input
 *		Input. An MLU address pointing to input data.
 *  @param[out] output_tensor
 *    Input.  Output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. An MLU address pointing to output position.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *  @param[in] extra
 *    Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The runtime task type is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeMatrixBandPartOpForward(cnmlBaseOp_t op,
                                                             cnmlTensor_t input_tensor,
                                                             void *input,
                                                             cnmlTensor_t output_tensor,
                                                             void *output,
                                                             cnrtQueue_t queue,
                                                             void *extra);
/* matrix band part operation end  */

/* listdiff operation start */
/*!
 *  @brief cnmlCreateListDiffOp.
 *
 *  Create a listdiff operator based on the base operator pointer
 *  given by the user.
 *
 *  This operator compares two vectors, outputs a vector containing value
 *  that belongs to first vector but not to second vector,
 *  and gives the index of these value in another vector
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *  @param[out] op
 *    Output. A pointer pointing to base operators address.
 *  @param[in] inputX
 *    Input. A four-dimensional MLU input tensor, the shape of which is
 *    [1, ci1, 1, 1], supporting data of float16 and float32 types.
 *  @param[in] inputY
 *    Input. A four-dimensional MLU input tensor, the shape of which is
 *    [1, ci2, 1, 1], supporting data of float16 and float32 types.
 *  @param[in] out
 *    Input. A four-dimensional MLU output tensor, the shape of which is
 *    [1, co, 1, 1], supporting data of float16 and float32 types.
 *  @param[in] out_idx
 *    Input. A four-dimensional MLU index vector the shape of which is
 *    [1, co, 1, 1], supporting data of int32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The type of input tensor is neither CNML_TENSOR nor CNML_CONST.
 */
cnmlStatus_t cnmlCreateListDiffOp(cnmlBaseOp_t *op,
                                  cnmlTensor_t inputX,
                                  cnmlTensor_t inputY,
                                  cnmlTensor_t out,
                                  cnmlTensor_t out_idx);

/*!
 *  @brief cnmlComputeListDiffOpForward.
 *
 *  Compute the listdiff operator specified by users on the MLU.
 *
 *  After creating a listdiff operator, input, output and computation queue,
 *  pass them into the function to compute the listdiff operator.
 *
 *  **DataType**
 *
 *    MLU270:
 *
 *      input : float16, float32, int32
 *
 *      output : the same as input
 *
 *  @param[in] op
 *    Input. A pointer which points to base operators.
 *  @param[in] inputX_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is
 *    [1, ci1, 1, 1], supporting data of float16 and float32 types.
 *    Pass NULL if not used.
 *  @param[in] inputX
 *    Input. An MLU address which points to input data.
 *  @param[in] inputY_tensor
 *    Input. A four-dimensional MLU input tensor, the shape of which is
 *    [1, ci2, 1, 1], supporting data of float16 and float32 types.
 *    Pass NULL if not used.
 *  @param[in] inputY
 *    Input. An MLU address which points to input data.
 *  @param[in] out_tensor
 *    Input. A four-dimensional MLU output tensor, the shape of which is
 *    [1, co, 1, 1], supporting data of float16 and float32 types.
 *    Pass NULL if not used.
 *  @param[out] out
 *    Output. An MLU address pointing to output position.
 *  @param[in] out_idx_tensor
 *    Input. A four-dimensional MLU index vector the shape of which is
 *    [1, co, 1, 1], supporting data of int32 type. Pass NULL if not used.
 *  @param[out] out_idx
 *    Output. An MLU address pointing to the index position.
 *  @param[in] queue
 *    Input. A computational queue pointer.
 *  @param[in] extra
 *    Input. Extra parameter pointer. Reserved for future use.
 *    Pass NULL if not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The operator pointer is null.
 *    - The inputX or inputY pointer is null.
 *    - The out or out_idx pointer is null.
 */
cnmlStatus_t cnmlComputeListDiffOpForward(cnmlBaseOp_t op,
                                          cnmlTensor_t inputX_tensor,
                                          void *inputX,
                                          cnmlTensor_t inputY_tensor,
                                          void *inputY,
                                          cnmlTensor_t out_tensor,
                                          void *out,
                                          cnmlTensor_t out_idx_tensor,
                                          void *out_idx,
                                          cnrtQueue_t queue,
                                          void *extra);
/* listdiff operation end */

/* logloss operation begin */
/*!
 *  @brief A function.
 *
 *  Create a logloss operation based on the base operator pointer given by the user
 *
 *  After creating a pointer to the base operator address, input and output tensors,
 *  dimension, pass them to the function to create a logloss operator
 *
 *  @param[out] op
 *    Output. A pointer to the base operator address
 *  @param[in] dim
 *    Input. Reduce dimension
 *  @param[in] inputTensorY
 *    Input. A 4-dimensional MLU input tensor, supporting data of float16 and float32
 *  @param[in] inputTensorP
 *    Input. A 4-dimensional MLU input tensor, all elements should be positive,
 *    supporting data of float16 and float32
 *  @param[in] weight
 *    Input. weight can be a 4-dimensional MLU input tensor,
 *    supporting data of float16 and float32, or nullptr. When weight is nullptr,
 *    this logloss operator don't have weights.
 *  @param[out] output
 *    Output. A 4-dimensional MLU input tensor, with the shape of [1, 1, 1, 1]
 *    supporting data of float16 and float32
 */
cnmlStatus_t cnmlCreateLogLossOp(cnmlBaseOp_t *op,
                                 cnmlDimension_t dim,
                                 cnmlTensor_t inputTensorY,
                                 cnmlTensor_t inputTensorP,
                                 cnmlTensor_t weight,
                                 cnmlTensor_t output);

/*!
 *  @brief A function.
 *
 *  Compute the user-specified logloss operator on the MLU
 *
 *  @param[in] op
 *    Input. A pointer to the base operator address
 *  @param[in] inputTensorY
 *    Input. A 4-dimensional MLU input tensor, supporting data of float16 and float32,
 *    Pass NULL if not used.
 *  @param[in] inputY
 *    Input. A MLU address pointing to the input data Y
 *  @param[in] inputTensorP
 *    Input. A 4-dimensional MLU input tensor, all elements should be positive,
 *    supporting data of float16 and float32, Pass NULL if not used.
 *  @param[in] inputP
 *    Input. A MLU address pointing to the input data P
 *  @param[in] weightTensor
 *    Input. weight can be a 4-dimensional MLU input tensor,
 *    supporting data of float16 and float32, or nullptr. When weight is nullptr,
 *    this logloss operator don't have weights. Pass NULL if not used.
 *  @param[in] weight
 *    Input. weight can be a MLU address pointing to the input data weights,
 *    or nullptr. When weight is nullptr, logloss operator don't have weights.
 *  @param[out] outputTensor
 *    Output. A 4-dimensional MLU input tensor, with the shape of [1, 1, 1, 1]
 *    supporting data of float16 and float32, Pass NULL if not used.
 *  @param[out] output
 *    Output. A MLU address pointing to the output data
 *  @param[in]  queue
 *    Input. A computation queue pointer.
 *  @param[in] extra
 *    Input. Extra parameter pointer. Reserved for future use.
 *    Pass NULL if not used.
 */
cnmlStatus_t cnmlComputeLogLossOpForward(cnmlBaseOp_t op,
                                         cnmlTensor_t inputTensorY,
                                         void *inputY,
                                         cnmlTensor_t inputTensorP,
                                         void *inputP,
                                         cnmlTensor_t weightTensor,
                                         void *weight,
                                         cnmlTensor_t outputTensor,
                                         void *output,
                                         cnrtQueue_t queue,
                                         void *extra);
/* logloss operation end */

/*!
 *	@brief A function.
 *
 *	This function initializes a multidimensional (1-N-dimensional) Tensor at the MLU end
 *according
 *	to the user-specified Tensor type.
 *
 *	@param[in] tensor
 *		Input. A pointer pointing to cnmlTensor_t
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The pointer of tensor is null.
 *		- Tensor_typeis not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTensor_V3(cnmlTensor_t *tensor);

/*!
 *	@brief A function.
 *
 *	This function sets the tensor type of the Tensor.
 *
 *	@param[in] tensor
 *		Input. A pointer pointing to cnmlTensor_t
 *	@retval cnmlTensorType_t tensor type
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The pointer of tensor is null.
 *		- Tensor_typies not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlSetTensorType(cnmlTensor_t tensor, cnmlTensorType_t tensor_type);

CNML_DLL_API cnmlStatus_t cnmlSetTensorDimMutable(cnmlTensor_t tensor,
                                                  bool *dim_mutable,
                                                  int dim_num);

CNML_DLL_API cnmlStatus_t cnmlSetTensorName(cnmlTensor_t tensor, const char *name);

CNML_DLL_API cnmlStatus_t cnmlGetTensorName(cnmlTensor_t tensor, char *name);

CNML_DLL_API cnmlStatus_t cnmlSetBaseOpJobType(cnmlBaseOp_t fop, cnrtJobType_t job_type);

CNML_DLL_API cnmlStatus_t cnmlSetFusionOpJobType(cnmlFusionOp_t fop, cnrtJobType_t job_type);

CNML_DLL_API cnmlStatus_t cnmlGetTensorElementNum(cnmlTensor_t tensor, size_t *element_num);

CNML_DLL_API cnmlStatus_t cnmlInferFusionOpOutputShape(cnmlFusionOp_t fop,
                                                       cnmlTensor_t inputs[],
                                                       int input_num,
                                                       cnmlTensor_t outputs[],
                                                       int output_num);
/*!
 *	@brief A function.
 *
 *
 *	According to the base operator pointer given by the user, a convolution operator is created.
 *
 *	After a pointer pointing to the address of base operator, the operation parameter of
 *convolution
 *	operator and input-output tensor are created, they are introduced into the function to
 *create
 *	the convolution operator.
 *
 *	Before the convolution operator is created, a pointer pointing to the address of the
 *convolution
 *	operator parameter struct is declared, and the pointer and required operator parameter are
 *	introduced to the function to set the operator parameter.
 *
 *	A simple 2-dimensional convolution can be seen as a process that a 2-dimensional convolution
 *	kernel (weight matrix) slides on 2-dimensional input data, matrix multiplication is
 *performed on
 *	some of the elements currently input, and then the results are summed into a single input
 *pixel.
 *	The convolution kernel repeats this process until it traverses the entire picture and
 *converts a
 *	2-dimensional matrix into another. The special operation padding is equivalent to filling
 *the
 *	edge of the input data with 0 (filling padding_height/2 0 in the height direction,
 *	padding_weight/2 0 in the weight direction), and stride refers to the sliding step of the
 *	convolution kernel.
 *
 *	The n-dimension and c-dimension generally refer to batch and channel. The general
 *convolution
 *	operation (4-dimensional convolution) can be seen as a process that the input and weight of
 *a
 *	batch is taken, and convolution operation is performed on the 2-dimensional inputs and
 *	convolution kernels of different channels, the computation results of different channels are
 *	added to get the output of the batch, after all the batches are completed, the bias is added
 *to
 *	get the output.
 *
 *	hf <= hi,wf <= wi
 *
 *	if (dilation_height > 1 || dilation_width > 1) pad_height == 0 && pad_width == 0
 *
 *	The length of the weight in the Height direction must be less than or equal to the length of
 *the
 *	input in the Height direction. The length of the weight in the Width direction must be less
 *than
 *	or equal to the length of the input in the Width direction.
 *
 *	If dilation factor of Height dimension or dilation factor of Width dimension is greater than
 *1,
 *	the pad length in the Height direction and the Width direction is greater than 1.
 *
 *	**Supports both MLU220 and MLU270.**
 *
 *	@param[out] op
 *		Output. A pointer pointing to the address of the base operator.
 *	@param[in] param
 *		Input. A pointer struct of convolution operation.
 *	@param[in] input_tensor
 *		Input. A 4-dimensional MLU input tensor, the shape is [ni, hi, wi, ci],supporting
 *data
 *of
 *	int8, int16 type.
 *	@param[in] input_quantized_param
 *		Input. A 4-dimensional MLU intput_quantized tensor, the shape is [1, 4, 1,
 *1],supporting data
 * of
 *	float32 type.
 *	@param[in] filter_tensor
 *		Input. A 4-dimensional MLU weight tensor, the shape is [nf, hf, wf, cf] (nf = co, cf
 *=
 *	ci),supporting data of int8, int16 type.
 *	@param[in] filter_quantized_param
 *		Input. A 4-dimensional MLU weight_quantized tensor, the shape is [1, 4, 1,
 *1],supporting data
 * of
 *	float32 type.
 *	@param[in] bias_tensor
 *		Input. A 4-dimensional MLU bias tensor, the shape is [nb, hb, wb, cb] (nb = 1, hb =
 *1,
 *wb = 1,
 *	cb = co),supporting data of float32, float16 type.
 *	@param[in] output_tensor
 *		Input. A 4-dimensional MLU output tensor, the shape is [no, ho, wo, co](no =
 *ni),supporting
 *	data of float32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- The type of input tensor is not CNML_TENSOR nor CNML_CONST.
 *		- The CPU tensor bound by the bias tensor is null.
 */

CNML_DLL_API cnmlStatus_t cnmlCreateConvOpTrainingForward(cnmlBaseOp_t *op,
                                                          cnmlConvOpParam_t param,
                                                          cnmlTensor_t input,
                                                          cnmlTensor_t input_quantized_param,
                                                          cnmlTensor_t filter,
                                                          cnmlTensor_t filter_quantized_param,
                                                          cnmlTensor_t bias,
                                                          cnmlTensor_t output);

/*!
 *	@brief A function.
 *
 *	Computing user-specified convolution operators on MLU.
 *
 *	After convolution operator, input, output, parameter at runtime, and computational queue are
 *	created, they are introduced into the function to compute convolution operator.
 *
 *	**Supports MLU270.**
 *
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] input_tensor
 *		Input. Input MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input
 *		Input. An MLU address pointing to input data.
 *	@param[in] output_tensor
 *		Input.	Output MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@param[in] extra
 *		Input.	Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *	@param[in] input_quantized_param
 *		Input. An MLU address pointing to intput quantized data.
 *	@param[in] filter_quantized_param
 *		Input. An MLU address pointing to filter quantized data.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *		- Reason3 The input pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The task type of runtime is invalid.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeConvOpTrainingForward(cnmlBaseOp_t op,
                                                           cnmlTensor_t input_tensor,
                                                           void *input,
                                                           cnmlTensor_t input_quantized_tensor,
                                                           void *input_quantized_param,
                                                           cnmlTensor_t filter_tensor,
                                                           void *filter,
                                                           cnmlTensor_t filter_quantized_tensor,
                                                           void *filter_quantized_param,
                                                           cnmlTensor_t bias_tensor,
                                                           void *bias,
                                                           cnmlTensor_t output_tensor,
                                                           void *output,
                                                           cnrtQueue_t queue,
                                                           void *extra);

/*!
 *	@brief A function.
 *
 *	According to the basic operator pointer given by the use, this function creates a
 *  Multiple-layer perceptron operator.
 *
 *	After the pointer pointing to the base operator, the sparse mode of MLP operator and the
 *	input-output tensor are created, they are introduced into the function to create the MLP
 *	operator.
 *
 *	Assuming input, weight, and output are arranged in NCHW order, output[n, coo, 1, 1] =
 *  âˆ‘input[n, cii, h, w] * filter[coo, cii, h, w], the sum of subscripts cii, h and W is
 *  carried out, and the summation range is [0, ci - 1],[0, hi - 1],[0, wi - 1], if the bias
 *  tensor is not null, the final output should add bias.
 *
 *	**Supports both MLU220 and MLU270.**
 *
 *	@param[out] op
 *		Output. A pointer pointing to the address of the base operator
 *	@param[in] input_tensor
 *		Input. A 4-dimensional input tensor with the shape of [ni, ci, hi, wi],supporting
 *  data of float16 type.
 *	@param[in] output_tensor
 *		Input. A 4-dimensional output tensor,the shape is [no, co, ho, wo] (no = ni, co =
 *  nf, ho = 1, wo = 1),supporting data of float16 type.
 *	@param[in] filter_tensor
 *		Input. A 4-dimensional weight tensor with the shape of	 [nf, cf, hf, wf] (nf =
 *  co, cf = ci, hf = hi, wf = wi),supporting data of float16 type.
 *	@param[in] bias_tensor
 *		Input. A 4-dimensional bias tensor with the shape of [nb, cb, hb, wb] (nb = 1, cb =
 *  co, hb = 1, wb = 1),supporting data of float16 type.
 *	@param[in] input_quantized_param
 *		Input. A 4-dimensional MLU intput_quantized tensor, the shape is [1, 4, 1,
 *  1],supporting data of float32 type.
 *	@param[in] filter_quantized_param
 *		Input. A 4-dimensional MLU weight_quantized tensor, the shape is [1, 4, 1,
 *  1],supporting data of float32 type.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateMlpOpTrainingForward(cnmlBaseOp_t *op,
                                                         cnmlTensor_t input,
                                                         cnmlTensor_t input_quantized_param,
                                                         cnmlTensor_t filter,
                                                         cnmlTensor_t filter_quantized_param,
                                                         cnmlTensor_t bias,
                                                         cnmlTensor_t output);

/*!
 *	@brief A function.
 *
 *	Computing the MLP operator specified by the user on MLU.
 *
 *	After the MLP operator, input, output and computational stream are created, they are
 *  introduced into the function to compute the MLP operator.
 *
 *	**Supports both MLU220 and MLU270.**
 *
 *	@param[in] op
 *		Input. A pointer which points to base operators.
 *	@param[in] input_tensor
 *		Input. Input MLU tensor pointer. Pass NULL if not used.
 *	@param[in] input
 *		Input. An MLU address pointing to input data.
 *	@param[in] output_tensor
 *		Input.	Output MLU tensor pointer. Pass NULL if not used.
 *	@param[out] output
 *		Output. An MLU address pointing to output position.
 *	@param[in] queue
 *		Input. A computation queue pointer.
 *	@param[in] extra
 *		Input.	Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *	@param[in] input_quantized_param
 *		Input. An MLU address pointing to intput quantized data.
 *	@param[in] filter_quantized_param
 *		Input. An MLU address pointing to filter quantized data.
 *	@retval CNML_STATUS_SUCCESS
 *		The function ends normally.
 *	@retval CNML_STATUS_INVALIDPARAM
 *		At least one of the following conditions are met:
 *		- Reason1 The operator pointer is null.
 *		- Reason2 The output pointer is null.
 *		- Reason3 The input pointer is null.
 *	@retval CNML_STATUS_INVALIDARG
 *		At least one of the following conditions are met:
 *		- Reason1 The task type of runtime is invalid.
 */

CNML_DLL_API cnmlStatus_t cnmlComputeMlpOpTrainingForward(cnmlBaseOp_t op,
                                                          cnmlTensor_t input_tensor,
                                                          void *input,
                                                          cnmlTensor_t input_quantized_tensor,
                                                          void *input_quantized_param,
                                                          cnmlTensor_t filter_tensor,
                                                          void *filter,
                                                          cnmlTensor_t filter_quantized_tensor,
                                                          void *filter_quantized_param,
                                                          cnmlTensor_t bias_tensor,
                                                          void *bias,
                                                          cnmlTensor_t output_tensor,
                                                          void *output,
                                                          cnrtQueue_t queue,
                                                          void *extra);
/* ScatterTorch operation start */
/*!
 * @struct cnmlScatterTorchOpParam
 * @brief A struct.
 *
 * cnmlScatterTorchOpParam is a structure describing the parameters required by ScatterTorch.
 * cnmlCreateScatterTorchOpParam() and cnmlDestroyScatterTorchOpParam are used to create and
 * destroy an instance of cnmlScatterTorchOpParam_t, respectively.
 */
struct cnmlScatterTorchOpParam;
/*! ``cnmlScatterTorchOpParam_t`` is a pointer to ``cnmlScatterTorchOpParam``, which is a
 *  struct describing the parameters of the ScatterTorch operator.
 */
typedef struct cnmlScatterTorchOpParam *cnmlScatterTorchOpParam_t;
/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function creates the parameters required by
 * ScatterTorch operator.
 * @param[out] param
 *   Output. A pointer pointing to the address of the parameter of the ScatterTorch operator.
 * @param[in] channel
 *   Input. the specified dimension to be scattered. The value is chosen from CNML_DIM_C and
 * CNML_DIM_H.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterTorchOpParam(cnmlScatterTorchOpParam_t *param,
                                                        cnmlDimension_t channel);

/*!
 * @brief A function.
 *
 * According to the pointer given by the user, the function destroies the parameters of the
 * ScatterTorch operator.
 *
 * After the ScatterTorch operator is finished, the created struct pointer of ScatterTorch
 * operator
 * is freed.
 * @param[in] param
 *   Input. A pointer pointing to the address of the struct of ScatterTorch operator parameters.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyScatterTorchOpParam(cnmlScatterTorchOpParam_t *param);

/*!
 * @brief A function.
 *
 * The function creates a ScatterTorch operator according to the base operator pointer given by
 * users.
 *
 * After creating a pointer pointing to the base operators, the index, src and output tensor will
 * be passed to the function to create the ScatterTorch operator.
 *
 * Scatter the src to the output on a specified dimension, depending on parameter channel and
 * according to the index tensor specify the coordinate on that dimension.
 *
 * As the op is an in-place op, make sure the output tensor has the correct shape.
 *
 * The equations for computing where the src should be placed.
 *
 *   channel=c:  output[n] [index[n][c][1][1]] [1] [1] = src
 *
 *   channel=h:  output[index[n][c][1][1]] [c] [1] [1] = src
 *
 * @param[out] op
 *   Output. A pointer pointing to the base operator address.
 * @param[in] input Tensor
 *   Input. A four-dimensional input tensor, the shape of which is [ni, ci, 1, 1],
 *   The datatype of the output can be float16 or float32.
 * @param[in] index Tensor
 *   Input. A four-dimensional input tensor, the shape of which is [idx_n, idx_c, 1, 1],
 *   uint32 datatype is supported.
 * @param[in] src Tensor
 *   Input. A four-dimensional input tensor, the shape of which is [1, 1, 1, 1]
 *   The datatype of the src can be float16 or float32.
 * @param[out] output_tensor
 *   Output. A four-dimensional output tensor, the shape of which is [no, co, 1, 1].
 *   The datatype of the output can be float16 or float32.
 * @param[in] param
 *   Input. A struct param for the ScatterTorch operator, including channel which should be
 * CNML_DIM_C or CNML_DIM_H.
 * @note output and input data type should be the same.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *   - op is a null pointer
 *   - Param is a null pointer.
 *   - input_tensor is a null pointer.
 *   - index_tensor is a null pointer.
 *   - src_tensor is a null pointer.
 *   - output_tensor is a null pointer.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateScatterTorchOp(cnmlBaseOp_t *op,
                                                   cnmlTensor_t input_tensor,
                                                   cnmlTensor_t index_tensor,
                                                   cnmlTensor_t src_tensor,
                                                   cnmlTensor_t output_tensor,
                                                   cnmlScatterTorchOpParam_t param);
/*!
 * @brief A function.
 *
 * Compute the ScatterTorch operator specified by users on MLU.
 *
 * After creating a pointer pointing to the base operators, passing index tensor, src
 * tensor and output tensor into the function to compute the ScatterTorch operator.
 *
 * As the op is an in-place op, make sure the cpu output pointer point to valid data.
 *
 * @param[out] output
 *   Output. The MLU address of the output data.
 * @param[in] op
 *   Input. A pointer to the base operators.
 * @param[in] input_tensor
 *   Input.  Input MLU tensor pointer. Pass NULL if not used.
 * @param[in] input
 *   Input. The MLU address of the input data.
 * @param[in] idx_tensor
 *   Input. Index MLU tensor pointer. Pass NULL if not used.
 * @param[in] index
 *   Input. The MLU address of the index data.
 * @param[in] src_tensor
 *   Input. Src MLU tensor pointer. Pass NULL if not used.
 * @param[in] src
 *   Input. The MLU address of the src data.
 * @param[out] output_tensor
 *   Output.  Output MLU tensor pointer. Pass NULL if not used.
 * @param[in] queue
 *   Input. A comutational queue pointer.
 * @param[in] extra
 *   Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 * @retval CNML_STATUS_SUCCESS
 *   The function ends normally.
 * @retval CNML_STATUS_INVALIDPARAM
 *   At least one of the following conditions are met:
 *   - op is a null pointer
 *   - input is a null pointer
 *   - index is a null pointer.
 *   - src is a null pointer.
 *   - output is a null pointer.
 */
cnmlStatus_t cnmlComputeScatterTorchOpForward(cnmlBaseOp_t op,
                                              cnmlTensor_t input_tensor,
                                              void *input,
                                              cnmlTensor_t idx_tensor,
                                              void *index,
                                              cnmlTensor_t src_tensor,
                                              void *src,
                                              cnmlTensor_t output_tensor,
                                              void *output,
                                              cnrtQueue_t queue,
                                              void *extra);
/* ScatterTorch operation end */

/*for training end*/

/* filter layout trans operation start */
/*!
 *  @brief A function.
 *
 *  According to the base operator pointer given by the user, create a filter layout trans
 *  function operator.
 *
 *  @param[in] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor
 *  @param[out] output
 *    Output. A 4-dimensional MLU output tensor
 *    - op is nullptr
 *    - The type of input tensor is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateFilterLayoutTransOp(cnmlBaseOp_t *op,
                                                        const cnmlTensor_t input,
                                                        const cnmlTensor_t output,
                                                        const cnmlTensor_t sw,
                                                        bool is_forward);
/*!
 *  @brief A function.
 *
 *  run filter layout trans operator.
 *
 *  @param[in] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input
 *    Input. A 4-dimensional MLU input tensor
 *  @param[out] output
 *    Output. A 4-dimensional MLU output tensor
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - op is nullptr
 *    - The type of input tensor is not CNML_TENSOR.
 */
CNML_DLL_API cnmlStatus_t
cnmlComputeFilterLayoutTransOpForward(cnmlBaseOp_t op,
                                      void *input,
                                      void *output,
                                      void *sw,
                                      cnrtInvokeFuncParam_t *compute_forw_param,
                                      cnrtQueue_t queue);
/* filter layout trans operation end*/

/* bcewithlogitsloss begin */
/*!
 *  @brief
 *
 *  The whole name of Op is Binary Cross Entropy with logits loss
 *  According to the base operator pointer given by the user, create a bcewithlogitsloss
 *  function operator.
 *
 *  Formula:
 *
 *  l = -weight*{pos_weight*y*log(sigmoid(x))+(1-y)*log(1-sigmoid(x))}
 *
 *         { (l1, l2, ..., ln)       reduction == 0
 *  Loss = { l1 + l2 + ... + ln      reduction == 1
 *         { (l1+l2+...+ln) / (nchw) reduction == 2
 *
 *  @param[in] op
 *    Output. A pointer to the base operator address.
 *  @param[in] input_vec
 *    Input. the cnmlTensor_t vector which include the input value below:
 *    (1) x  :(must) an input tensor which is the input of bcewithlogitsloss,
 *            the shape of x is four dimensions [N,C,H,W].
 *    (2) y  :(must) an input tensor which is the target label,
 *            the shape of y is four dimensions [N,C,H,W].
 *    (3) weight :(optional) an input tensor which is the weight of bacth, the shape of weight is
 *            [N,1,1,1].
 *    (4) pos_weight :(optional) an input tensor which is the pos_weight of classes, the shape of
 *            pos_weight is [1,C,1,1].
 *    The input data supports the data of float16 and float32 datatype.
 *  @param[in] input_num
 *    Input. the input_num is the size of input_vec.
 *  @param[in] reduction
 *    Input. Three models: None, Sum, Mean. When reduction is 0, it stands for None;
 *    When reduction is 1, it stands for Sum. When reduction is 2, it stands for Mean.
 *  @param[in] is_weight
 *    Input. when weight exists, is_weight is 1; If not, is_weight is 0;
 *  @param[in] is_pos_weight
 *    Input. when pos_weight exists, is_pos_weight is 1; If not, is_pos_weight is 0;
 *  @param[out] output
 *    Output. A 4-dimensional MLU tensor, the shape is [N, C, H, W] which is same as x shape.
 *    When Reduction is 0, while the shape is [1, 1, 1, 1] when Reduction is 1, 2
 *    supporting the data of float32 type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The input tensor type is neither CNML_TENSOR nor CNML_CONST.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateBceWithLogitsLossOp(cnmlBaseOp_t *op,
                                                        const cnmlTensor_t *input_vec,
                                                        int input_nums,
                                                        int reduction,
                                                        int is_weight,
                                                        int is_pos_weight,
                                                        const cnmlTensor_t output);

/*!
 *  @brief
 *  Computing user-specified bcewithlogitsloss operation on MLU,
 *
 *  @param[in] op
 *    Output. A pointer to the base operator address.
 * @param[in] input_tensor_vec
 *   Input. input MLU tensor pointer. Pass NULL if not used.
 *  @param[in] inputs
 *    Input. A MLU address vector that point to input_vec of
 *           bcewithlogitsloss create function.
 *  @param[in] input_nums
 *    Input. the size of input_vec.
 * @param[output] output_tensor
 *   Input. output MLU tensor pointer. Pass NULL if not used.
 *  @param[out] output
 *    Output. A MLU address that points to output.
 * @param[in] queue
 *   Input. A comutational queue pointer.
 * @param[in] extra
 *   Input.  Extra parameter pointer. Reserved for future use. Pass NULL is not used.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 */
CNML_DLL_API cnmlStatus_t cnmlComputeBceWithLogitsLossOp(cnmlBaseOp_t op,
                                                         cnmlTensor_t input_tensor_vec[],
                                                         void *inputs[],
                                                         int input_nums,
                                                         cnmlTensor_t output_tensor,
                                                         void *output,
                                                         cnrtQueue_t queue,
                                                         void *extra);
/* bcewithlogitsloss end */

/******* deprecated API ********/
// cpu tensor
/*!
 *  @struct cnmlCpuTensor
 *  @brief A struct.
 *
 *  cnmlCpuTensor is a structure describing tensor in CPU. cnmlCreateCpuTensor() is used to create a
 *  4D instance of cnmlCpuTensor_t. cnmlCreateCpuTensor_V2() is used to create a ND instance of
 *  cnmlCpuTensor_t. cnmlDestroyCpuTensor() is used to destroy an instance of cnmlCpuTensor_t. */
struct cnmlCpuTensor;
/*! ``cnmlCpuTensor_t`` is a pointer to ``cnmlCpuTensor`` which is a
    structure holding the description of a tensor in CPU. */
typedef struct cnmlCpuTensor *cnmlCpuTensor_t;

/*!
 *  @brief A function.
 *
 *  This function initializes a tensor at CPU end according to the user-specified Tensor type.
 *
 *  @param[out] cpu_tensor
 *    Output. A pointer pointing to the tensor at CPU end that has been created.
 *  @param[in] tensor_type
 *    Input. An enumeration variable indicates the tensor type. The optional types are CNML_TENSOR,
 *  CNML_FILTER and CNML_CONST_TENSOR.
 *  @param[in] data_type
 *    Input. A variable that indicates the type of data at CPU end.
 *  @param[in] data_order
 *    Input. Variable indicating the placement format of data at CPU end, currently, the supported
 *  orders are: CNML_NCHW,CNML_NHWC,CNML_HWCN,CNML_TNC.
 *  @param[in] n
 *    Input. An integer variable that indicates the size of n dimension.
 *  @param[in] c
 *    Input. An integer variable that indicates the size of c dimension.
 *  @param[in] h
 *    Input. An integer variable that indicates the size of h dimension.
 *  @param[in] w
 *    Input. An integer variable that indicates the size of w dimension.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Tensor_type,data_type,data_orderis not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCpuTensor(cnmlCpuTensor_t *cpu_tensor,
                                              cnmlTensorType_t tensor_type,
                                              cnmlDataType_t data_type,
                                              cnmlDataOrder_t data_order,
                                              int n,
                                              int c,
                                              int h,
                                              int w);

/*!
 *  @brief A function.
 *
 *  This function initializes a tensor at CPU end according to the user-specified Tensor type.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlCpuTensor_t.
 *  @param[in] tensor_type
 *    Input. A variable indicating Tensor type.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Tensor_type not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateCpuTensor_V2(cnmlCpuTensor_t *tensor,
                                                 cnmlTensorType_t tensor_type);

/*!
 *  @brief A function.
 *
 *  When data at MLU end participates in some operations, it is necessary to get the information of
 *  corresponding data at CPU end. This function is used to bind the information of Tensor at the
 *  CPU to the MLU, so that MLU can get the necessary information at the CPU end when computing.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at MLU end.
 *  @param[in] cpu_tensor
 *    Input. A pointer pointing to the tensor at CPU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - The pointer of cpu_tensor is null.
 */
CNML_DLL_API cnmlStatus_t cnmlBindCpuDataInfo(cnmlTensor_t tensor, cnmlCpuTensor_t cpu_tensor);

/*!
 *  @brief A function.
 *
 *  According to the pointer given by the user, the pointer of the tensor at cpu end is freed.
 *
 *  @param[in] cpu_tensor
 *    Input. A pointer pointing to the tensor address at the CPU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of cpu_tensor is null.
 *    - The pointer content pointed to by cpu_tensor has been freed.
 */
CNML_DLL_API cnmlStatus_t cnmlDestroyCpuTensor(cnmlCpuTensor_t *cpu_tensor);

/*!
 *  @brief A function.
 *
 *  This function is used to copy data of tensor at CPU end to file.
 *
 *  @param[in] filename
 *    Input. A string pointer that specifies the file name.
 *  @param[in] cpu_tensor
 *    Input. A pointer pointing to the tensor address at the CPU end, indicating which tensor data
 *  needs to be saved.
 *  @param[in] tensor_type
 *    Input. An enumeration variable indicating the type of tensor at CPU end.
 *  @param[in] output
 *    Input. A void* pointer pointing to the address allocated by the CPU to save data.
 *  @param[in] app
 *    Input. A Boolean variable that specifies whether is written to a file in an additive manner.
 */
CNML_DLL_API void cnmlDumpTensor2File(const char *filename,
                                      cnmlCpuTensor_t cpu_tensor,
                                      cnmlTensorType_t tensor_type,
                                      void *output,
                                      bool app);

/*!
 *  @brief A function.
 *
 *  This function initializes a multidimensional (1-N-dimensional) Tensor at the MLU end according
 *  to the user-specified Tensor type.
 *
 *  This interface is an older version and will not be maintained in the future. It is recommended
 *  to use cnmlCreateTensor_V2.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to cnmlTensor_t
 *  @param[in] tensor_type
 *    Input. A variable indicating the Tensor type
 *  @param[in] data_type
 *    Input. A variable indicating the Tensor data type
 *  @param[in] n
 *    Input. A variable indicating the size of the input Tensor in the n-dimension
 *  @param[in] c
 *    Input. A variable indicating the size of the input Tensor in the c-dimension
 *  @param[in] h
 *    Input. A variable indicating the size of the input Tensor in the h-dimension
 *  @param[in] w
 *    Input. A variable indicating the size of the input Tensor in the w-dimension
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointer of tensor is null.
 *    - Tensor_typeis not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlCreateTensor(cnmlTensor_t *tensor,
                                           cnmlTensorType_t tensor_type,
                                           cnmlDataType_t data_type,
                                           int n,
                                           int c,
                                           int h,
                                           int w);

/*!
 *  @brief A function.
 *
 *  This function is used to bind the data information of the tensors at MLU and CPU end.
 *
 *  @param[in] tensor
 *    Input. A pointer pointing to the tensor at MLU end, and the interface currently supports only
 *  CNML_FILTER and CNML_CONST-type Tensor.
 *  @param[in] cpu_tensor
 *    Input. A pointer pointing to the tensor at CPU end, and the interface currently supports only
 *  CNML_FILTER and CNML_CONST-type Tensor.
 *  @param[in] cpu_data_ptr
 *    Input. A pointer of void type pointing to the binding data address of the Tensor at CPU end.
 *  @retval CNML_STATUS_SUCCESS
 *    The function ends normally.
 *  @retval CNML_STATUS_INVALIDPARAM
 *    At least one of the following conditions are met:
 *    - The pointers of tensor, cpu_tensor, cpu_data_ptr are null.
 *    - Tensor type is not supported.
 */
CNML_DLL_API cnmlStatus_t cnmlBindConstData(cnmlTensor_t tensor,
                                            cnmlCpuTensor_t cpu_tensor,
                                            void *cpu_tensor_ptr);

/******** deprecated API *********/

#if defined(__cplusplus)
}
#endif

#endif  // CNML_H_
